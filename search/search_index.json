{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to ROAR \u00a4","title":"Welcome to ROAR"},{"location":"#welcome-to-roar","text":"","title":"Welcome to ROAR"},{"location":"architecture/","text":"ROAR Carla Overall Architecture \u00a4 Environment Maps \u00a4 Environmental Perception \u00a4 Motion Planning \u00a4 Vehicle Controller \u00a4","title":"Architecture"},{"location":"architecture/#roar-carla-overall-architecture","text":"","title":"ROAR Carla Overall Architecture"},{"location":"architecture/#environment-maps","text":"","title":"Environment Maps"},{"location":"architecture/#environmental-perception","text":"","title":"Environmental Perception"},{"location":"architecture/#motion-planning","text":"","title":"Motion Planning"},{"location":"architecture/#vehicle-controller","text":"","title":"Vehicle Controller"},{"location":"introduction/","text":"Welcome to ROAR \u00a4 Documentation for ROAR-Simulator \u00a4 Quick Links \u00a4 If you are new to the project visit Quick Start If you are curious about ROAR Competition at Berkeley visit Berkeley ROAR If you are curious about Carla visit Carla Simulator For more information regarding DeCal Course visit Roar Decal . Contribute To ROAR Guide \u00a4 Communication \u00a4 Before starting a new contribution, it is important to let the community know what you plan on doing. This serves several purposes. It lets everyone know that you are going to start work on a feature or bug fix so that no one else does the same and duplicates your effort. It lets anyone who may already be working on the feature or bug fix know you intend to work on it, so they can tell you and you don't duplicate their effort. It gives others a chance to provide more information about what the feature or bug fix might need or how it may need to be implemented. You can let the community know by first opening an Issue on Github. An admin will tag a related Pull Request if this is a duplicated issue Documentation Style \u00a4 We use mkdocs and mkdocstrings to automatically generate documentation. This means that we require all Python code documentation to be written in Google Style The recommended method for enabling automatic Google Docstring framework generation is through PyCharm. Here's a tutorial on how to enable this feature in PyCharm Pull Request Style \u00a4 We ask that you fill out the pull request template as indicated in Github, to provide as much details as possible. Issue Style \u00a4 We ask that you fill out the correct issue template as indicated on Github.","title":"Introduction"},{"location":"introduction/#welcome-to-roar","text":"","title":"Welcome to ROAR"},{"location":"introduction/#documentation-for-roar-simulator","text":"","title":"Documentation for ROAR-Simulator"},{"location":"introduction/#quick-links","text":"If you are new to the project visit Quick Start If you are curious about ROAR Competition at Berkeley visit Berkeley ROAR If you are curious about Carla visit Carla Simulator For more information regarding DeCal Course visit Roar Decal .","title":"Quick Links"},{"location":"introduction/#contribute-to-roar-guide","text":"","title":"Contribute To ROAR Guide"},{"location":"introduction/#communication","text":"Before starting a new contribution, it is important to let the community know what you plan on doing. This serves several purposes. It lets everyone know that you are going to start work on a feature or bug fix so that no one else does the same and duplicates your effort. It lets anyone who may already be working on the feature or bug fix know you intend to work on it, so they can tell you and you don't duplicate their effort. It gives others a chance to provide more information about what the feature or bug fix might need or how it may need to be implemented. You can let the community know by first opening an Issue on Github. An admin will tag a related Pull Request if this is a duplicated issue","title":"Communication"},{"location":"introduction/#documentation-style","text":"We use mkdocs and mkdocstrings to automatically generate documentation. This means that we require all Python code documentation to be written in Google Style The recommended method for enabling automatic Google Docstring framework generation is through PyCharm. Here's a tutorial on how to enable this feature in PyCharm","title":"Documentation Style"},{"location":"introduction/#pull-request-style","text":"We ask that you fill out the pull request template as indicated in Github, to provide as much details as possible.","title":"Pull Request Style"},{"location":"introduction/#issue-style","text":"We ask that you fill out the correct issue template as indicated on Github.","title":"Issue Style"},{"location":"quickstart/","text":"Note: for Mac users, please dual boot as Windows 10. Fork the Repo Please click the Fork button on the upper right corner and submit a pull request to master branch. For a more in-depth tutorial on recommended setup video clone the repo git clone --recursive https://github.com/YOURUSERNAME/ROAR.git Create virtual environment with python3.7 conda create -n ROAR python=3.7 conda activate ROAR Install Dependency General Dependency pip install -r requirements.txt in the ROAR folder For simulator cd ROAR_Sim pip install -r requirements.txt Download Simulator distribution for your OS GDrive Link For actual vehicle wired to your computer cd ROAR_Jetson pip install -r requirements.txt For actual vehicle running on Jetson Nano cd ROAR_Jetson sudo apt-get install python-dev libsdl1.2-dev libsdl-image1.2-dev libsdl-mixer1.2-dev libsdl-ttf2.0-dev libsdl1.2-dev libsmpeg-dev python-numpy subversion libportmidi-dev ffmpeg libswscale-dev libavformat-dev libavcodec-dev libfreetype6-dev pip3 install -r requirements_jetson_nano.txt Enjoy For Simulator python runner_sim.py For physical car python runner_jetson.py or python3 runner_jetson.py","title":"Quick Start"},{"location":"code_documentations/runcompeval/","text":"::: runner_competition_evaluator","title":"Runner Competition Evaluator"},{"location":"code_documentations/runner_sim/","text":"main () \u00a4 Starts game loop Source code in ROAR/runner_sim.py def main (): \"\"\"Starts game loop\"\"\" agent_config = AgentConfig . parse_file ( Path ( \"./ROAR_Sim/configurations/agent_configuration.json\" )) carla_config = CarlaConfig . parse_file ( Path ( \"./ROAR_Sim/configurations/configuration.json\" )) carla_runner = CarlaRunner ( carla_settings = carla_config , agent_settings = agent_config , npc_agent_class = PurePursuitAgent ) try : my_vehicle = carla_runner . set_carla_world () agent = PIDAgent ( vehicle = my_vehicle , agent_settings = agent_config ) carla_runner . start_game_loop ( agent = agent , use_manual_control = False ) except Exception as e : logging . error ( f \"Something bad happened during initialization: { e } \" ) carla_runner . on_finish () logging . error ( f \" { e } . Might be a good idea to restart Server\" )","title":"Runner Sim"},{"location":"code_documentations/runner_sim/#runner_sim.main","text":"Starts game loop Source code in ROAR/runner_sim.py def main (): \"\"\"Starts game loop\"\"\" agent_config = AgentConfig . parse_file ( Path ( \"./ROAR_Sim/configurations/agent_configuration.json\" )) carla_config = CarlaConfig . parse_file ( Path ( \"./ROAR_Sim/configurations/configuration.json\" )) carla_runner = CarlaRunner ( carla_settings = carla_config , agent_settings = agent_config , npc_agent_class = PurePursuitAgent ) try : my_vehicle = carla_runner . set_carla_world () agent = PIDAgent ( vehicle = my_vehicle , agent_settings = agent_config ) carla_runner . start_game_loop ( agent = agent , use_manual_control = False ) except Exception as e : logging . error ( f \"Something bad happened during initialization: { e } \" ) carla_runner . on_finish () logging . error ( f \" { e } . Might be a good idea to restart Server\" )","title":"main()"},{"location":"code_documentations/Bridges/bridges/","text":"This file defines a basic Bridge for extensibility of the ROAR Autonomous software Bridge \u00a4 __init__ ( self ) special \u00a4 Source code in Bridges/bridge.py def __init__ ( self ): self . logger = logging . Logger ( __name__ ) convert_control_from_agent_to_source ( self , control ) \u00a4 Source code in Bridges/bridge.py @abstractmethod def convert_control_from_agent_to_source ( self , control : VehicleControl ) -> Any : pass convert_control_from_source_to_agent ( self , source ) \u00a4 Source code in Bridges/bridge.py @abstractmethod def convert_control_from_source_to_agent ( self , source ) -> VehicleControl : pass convert_depth_from_source_to_agent ( self , source ) \u00a4 Source code in Bridges/bridge.py @abstractmethod def convert_depth_from_source_to_agent ( self , source ) -> DepthData : pass convert_imu_from_source_to_agent ( self , source ) \u00a4 Source code in Bridges/bridge.py @abstractmethod def convert_imu_from_source_to_agent ( self , source ) -> IMUData : pass convert_location_from_source_to_agent ( self , source ) \u00a4 Source code in Bridges/bridge.py @abstractmethod def convert_location_from_source_to_agent ( self , source ) -> Location : pass convert_rgb_from_source_to_agent ( self , source ) \u00a4 Source code in Bridges/bridge.py @abstractmethod def convert_rgb_from_source_to_agent ( self , source ) -> RGBData : pass convert_rotation_from_source_to_agent ( self , source ) \u00a4 Source code in Bridges/bridge.py @abstractmethod def convert_rotation_from_source_to_agent ( self , source ) -> Rotation : pass convert_sensor_data_from_source_to_agent ( self , source ) \u00a4 Source code in Bridges/bridge.py @abstractmethod def convert_sensor_data_from_source_to_agent ( self , source ) -> SensorsData : pass convert_transform_from_source_to_agent ( self , source ) \u00a4 Source code in Bridges/bridge.py @abstractmethod def convert_transform_from_source_to_agent ( self , source ) -> Transform : pass convert_vector3d_from_agent_to_source ( self , vector3d ) \u00a4 Source code in Bridges/bridge.py @abstractmethod def convert_vector3d_from_agent_to_source ( self , vector3d : Vector3D ) -> Any : pass convert_vector3d_from_source_to_agent ( self , source ) \u00a4 Source code in Bridges/bridge.py @abstractmethod def convert_vector3d_from_source_to_agent ( self , source ) -> Vector3D : pass convert_vehicle_from_source_to_agent ( self , source ) \u00a4 Source code in Bridges/bridge.py @abstractmethod def convert_vehicle_from_source_to_agent ( self , source ) -> Vehicle : pass","title":"Bridge"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge","text":"","title":"Bridge"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.__init__","text":"Source code in Bridges/bridge.py def __init__ ( self ): self . logger = logging . Logger ( __name__ )","title":"__init__()"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.convert_control_from_agent_to_source","text":"Source code in Bridges/bridge.py @abstractmethod def convert_control_from_agent_to_source ( self , control : VehicleControl ) -> Any : pass","title":"convert_control_from_agent_to_source()"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.convert_control_from_source_to_agent","text":"Source code in Bridges/bridge.py @abstractmethod def convert_control_from_source_to_agent ( self , source ) -> VehicleControl : pass","title":"convert_control_from_source_to_agent()"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.convert_depth_from_source_to_agent","text":"Source code in Bridges/bridge.py @abstractmethod def convert_depth_from_source_to_agent ( self , source ) -> DepthData : pass","title":"convert_depth_from_source_to_agent()"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.convert_imu_from_source_to_agent","text":"Source code in Bridges/bridge.py @abstractmethod def convert_imu_from_source_to_agent ( self , source ) -> IMUData : pass","title":"convert_imu_from_source_to_agent()"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.convert_location_from_source_to_agent","text":"Source code in Bridges/bridge.py @abstractmethod def convert_location_from_source_to_agent ( self , source ) -> Location : pass","title":"convert_location_from_source_to_agent()"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.convert_rgb_from_source_to_agent","text":"Source code in Bridges/bridge.py @abstractmethod def convert_rgb_from_source_to_agent ( self , source ) -> RGBData : pass","title":"convert_rgb_from_source_to_agent()"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.convert_rotation_from_source_to_agent","text":"Source code in Bridges/bridge.py @abstractmethod def convert_rotation_from_source_to_agent ( self , source ) -> Rotation : pass","title":"convert_rotation_from_source_to_agent()"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.convert_sensor_data_from_source_to_agent","text":"Source code in Bridges/bridge.py @abstractmethod def convert_sensor_data_from_source_to_agent ( self , source ) -> SensorsData : pass","title":"convert_sensor_data_from_source_to_agent()"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.convert_transform_from_source_to_agent","text":"Source code in Bridges/bridge.py @abstractmethod def convert_transform_from_source_to_agent ( self , source ) -> Transform : pass","title":"convert_transform_from_source_to_agent()"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.convert_vector3d_from_agent_to_source","text":"Source code in Bridges/bridge.py @abstractmethod def convert_vector3d_from_agent_to_source ( self , vector3d : Vector3D ) -> Any : pass","title":"convert_vector3d_from_agent_to_source()"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.convert_vector3d_from_source_to_agent","text":"Source code in Bridges/bridge.py @abstractmethod def convert_vector3d_from_source_to_agent ( self , source ) -> Vector3D : pass","title":"convert_vector3d_from_source_to_agent()"},{"location":"code_documentations/Bridges/bridges/#Bridges.bridge.Bridge.convert_vehicle_from_source_to_agent","text":"Source code in Bridges/bridge.py @abstractmethod def convert_vehicle_from_source_to_agent ( self , source ) -> Vehicle : pass","title":"convert_vehicle_from_source_to_agent()"},{"location":"code_documentations/Bridges/carla_bridge/","text":"::: Bridges.carla_bridge","title":"Carla Bridge"},{"location":"code_documentations/Bridges/jetson_bridge/","text":"JetsonBridge \u00a4 convert_control_from_agent_to_source ( self , control ) \u00a4 Converts control to Throttle and Steering numpy arrays bound between -1 and 1. Parameters: Name Type Description Default control VehicleControl required Returns: Type Description Tuple Tuple Source code in Bridges/jetson_bridge.py def convert_control_from_agent_to_source ( self , control : VehicleControl ) -> Tuple : \"\"\" Converts control to Throttle and Steering numpy arrays bound between -1 and 1. Args: control (): Returns: Tuple \"\"\" return np . clip ( control . throttle , a_min =- 1 , a_max = 1 ), np . clip ( control . steering , a_min =- 1 , a_max = 1 ) convert_control_from_source_to_agent ( self , source ) \u00a4 Convert Jetson raw vehicle control to VehicleControl(throttle,steering). Parameters: Name Type Description Default source Vehicle required Returns: Type Description VehicleControl VehicleControl(Throttle, Steering) Source code in Bridges/jetson_bridge.py def convert_control_from_source_to_agent ( self , source : JetsonVehicle ) -> VehicleControl : \"\"\" Convert Jetson raw vehicle control to VehicleControl(throttle,steering). Args: source (): Returns: VehicleControl(Throttle, Steering) \"\"\" return VehicleControl ( throttle = source . throttle , steering = source . steering ) convert_depth_from_source_to_agent ( self , source ) \u00a4 Convert Jetson raw Image to an Optional with Depth numpy array. Parameters: Name Type Description Default source required Returns: Type Description Optional[ROAR.utilities_module.data_structures_models.DepthData] DepthData Source code in Bridges/jetson_bridge.py def convert_depth_from_source_to_agent ( self , source ) -> Optional [ DepthData ]: \"\"\" Convert Jetson raw Image to an Optional with Depth numpy array. Args: source (): Returns: DepthData \"\"\" if source is not None : return DepthData ( data = source ) return None convert_imu_from_source_to_agent ( self , source ) \u00a4 Convert Jetson raw IMUData to IMUData(accelerometer, gyroscope). Parameters: Name Type Description Default source required Returns: Type Description IMUData IMUData(accelerometer, gyroscope) Source code in Bridges/jetson_bridge.py def convert_imu_from_source_to_agent ( self , source ) -> IMUData : \"\"\" Convert Jetson raw IMUData to IMUData(accelerometer, gyroscope). Args: source (): Returns: IMUData(accelerometer, gyroscope) \"\"\" # TODO fill in data here return IMUData ( accelerometer = Vector3D ( x = 0 , y = 0 , z = 0 ), gyroscope = Vector3D ( x = 0 , y = 0 , z = 0 ), ) convert_location_from_source_to_agent ( self , source ) \u00a4 Convert Location data from Jetson Vehicle to Agent's location data type. Parameters: Name Type Description Default source required Returns: Type Description Location Location(x, y, z) Source code in Bridges/jetson_bridge.py def convert_location_from_source_to_agent ( self , source ) -> Location : \"\"\" Convert Location data from Jetson Vehicle to Agent's location data type. Args: source (): Returns: Location(x, y, z) \"\"\" return Location ( x = source . x , y = source . y , z =- source . z ) convert_rgb_from_source_to_agent ( self , source ) \u00a4 Convert Jetson raw Image to an Optional with RGB numpy array. Parameters: Name Type Description Default source required Returns: Type Description Optional[ROAR.utilities_module.data_structures_models.RGBData] RGBData Source code in Bridges/jetson_bridge.py def convert_rgb_from_source_to_agent ( self , source ) -> Optional [ RGBData ]: \"\"\" Convert Jetson raw Image to an Optional with RGB numpy array. Args: source (): Returns: RGBData \"\"\" if source is not None : return RGBData ( data = source ) return None convert_rotation_from_source_to_agent ( self , source ) \u00a4 Convert a Jetson raw rotation to Rotation(pitch=float,yaw=float,roll=float). Parameters: Name Type Description Default source required Returns: Type Description Rotation Rotation(pitch, yaw, roll) Source code in Bridges/jetson_bridge.py def convert_rotation_from_source_to_agent ( self , source ) -> Rotation : \"\"\" Convert a Jetson raw rotation to Rotation(pitch=float,yaw=float,roll=float). Args: source (): Returns: Rotation(pitch, yaw, roll) \"\"\" return Rotation ( pitch = source . pitch , yaw = source . yaw , roll = source . roll ) convert_sensor_data_from_source_to_agent ( self , source ) \u00a4 Returns Jetson Sensors Data from raw front RGB, rear RGB, front depth, and IMU Data. Parameters: Name Type Description Default source required Returns: Type Description SensorsData SensorData(front_RGB, rear_RGB, front_depth, IMU_Data) Source code in Bridges/jetson_bridge.py def convert_sensor_data_from_source_to_agent ( self , source ) -> SensorsData : \"\"\" Returns Jetson Sensors Data from raw front RGB, rear RGB, front depth, and IMU Data. Args: source (): Returns: SensorData(front_RGB, rear_RGB, front_depth, IMU_Data) \"\"\" return SensorsData ( front_rgb = self . convert_rgb_from_source_to_agent ( source = source . get ( \"front_rgb\" , None ) ), rear_rgb = self . convert_rgb_from_source_to_agent ( source = source . get ( \"rear_rgb\" , None ) ), front_depth = self . convert_depth_from_source_to_agent ( source = source . get ( \"front_depth\" , None ) ), imu_data = self . convert_imu_from_source_to_agent ( source = source . get ( \"imu\" , None ) ), vive_tracker_data = self . convert_vive_tracker_data_from_source_to_agent ( source = source . get ( \"vive_tracking\" , None )) ) convert_transform_from_source_to_agent ( self , source ) \u00a4 Convert Jetson raw location and rotation to Transform(location,rotation). Parameters: Name Type Description Default source required Returns: Type Description Transform Transform(Location, Rotation) Source code in Bridges/jetson_bridge.py def convert_transform_from_source_to_agent ( self , source ) -> Transform : \"\"\" Convert Jetson raw location and rotation to Transform(location,rotation). Args: source (): Returns: Transform(Location, Rotation) \"\"\" return Transform ( location = self . convert_location_from_source_to_agent ( source = source . location ), rotation = self . convert_rotation_from_source_to_agent ( source = source . rotation ), ) convert_vector3d_from_agent_to_source ( self , vector3d ) \u00a4 Convert Jetson Vector3D Object to Vector3D data. Parameters: Name Type Description Default vector3d Vector3D required Returns: Type Description Any Array Source code in Bridges/jetson_bridge.py def convert_vector3d_from_agent_to_source ( self , vector3d : Vector3D ) -> Any : \"\"\" Convert Jetson Vector3D Object to Vector3D data. Args: vector3d (): Returns: Array \"\"\" return [ vector3d . x , vector3d . y , vector3d . z ] convert_vector3d_from_source_to_agent ( self , source ) \u00a4 Convert Jetson raw Vector3d Data to a Vector3D Object. Parameters: Name Type Description Default source required Returns: Type Description Vector3D Vector3D(x, y, z) Source code in Bridges/jetson_bridge.py def convert_vector3d_from_source_to_agent ( self , source ) -> Vector3D : \"\"\" Convert Jetson raw Vector3d Data to a Vector3D Object. Args: source (): Returns: Vector3D(x, y, z) \"\"\" return Vector3D ( x = source . x , y = source . y , z = source . z ) convert_vehicle_from_source_to_agent ( self , source ) \u00a4 Converts Transform, Velocity, Wheel_Base, and Control of JetsonVehicle. Parameters: Name Type Description Default source Vehicle required Returns: Type Description Vehicle Vehicle(Transform, Velocity, Wheel_Base, Control) Source code in Bridges/jetson_bridge.py def convert_vehicle_from_source_to_agent ( self , source : JetsonVehicle ) -> Vehicle : \"\"\" Converts Transform, Velocity, Wheel_Base, and Control of JetsonVehicle. Args: source (): Returns: Vehicle(Transform, Velocity, Wheel_Base, Control) \"\"\" return Vehicle ( transform = Transform ( location = Location ( x =- source . location [ 0 ], y = source . location [ 1 ], z =- source . location [ 2 ]), rotation = Rotation ( roll =- source . rotation [ 2 ], pitch = source . rotation [ 0 ], yaw =- source . rotation [ 1 ]), ), velocity = Vector3D ( x =- source . velocity [ 0 ], y = source . velocity [ 1 ], z =- source . velocity [ 2 ]), wheel_base = 0.26 , control = self . convert_control_from_source_to_agent ( source = source ) ) convert_vive_tracker_data_from_source_to_agent ( self , source ) \u00a4 Converts raw Vive Tracker data to ViveTrackerData(Location, Rotation, Velocity). Parameters: Name Type Description Default source Optional[ROAR_Jetson.vive.models.ViveTrackerMessage] required Returns: Type Description Optional[ROAR.utilities_module.data_structures_models.ViveTrackerData] ViveTrackerData(Location, Rotation, Velocity) Source code in Bridges/jetson_bridge.py def convert_vive_tracker_data_from_source_to_agent ( self , source : Optional [ ViveTrackerMessage ]) -> \\ Optional [ ViveTrackerData ]: \"\"\" Converts raw Vive Tracker data to ViveTrackerData(Location, Rotation, Velocity). Args: source (): Returns: ViveTrackerData(Location, Rotation, Velocity) \"\"\" if source is not None : vive_tracker_data = ViveTrackerData ( location = Location ( x =- source . x , y = source . y , z =- source . z ), rotation = Rotation ( roll =- source . roll , pitch = source . pitch , yaw =- source . yaw ), velocity = Vector3D ( x = source . vel_x , y = source . vel_y , z = source . vel_z ) ) return vive_tracker_data return None","title":"Jetson Bridge"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge","text":"","title":"JetsonBridge"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_control_from_agent_to_source","text":"Converts control to Throttle and Steering numpy arrays bound between -1 and 1. Parameters: Name Type Description Default control VehicleControl required Returns: Type Description Tuple Tuple Source code in Bridges/jetson_bridge.py def convert_control_from_agent_to_source ( self , control : VehicleControl ) -> Tuple : \"\"\" Converts control to Throttle and Steering numpy arrays bound between -1 and 1. Args: control (): Returns: Tuple \"\"\" return np . clip ( control . throttle , a_min =- 1 , a_max = 1 ), np . clip ( control . steering , a_min =- 1 , a_max = 1 )","title":"convert_control_from_agent_to_source()"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_control_from_source_to_agent","text":"Convert Jetson raw vehicle control to VehicleControl(throttle,steering). Parameters: Name Type Description Default source Vehicle required Returns: Type Description VehicleControl VehicleControl(Throttle, Steering) Source code in Bridges/jetson_bridge.py def convert_control_from_source_to_agent ( self , source : JetsonVehicle ) -> VehicleControl : \"\"\" Convert Jetson raw vehicle control to VehicleControl(throttle,steering). Args: source (): Returns: VehicleControl(Throttle, Steering) \"\"\" return VehicleControl ( throttle = source . throttle , steering = source . steering )","title":"convert_control_from_source_to_agent()"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_depth_from_source_to_agent","text":"Convert Jetson raw Image to an Optional with Depth numpy array. Parameters: Name Type Description Default source required Returns: Type Description Optional[ROAR.utilities_module.data_structures_models.DepthData] DepthData Source code in Bridges/jetson_bridge.py def convert_depth_from_source_to_agent ( self , source ) -> Optional [ DepthData ]: \"\"\" Convert Jetson raw Image to an Optional with Depth numpy array. Args: source (): Returns: DepthData \"\"\" if source is not None : return DepthData ( data = source ) return None","title":"convert_depth_from_source_to_agent()"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_imu_from_source_to_agent","text":"Convert Jetson raw IMUData to IMUData(accelerometer, gyroscope). Parameters: Name Type Description Default source required Returns: Type Description IMUData IMUData(accelerometer, gyroscope) Source code in Bridges/jetson_bridge.py def convert_imu_from_source_to_agent ( self , source ) -> IMUData : \"\"\" Convert Jetson raw IMUData to IMUData(accelerometer, gyroscope). Args: source (): Returns: IMUData(accelerometer, gyroscope) \"\"\" # TODO fill in data here return IMUData ( accelerometer = Vector3D ( x = 0 , y = 0 , z = 0 ), gyroscope = Vector3D ( x = 0 , y = 0 , z = 0 ), )","title":"convert_imu_from_source_to_agent()"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_location_from_source_to_agent","text":"Convert Location data from Jetson Vehicle to Agent's location data type. Parameters: Name Type Description Default source required Returns: Type Description Location Location(x, y, z) Source code in Bridges/jetson_bridge.py def convert_location_from_source_to_agent ( self , source ) -> Location : \"\"\" Convert Location data from Jetson Vehicle to Agent's location data type. Args: source (): Returns: Location(x, y, z) \"\"\" return Location ( x = source . x , y = source . y , z =- source . z )","title":"convert_location_from_source_to_agent()"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_rgb_from_source_to_agent","text":"Convert Jetson raw Image to an Optional with RGB numpy array. Parameters: Name Type Description Default source required Returns: Type Description Optional[ROAR.utilities_module.data_structures_models.RGBData] RGBData Source code in Bridges/jetson_bridge.py def convert_rgb_from_source_to_agent ( self , source ) -> Optional [ RGBData ]: \"\"\" Convert Jetson raw Image to an Optional with RGB numpy array. Args: source (): Returns: RGBData \"\"\" if source is not None : return RGBData ( data = source ) return None","title":"convert_rgb_from_source_to_agent()"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_rotation_from_source_to_agent","text":"Convert a Jetson raw rotation to Rotation(pitch=float,yaw=float,roll=float). Parameters: Name Type Description Default source required Returns: Type Description Rotation Rotation(pitch, yaw, roll) Source code in Bridges/jetson_bridge.py def convert_rotation_from_source_to_agent ( self , source ) -> Rotation : \"\"\" Convert a Jetson raw rotation to Rotation(pitch=float,yaw=float,roll=float). Args: source (): Returns: Rotation(pitch, yaw, roll) \"\"\" return Rotation ( pitch = source . pitch , yaw = source . yaw , roll = source . roll )","title":"convert_rotation_from_source_to_agent()"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_sensor_data_from_source_to_agent","text":"Returns Jetson Sensors Data from raw front RGB, rear RGB, front depth, and IMU Data. Parameters: Name Type Description Default source required Returns: Type Description SensorsData SensorData(front_RGB, rear_RGB, front_depth, IMU_Data) Source code in Bridges/jetson_bridge.py def convert_sensor_data_from_source_to_agent ( self , source ) -> SensorsData : \"\"\" Returns Jetson Sensors Data from raw front RGB, rear RGB, front depth, and IMU Data. Args: source (): Returns: SensorData(front_RGB, rear_RGB, front_depth, IMU_Data) \"\"\" return SensorsData ( front_rgb = self . convert_rgb_from_source_to_agent ( source = source . get ( \"front_rgb\" , None ) ), rear_rgb = self . convert_rgb_from_source_to_agent ( source = source . get ( \"rear_rgb\" , None ) ), front_depth = self . convert_depth_from_source_to_agent ( source = source . get ( \"front_depth\" , None ) ), imu_data = self . convert_imu_from_source_to_agent ( source = source . get ( \"imu\" , None ) ), vive_tracker_data = self . convert_vive_tracker_data_from_source_to_agent ( source = source . get ( \"vive_tracking\" , None )) )","title":"convert_sensor_data_from_source_to_agent()"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_transform_from_source_to_agent","text":"Convert Jetson raw location and rotation to Transform(location,rotation). Parameters: Name Type Description Default source required Returns: Type Description Transform Transform(Location, Rotation) Source code in Bridges/jetson_bridge.py def convert_transform_from_source_to_agent ( self , source ) -> Transform : \"\"\" Convert Jetson raw location and rotation to Transform(location,rotation). Args: source (): Returns: Transform(Location, Rotation) \"\"\" return Transform ( location = self . convert_location_from_source_to_agent ( source = source . location ), rotation = self . convert_rotation_from_source_to_agent ( source = source . rotation ), )","title":"convert_transform_from_source_to_agent()"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_vector3d_from_agent_to_source","text":"Convert Jetson Vector3D Object to Vector3D data. Parameters: Name Type Description Default vector3d Vector3D required Returns: Type Description Any Array Source code in Bridges/jetson_bridge.py def convert_vector3d_from_agent_to_source ( self , vector3d : Vector3D ) -> Any : \"\"\" Convert Jetson Vector3D Object to Vector3D data. Args: vector3d (): Returns: Array \"\"\" return [ vector3d . x , vector3d . y , vector3d . z ]","title":"convert_vector3d_from_agent_to_source()"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_vector3d_from_source_to_agent","text":"Convert Jetson raw Vector3d Data to a Vector3D Object. Parameters: Name Type Description Default source required Returns: Type Description Vector3D Vector3D(x, y, z) Source code in Bridges/jetson_bridge.py def convert_vector3d_from_source_to_agent ( self , source ) -> Vector3D : \"\"\" Convert Jetson raw Vector3d Data to a Vector3D Object. Args: source (): Returns: Vector3D(x, y, z) \"\"\" return Vector3D ( x = source . x , y = source . y , z = source . z )","title":"convert_vector3d_from_source_to_agent()"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_vehicle_from_source_to_agent","text":"Converts Transform, Velocity, Wheel_Base, and Control of JetsonVehicle. Parameters: Name Type Description Default source Vehicle required Returns: Type Description Vehicle Vehicle(Transform, Velocity, Wheel_Base, Control) Source code in Bridges/jetson_bridge.py def convert_vehicle_from_source_to_agent ( self , source : JetsonVehicle ) -> Vehicle : \"\"\" Converts Transform, Velocity, Wheel_Base, and Control of JetsonVehicle. Args: source (): Returns: Vehicle(Transform, Velocity, Wheel_Base, Control) \"\"\" return Vehicle ( transform = Transform ( location = Location ( x =- source . location [ 0 ], y = source . location [ 1 ], z =- source . location [ 2 ]), rotation = Rotation ( roll =- source . rotation [ 2 ], pitch = source . rotation [ 0 ], yaw =- source . rotation [ 1 ]), ), velocity = Vector3D ( x =- source . velocity [ 0 ], y = source . velocity [ 1 ], z =- source . velocity [ 2 ]), wheel_base = 0.26 , control = self . convert_control_from_source_to_agent ( source = source ) )","title":"convert_vehicle_from_source_to_agent()"},{"location":"code_documentations/Bridges/jetson_bridge/#Bridges.jetson_bridge.JetsonBridge.convert_vive_tracker_data_from_source_to_agent","text":"Converts raw Vive Tracker data to ViveTrackerData(Location, Rotation, Velocity). Parameters: Name Type Description Default source Optional[ROAR_Jetson.vive.models.ViveTrackerMessage] required Returns: Type Description Optional[ROAR.utilities_module.data_structures_models.ViveTrackerData] ViveTrackerData(Location, Rotation, Velocity) Source code in Bridges/jetson_bridge.py def convert_vive_tracker_data_from_source_to_agent ( self , source : Optional [ ViveTrackerMessage ]) -> \\ Optional [ ViveTrackerData ]: \"\"\" Converts raw Vive Tracker data to ViveTrackerData(Location, Rotation, Velocity). Args: source (): Returns: ViveTrackerData(Location, Rotation, Velocity) \"\"\" if source is not None : vive_tracker_data = ViveTrackerData ( location = Location ( x =- source . x , y = source . y , z =- source . z ), rotation = Rotation ( roll =- source . roll , pitch = source . pitch , yaw =- source . yaw ), velocity = Vector3D ( x = source . vel_x , y = source . vel_y , z = source . vel_z ) ) return vive_tracker_data return None","title":"convert_vive_tracker_data_from_source_to_agent()"},{"location":"code_documentations/ROAR/agent_module/","text":"ForwardOnlyAgent \u00a4 __init__ ( self , vehicle , agent_settings , ** kwargs ) special \u00a4 Source code in ROAR/agent_module/forward_only_agent.py def __init__ ( self , vehicle : Vehicle , agent_settings : AgentConfig , ** kwargs ): super () . __init__ ( vehicle , agent_settings , ** kwargs ) run_step ( self , sensors_data , vehicle ) \u00a4 Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/agent_module/forward_only_agent.py def run_step ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> VehicleControl : super () . run_step ( sensors_data = sensors_data , vehicle = vehicle ) control = VehicleControl ( throttle = 0.4 , steering = 0 ) return control OpenCVTensorflowObjectDetectionAgent \u00a4 __init__ ( self , vehicle , agent_settings ) special \u00a4 Source code in ROAR/agent_module/opencv_tensorflow_object_detection_agent.py def __init__ ( self , vehicle : Vehicle , agent_settings : AgentConfig ): super () . __init__ ( vehicle , agent_settings ) folder_name = \"ssd_mobilenet_v2_coco_2018_03_29\" self . weights_folder_path = \\ Path ( \"/home/michael/Desktop/projects/ROAR/ROAR-Sim/data/weights/\" ) frozen_graph_weights_path : Path = self . weights_folder_path / 'opencv_weights_and_config' / folder_name / 'frozen_inference_graph.pb' frozen_graph_struct_path : Path = self . weights_folder_path / 'opencv_weights_and_config' / folder_name / 'model_structure.pbtxt' print ( f \"Path set \\n { frozen_graph_weights_path } \\n { frozen_graph_struct_path } \" ) self . tensorflowNet = cv2 . dnn . readNetFromTensorflow ( frozen_graph_weights_path . as_posix (), frozen_graph_struct_path . as_posix () ) print ( \"OpenCVTensorflowObjectDetectionAgent initialized\" ) run_step ( self , sensors_data , vehicle ) \u00a4 Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/agent_module/opencv_tensorflow_object_detection_agent.py def run_step ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> VehicleControl : super ( OpenCVTensorflowObjectDetectionAgent , self ) . run_step ( sensors_data = sensors_data , vehicle = vehicle ) image = self . front_rgb_camera . data . copy () rows , cols , channels = image . shape # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Use the given image as input, which needs to be blob(s). self . tensorflowNet . setInput ( cv2 . dnn . blobFromImage ( image , size = ( 300 , 300 ), swapRB = True , crop = False )) # Runs a forward pass to compute the net output networkOutput = self . tensorflowNet . forward () # Loop on the outputs for detection in networkOutput [ 0 , 0 ]: score = float ( detection [ 2 ]) if score > 0.3 : left = detection [ 3 ] * cols top = detection [ 4 ] * rows right = detection [ 5 ] * cols bottom = detection [ 6 ] * rows area = ( right - left ) * ( bottom - top ) # draw a red rectangle around detected objects if area < 10000 : cv2 . rectangle ( image , ( int ( left ), int ( top )), ( int ( right ), int ( bottom )), ( 0 , 0 , 255 ), thickness = 2 ) self . logger . debug ( f \"Detection confirmed. Score = { score } \" ) # cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (0, 0, 255), thickness=2) # Show the image with a rectagle surrounding the detected objects cv2 . imshow ( 'Image' , image ) cv2 . waitKey ( 1 ) return VehicleControl () PIDAgent \u00a4 __init__ ( self , target_speed = 40 , ** kwargs ) special \u00a4 Source code in ROAR/agent_module/pid_agent.py def __init__ ( self , target_speed = 40 , ** kwargs ): super () . __init__ ( ** kwargs ) self . target_speed = target_speed self . logger = logging . getLogger ( \"PID Agent\" ) self . route_file_path = Path ( self . agent_settings . waypoint_file_path ) self . pid_controller = PIDController ( agent = self , steering_boundary = ( - 1 , 1 ), throttle_boundary = ( - 1 , 1 )) self . mission_planner = WaypointFollowingMissionPlanner ( agent = self ) # initiated right after mission plan self . behavior_planner = BehaviorPlanner ( agent = self ) self . local_planner = SimpleWaypointFollowingLocalPlanner ( agent = self , controller = self . pid_controller , mission_planner = self . mission_planner , behavior_planner = self . behavior_planner , closeness_threshold = 1 ) self . logger . debug ( f \"Waypoint Following Agent Initiated. Reading f\" f \"rom { self . route_file_path . as_posix () } \" ) run_step ( self , vehicle , sensors_data ) \u00a4 Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/agent_module/pid_agent.py def run_step ( self , vehicle : Vehicle , sensors_data : SensorsData ) -> VehicleControl : super ( PIDAgent , self ) . run_step ( vehicle = vehicle , sensors_data = sensors_data ) self . transform_history . append ( self . vehicle . transform ) if self . local_planner . is_done (): control = VehicleControl () self . logger . debug ( \"Path Following Agent is Done. Idling.\" ) else : control = self . local_planner . run_in_series () return control PurePursuitAgent \u00a4 __init__ ( self , vehicle , agent_settings , target_speed = 50 ) special \u00a4 Source code in ROAR/agent_module/pure_pursuit_agent.py def __init__ ( self , vehicle : Vehicle , agent_settings : AgentConfig , target_speed = 50 ): super () . __init__ ( vehicle = vehicle , agent_settings = agent_settings ) self . route_file_path = Path ( self . agent_settings . waypoint_file_path ) self . pure_pursuit_controller = \\ PurePursuitController ( agent = self , target_speed = target_speed , look_ahead_gain = 0.1 , look_ahead_distance = 3 ) self . mission_planner = WaypointFollowingMissionPlanner ( agent = self ) # initiated right after mission plan self . behavior_planner = BehaviorPlanner ( agent = self ) self . local_planner = SimpleWaypointFollowingLocalPlanner ( agent = self , controller = self . pure_pursuit_controller , mission_planner = self . mission_planner , behavior_planner = self . behavior_planner , closeness_threshold = 3 ) run_step ( self , sensors_data , vehicle ) \u00a4 Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/agent_module/pure_pursuit_agent.py def run_step ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> VehicleControl : super ( PurePursuitAgent , self ) . run_step ( sensors_data = sensors_data , vehicle = vehicle ) vehicle_control = self . local_planner . run_in_series () return vehicle_control","title":"Agent Module"},{"location":"code_documentations/ROAR/agent_module/#ROAR.agent_module.forward_only_agent.ForwardOnlyAgent","text":"","title":"ForwardOnlyAgent"},{"location":"code_documentations/ROAR/agent_module/#ROAR.agent_module.forward_only_agent.ForwardOnlyAgent.__init__","text":"Source code in ROAR/agent_module/forward_only_agent.py def __init__ ( self , vehicle : Vehicle , agent_settings : AgentConfig , ** kwargs ): super () . __init__ ( vehicle , agent_settings , ** kwargs )","title":"__init__()"},{"location":"code_documentations/ROAR/agent_module/#ROAR.agent_module.forward_only_agent.ForwardOnlyAgent.run_step","text":"Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/agent_module/forward_only_agent.py def run_step ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> VehicleControl : super () . run_step ( sensors_data = sensors_data , vehicle = vehicle ) control = VehicleControl ( throttle = 0.4 , steering = 0 ) return control","title":"run_step()"},{"location":"code_documentations/ROAR/agent_module/#ROAR.agent_module.opencv_tensorflow_object_detection_agent.OpenCVTensorflowObjectDetectionAgent","text":"","title":"OpenCVTensorflowObjectDetectionAgent"},{"location":"code_documentations/ROAR/agent_module/#ROAR.agent_module.opencv_tensorflow_object_detection_agent.OpenCVTensorflowObjectDetectionAgent.__init__","text":"Source code in ROAR/agent_module/opencv_tensorflow_object_detection_agent.py def __init__ ( self , vehicle : Vehicle , agent_settings : AgentConfig ): super () . __init__ ( vehicle , agent_settings ) folder_name = \"ssd_mobilenet_v2_coco_2018_03_29\" self . weights_folder_path = \\ Path ( \"/home/michael/Desktop/projects/ROAR/ROAR-Sim/data/weights/\" ) frozen_graph_weights_path : Path = self . weights_folder_path / 'opencv_weights_and_config' / folder_name / 'frozen_inference_graph.pb' frozen_graph_struct_path : Path = self . weights_folder_path / 'opencv_weights_and_config' / folder_name / 'model_structure.pbtxt' print ( f \"Path set \\n { frozen_graph_weights_path } \\n { frozen_graph_struct_path } \" ) self . tensorflowNet = cv2 . dnn . readNetFromTensorflow ( frozen_graph_weights_path . as_posix (), frozen_graph_struct_path . as_posix () ) print ( \"OpenCVTensorflowObjectDetectionAgent initialized\" )","title":"__init__()"},{"location":"code_documentations/ROAR/agent_module/#ROAR.agent_module.opencv_tensorflow_object_detection_agent.OpenCVTensorflowObjectDetectionAgent.run_step","text":"Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/agent_module/opencv_tensorflow_object_detection_agent.py def run_step ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> VehicleControl : super ( OpenCVTensorflowObjectDetectionAgent , self ) . run_step ( sensors_data = sensors_data , vehicle = vehicle ) image = self . front_rgb_camera . data . copy () rows , cols , channels = image . shape # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Use the given image as input, which needs to be blob(s). self . tensorflowNet . setInput ( cv2 . dnn . blobFromImage ( image , size = ( 300 , 300 ), swapRB = True , crop = False )) # Runs a forward pass to compute the net output networkOutput = self . tensorflowNet . forward () # Loop on the outputs for detection in networkOutput [ 0 , 0 ]: score = float ( detection [ 2 ]) if score > 0.3 : left = detection [ 3 ] * cols top = detection [ 4 ] * rows right = detection [ 5 ] * cols bottom = detection [ 6 ] * rows area = ( right - left ) * ( bottom - top ) # draw a red rectangle around detected objects if area < 10000 : cv2 . rectangle ( image , ( int ( left ), int ( top )), ( int ( right ), int ( bottom )), ( 0 , 0 , 255 ), thickness = 2 ) self . logger . debug ( f \"Detection confirmed. Score = { score } \" ) # cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (0, 0, 255), thickness=2) # Show the image with a rectagle surrounding the detected objects cv2 . imshow ( 'Image' , image ) cv2 . waitKey ( 1 ) return VehicleControl ()","title":"run_step()"},{"location":"code_documentations/ROAR/agent_module/#ROAR.agent_module.pid_agent.PIDAgent","text":"","title":"PIDAgent"},{"location":"code_documentations/ROAR/agent_module/#ROAR.agent_module.pid_agent.PIDAgent.__init__","text":"Source code in ROAR/agent_module/pid_agent.py def __init__ ( self , target_speed = 40 , ** kwargs ): super () . __init__ ( ** kwargs ) self . target_speed = target_speed self . logger = logging . getLogger ( \"PID Agent\" ) self . route_file_path = Path ( self . agent_settings . waypoint_file_path ) self . pid_controller = PIDController ( agent = self , steering_boundary = ( - 1 , 1 ), throttle_boundary = ( - 1 , 1 )) self . mission_planner = WaypointFollowingMissionPlanner ( agent = self ) # initiated right after mission plan self . behavior_planner = BehaviorPlanner ( agent = self ) self . local_planner = SimpleWaypointFollowingLocalPlanner ( agent = self , controller = self . pid_controller , mission_planner = self . mission_planner , behavior_planner = self . behavior_planner , closeness_threshold = 1 ) self . logger . debug ( f \"Waypoint Following Agent Initiated. Reading f\" f \"rom { self . route_file_path . as_posix () } \" )","title":"__init__()"},{"location":"code_documentations/ROAR/agent_module/#ROAR.agent_module.pid_agent.PIDAgent.run_step","text":"Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/agent_module/pid_agent.py def run_step ( self , vehicle : Vehicle , sensors_data : SensorsData ) -> VehicleControl : super ( PIDAgent , self ) . run_step ( vehicle = vehicle , sensors_data = sensors_data ) self . transform_history . append ( self . vehicle . transform ) if self . local_planner . is_done (): control = VehicleControl () self . logger . debug ( \"Path Following Agent is Done. Idling.\" ) else : control = self . local_planner . run_in_series () return control","title":"run_step()"},{"location":"code_documentations/ROAR/agent_module/#ROAR.agent_module.pure_pursuit_agent.PurePursuitAgent","text":"","title":"PurePursuitAgent"},{"location":"code_documentations/ROAR/agent_module/#ROAR.agent_module.pure_pursuit_agent.PurePursuitAgent.__init__","text":"Source code in ROAR/agent_module/pure_pursuit_agent.py def __init__ ( self , vehicle : Vehicle , agent_settings : AgentConfig , target_speed = 50 ): super () . __init__ ( vehicle = vehicle , agent_settings = agent_settings ) self . route_file_path = Path ( self . agent_settings . waypoint_file_path ) self . pure_pursuit_controller = \\ PurePursuitController ( agent = self , target_speed = target_speed , look_ahead_gain = 0.1 , look_ahead_distance = 3 ) self . mission_planner = WaypointFollowingMissionPlanner ( agent = self ) # initiated right after mission plan self . behavior_planner = BehaviorPlanner ( agent = self ) self . local_planner = SimpleWaypointFollowingLocalPlanner ( agent = self , controller = self . pure_pursuit_controller , mission_planner = self . mission_planner , behavior_planner = self . behavior_planner , closeness_threshold = 3 )","title":"__init__()"},{"location":"code_documentations/ROAR/agent_module/#ROAR.agent_module.pure_pursuit_agent.PurePursuitAgent.run_step","text":"Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/agent_module/pure_pursuit_agent.py def run_step ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> VehicleControl : super ( PurePursuitAgent , self ) . run_step ( sensors_data = sensors_data , vehicle = vehicle ) vehicle_control = self . local_planner . run_in_series () return vehicle_control","title":"run_step()"},{"location":"code_documentations/ROAR/config/","text":"::: ROAR.configurations","title":"Config"},{"location":"code_documentations/ROAR/controller_module/","text":"controller \u00a4 Controller \u00a4 __init__ ( self , agent , ** kwargs ) special \u00a4 Source code in ROAR/control_module/controller.py def __init__ ( self , agent , ** kwargs ): super () . __init__ ( ** kwargs ) self . agent = agent self . logger = logging . getLogger ( \"Controller\" ) run_in_series ( self , next_waypoint , ** kwargs ) \u00a4 Abstract function for run step Parameters: Name Type Description Default next_waypoint Transform next waypoint required **kwargs {} Returns: Type Description VehicleControl VehicleControl Source code in ROAR/control_module/controller.py @abstractmethod def run_in_series ( self , next_waypoint : Transform , ** kwargs ) \\ -> VehicleControl : \"\"\" Abstract function for run step Args: next_waypoint: next waypoint **kwargs: Returns: VehicleControl \"\"\" return VehicleControl () run_in_threaded ( self , ** kwargs ) \u00a4 This is the threaded function. Parameters: Name Type Description Default **kwargs {} Source code in ROAR/control_module/controller.py def run_in_threaded ( self , ** kwargs ): pass mpc_controller \u00a4 VehicleMPCController \u00a4 __init__ ( self , agent , route_file_path , target_speed = inf , steps_ahead = 10 , max_throttle = 1 , max_steering = 1 , dt = 0.1 ) special \u00a4 Source code in ROAR/control_module/mpc_controller.py def __init__ ( self , agent : Agent , route_file_path : Path , # read in route target_speed = float ( \"inf\" ), steps_ahead = 10 , max_throttle = 1 , max_steering = 1 , dt = 0.1 ): super () . __init__ ( agent = agent ) self . logger = logging . getLogger ( __name__ ) # Read in route file self . track_DF = pd . read_csv ( route_file_path , header = None ) # Fit the route to a curve spline_points = 10000 self . pts_2D = self . track_DF . loc [:, [ 0 , 1 ]] . values tck , u = splprep ( self . pts_2D . T , u = None , s = 2.0 , per = 1 , k = 3 ) u_new = np . linspace ( u . min (), u . max (), spline_points ) x_new , y_new = splev ( u_new , tck , der = 0 ) self . pts_2D = np . c_ [ x_new , y_new ] # Modified parm self . prev_cte = 0 self . target_speed = target_speed self . state_vars = ( 'x' , 'y' , 'v' , '\u03c8' , 'cte' , 'e\u03c8' ) self . steps_ahead = steps_ahead self . dt = dt # Cost function coefficients self . cte_coeff = 100 # 100 self . epsi_coeff = 100 # 100 self . speed_coeff = 0.4 # 0.2 self . acc_coeff = 1 # 1 self . steer_coeff = 0.1 # 0.1 self . consec_acc_coeff = 50 self . consec_steer_coeff = 50 # Front wheel L self . Lf = 2.5 # How the polynomial fitting the desired curve is fitted self . steps_poly = 30 # modify to 3 when using 3D data self . poly_degree = 3 # Bounds for the optimizer self . bounds = ( 6 * self . steps_ahead * [( None , None )] + self . steps_ahead * [( 0 , max_throttle )] # throttle bounds + self . steps_ahead * [( - max_steering , max_steering )] # steer bounds ) # State 0 placeholder num_vars = ( len ( self . state_vars ) + 2 ) # State variables and two actuators self . state0 = np . zeros ( self . steps_ahead * num_vars ) # Lambdify and minimize stuff self . evaluator = 'numpy' self . tolerance = 1 self . cost_func , self . cost_grad_func , self . constr_funcs = \\ self . get_func_constraints_and_bounds () # To keep the previous state self . steer = 0 self . throttle = 0 self . logger . debug ( \"MPC Controller initiated\" ) clip_throttle ( throttle , curr_speed , target_speed ) staticmethod \u00a4 Source code in ROAR/control_module/mpc_controller.py @staticmethod def clip_throttle ( throttle , curr_speed , target_speed ): return np . clip ( throttle - 0.01 * ( curr_speed - target_speed ), 0.4 , 0.9 ) create_array_of_symbols ( str_symbol , N ) staticmethod \u00a4 Source code in ROAR/control_module/mpc_controller.py @staticmethod def create_array_of_symbols ( str_symbol , N ): return sym . symbols ( ' {symbol} 0: {N} ' . format ( symbol = str_symbol , N = N )) generate_fun ( self , symb_fun , vars_ , init , poly ) \u00a4 Generates a function of the form fun(x, *args) Source code in ROAR/control_module/mpc_controller.py def generate_fun ( self , symb_fun , vars_ , init , poly ): \"\"\" Generates a function of the form `fun(x, *args)` \"\"\" args = init + poly return sym . lambdify (( vars_ , * args ), symb_fun , self . evaluator ) generate_grad ( self , symb_fun , vars_ , init , poly ) \u00a4 TODO: add comments Source code in ROAR/control_module/mpc_controller.py def generate_grad ( self , symb_fun , vars_ , init , poly ): \"\"\" TODO: add comments \"\"\" args = init + poly return sym . lambdify ( ( vars_ , * args ), derive_by_array ( symb_fun , vars_ + args )[: len ( vars_ )], self . evaluator ) get_closest_waypoint_index_2D ( self , car_location , waypoint_location ) \u00a4 Get the index of the closest waypoint in self.pts_2D Note: it may give wrong index when the route is overlapped Source code in ROAR/control_module/mpc_controller.py def get_closest_waypoint_index_2D ( self , car_location , waypoint_location ): \"\"\"Get the index of the closest waypoint in self.pts_2D Note: it may give wrong index when the route is overlapped \"\"\" location_arr = np . array ([ car_location . x , car_location . y ]) dists = np . linalg . norm ( self . pts_2D - location_arr , axis = 1 ) return np . argmin ( dists ) get_closest_waypoint_index_3D ( self , car_location , waypoint_location ) \u00a4 Get the index of the closest waypoint in self.track_DF car_location: current car location waypoint_location: next_waypoint Source code in ROAR/control_module/mpc_controller.py def get_closest_waypoint_index_3D ( self , car_location , waypoint_location ): \"\"\"Get the index of the closest waypoint in self.track_DF car_location: current car location waypoint_location: next_waypoint \"\"\" index = self . track_DF . loc [( self . track_DF [ 0 ] == waypoint_location . x ) & ( self . track_DF [ 1 ] == waypoint_location . y )] . index if len ( index ) > 0 : return index [ 0 ] else : location_arr = np . array ([ car_location . x , car_location . y , car_location . z , ]) dists = np . linalg . norm ( self . track_DF - location_arr , axis = 1 ) return np . argmin ( dists ) get_func_constraints_and_bounds ( self ) \u00a4 Defines MPC's cost function and constraints. Source code in ROAR/control_module/mpc_controller.py def get_func_constraints_and_bounds ( self ): \"\"\" Defines MPC's cost function and constraints. \"\"\" # Polynomial coefficients will also be symbolic variables poly = self . create_array_of_symbols ( 'poly' , self . poly_degree + 1 ) # Initialize the initial state x_init = sym . symbols ( 'x_init' ) y_init = sym . symbols ( 'y_init' ) \u03c8_init = sym . symbols ( '\u03c8_init' ) v_init = sym . symbols ( 'v_init' ) cte_init = sym . symbols ( 'cte_init' ) e\u03c8_init = sym . symbols ( 'e\u03c8_init' ) init = ( x_init , y_init , \u03c8_init , v_init , cte_init , e\u03c8_init ) # State variables x = self . create_array_of_symbols ( 'x' , self . steps_ahead ) y = self . create_array_of_symbols ( 'y' , self . steps_ahead ) \u03c8 = self . create_array_of_symbols ( '\u03c8' , self . steps_ahead ) v = self . create_array_of_symbols ( 'v' , self . steps_ahead ) cte = self . create_array_of_symbols ( 'cte' , self . steps_ahead ) e\u03c8 = self . create_array_of_symbols ( 'e\u03c8' , self . steps_ahead ) # Actuators a = self . create_array_of_symbols ( 'a' , self . steps_ahead ) \u03b4 = self . create_array_of_symbols ( '\u03b4' , self . steps_ahead ) vars_ = ( # Symbolic arrays (but NOT actuators) * x , * y , * \u03c8 , * v , * cte , * e\u03c8 , # Symbolic arrays (actuators) * a , * \u03b4 , ) cost = 0 for t in range ( self . steps_ahead ): cost += ( # Reference state penalties self . cte_coeff * cte [ t ] ** 2 + self . epsi_coeff * e\u03c8 [ t ] ** 2 + + self . speed_coeff * ( v [ t ] - self . target_speed ) ** 2 # Actuator penalties + self . acc_coeff * a [ t ] ** 2 + self . steer_coeff * \u03b4 [ t ] ** 2 ) # Penalty for differences in consecutive actuators for t in range ( self . steps_ahead - 1 ): cost += ( self . consec_acc_coeff * ( a [ t + 1 ] - a [ t ]) ** 2 + self . consec_steer_coeff * ( \u03b4 [ t + 1 ] - \u03b4 [ t ]) ** 2 ) # Initialize constraints eq_constr = _EqualityConstraints ( self . steps_ahead , self . state_vars ) eq_constr [ 'x' ][ 0 ] = x [ 0 ] - x_init eq_constr [ 'y' ][ 0 ] = y [ 0 ] - y_init eq_constr [ '\u03c8' ][ 0 ] = \u03c8 [ 0 ] - \u03c8_init eq_constr [ 'v' ][ 0 ] = v [ 0 ] - v_init eq_constr [ 'cte' ][ 0 ] = cte [ 0 ] - cte_init eq_constr [ 'e\u03c8' ][ 0 ] = e\u03c8 [ 0 ] - e\u03c8_init for t in range ( 1 , self . steps_ahead ): curve = sum ( poly [ - ( i + 1 )] * x [ t - 1 ] ** i for i in range ( len ( poly ))) # The desired \u03c8 is equal to the derivative of the polynomial # curve at # point x[t-1] \u03c8des = sum ( poly [ - ( i + 1 )] * i * x [ t - 1 ] ** ( i - 1 ) for i in range ( 1 , len ( poly ))) eq_constr [ 'x' ][ t ] = x [ t ] - ( x [ t - 1 ] + v [ t - 1 ] * sym . cos ( \u03c8 [ t - 1 ]) * self . dt ) eq_constr [ 'y' ][ t ] = y [ t ] - ( y [ t - 1 ] + v [ t - 1 ] * sym . sin ( \u03c8 [ t - 1 ]) * self . dt ) eq_constr [ '\u03c8' ][ t ] = \u03c8 [ t ] - ( \u03c8 [ t - 1 ] - v [ t - 1 ] * \u03b4 [ t - 1 ] / self . Lf * self . dt ) eq_constr [ 'v' ][ t ] = v [ t ] - ( v [ t - 1 ] + a [ t - 1 ] * self . dt ) eq_constr [ 'cte' ][ t ] = cte [ t ] - ( curve - y [ t - 1 ] + v [ t - 1 ] * sym . sin ( e\u03c8 [ t - 1 ]) * self . dt ) eq_constr [ 'e\u03c8' ][ t ] = e\u03c8 [ t ] - ( \u03c8 [ t - 1 ] - \u03c8des - v [ t - 1 ] * \u03b4 [ t - 1 ] / self . Lf * self . dt ) # Generate actual functions from cost_func = self . generate_fun ( cost , vars_ , init , poly ) cost_grad_func = self . generate_grad ( cost , vars_ , init , poly ) constr_funcs = [] for symbol in self . state_vars : for t in range ( self . steps_ahead ): func = self . generate_fun ( eq_constr [ symbol ][ t ], vars_ , init , poly ) grad_func = self . generate_grad ( eq_constr [ symbol ][ t ], vars_ , init , poly ) constr_funcs . append ( { 'type' : 'eq' , 'fun' : func , 'jac' : grad_func , 'args' : None }, ) return cost_func , cost_grad_func , constr_funcs get_state0 ( self , v , cte , epsi , a , delta , poly ) \u00a4 Source code in ROAR/control_module/mpc_controller.py def get_state0 ( self , v , cte , epsi , a , delta , poly ): a = a or 0 delta = delta or 0 x = np . linspace ( 0 , 1 , self . steps_ahead ) y = np . polyval ( poly , x ) psi = 0 self . state0 [: self . steps_ahead ] = x self . state0 [ self . steps_ahead : 2 * self . steps_ahead ] = y self . state0 [ 2 * self . steps_ahead : 3 * self . steps_ahead ] = psi self . state0 [ 3 * self . steps_ahead : 4 * self . steps_ahead ] = v self . state0 [ 4 * self . steps_ahead : 5 * self . steps_ahead ] = cte self . state0 [ 5 * self . steps_ahead : 6 * self . steps_ahead ] = epsi self . state0 [ 6 * self . steps_ahead : 7 * self . steps_ahead ] = a self . state0 [ 7 * self . steps_ahead : 8 * self . steps_ahead ] = delta return self . state0 minimize_cost ( self , bounds , x0 , init ) \u00a4 Source code in ROAR/control_module/mpc_controller.py def minimize_cost ( self , bounds , x0 , init ): for constr_func in self . constr_funcs : constr_func [ 'args' ] = init return minimize ( fun = self . cost_func , x0 = x0 , args = init , jac = self . cost_grad_func , bounds = bounds , constraints = self . constr_funcs , method = 'SLSQP' , tol = self . tolerance , ) run_in_series ( self , next_waypoint ) \u00a4 Abstract function for run step Parameters: Name Type Description Default next_waypoint Transform next waypoint required **kwargs required Returns: Type Description VehicleControl VehicleControl Source code in ROAR/control_module/mpc_controller.py def run_in_series ( self , next_waypoint : Transform ) -> VehicleControl : super ( VehicleMPCController , self ) . run_in_series ( next_waypoint ) # get vehicle location (x, y) # location = self.vehicle.transform.location location = self . agent . vehicle . transform . location x , y = location . x , location . y # get vehicle rotation # rotation = self.vehicle.transform.rotation rotation = self . agent . vehicle . transform . rotation \u03c8 = rotation . yaw / 180 * np . pi # transform into radient cos_\u03c8 = np . cos ( \u03c8 ) sin_\u03c8 = np . sin ( \u03c8 ) # get vehicle speed # v = Vehicle.get_speed(self.vehicle) v = Vehicle . get_speed ( self . agent . vehicle ) # get next waypoint location wx , wy = next_waypoint . location . x , next_waypoint . location . y # debug logging # self.logger.debug(f\"car location: ({x}, {y})\") # self.logger.debug(f\"car \u03c8: {\u03c8}\") # self.logger.debug(f\"car speed: {v}\") # self.logger.debug(f\"next waypoint: ({wx}, {wy})\") ### 3D ### # get the index of next waypoint # waypoint_index = self.get_closest_waypoint_index_3D(location, # next_waypoint.location) # # find more waypoints index to fit a polynomial # waypoint_index_shifted = waypoint_index - 2 # indeces = waypoint_index_shifted + self.steps_poly * np.arange( # self.poly_degree + 1) # indeces = indeces % self.track_DF.shape[0] # # get waypoints for polynomial fitting # pts = np.array([[self.track_DF.iloc[i][0], self.track_DF.iloc[i][ # 1]] for i in indeces]) ### 2D ### index_2D = self . get_closest_waypoint_index_2D ( location , next_waypoint . location ) index_2D_shifted = index_2D - 5 indeces_2D = index_2D_shifted + self . steps_poly * np . arange ( self . poly_degree + 1 ) indeces_2D = indeces_2D % self . pts_2D . shape [ 0 ] pts = self . pts_2D [ indeces_2D ] # self.logger.debug(f'\\nwaypoint index:\\n {index_2D}') # self.logger.debug(f'\\nindeces:\\n {indeces_2D}') # transform waypoints from world to car coorinate pts_car = VehicleMPCController . transform_into_cars_coordinate_system ( pts , x , y , cos_\u03c8 , sin_\u03c8 ) # fit the polynomial poly = np . polyfit ( pts_car [:, 0 ], pts_car [:, 1 ], self . poly_degree ) # Debug # self.logger.debug(f'\\nwaypoint index:\\n {waypoint_index}') # self.logger.debug(f'\\nindeces:\\n {indeces}') # self.logger.debug(f'\\npts for poly_fit:\\n {pts}') # self.logger.debug(f'\\npts_car:\\n {pts_car}') ########### cte = poly [ - 1 ] e\u03c8 = - np . arctan ( poly [ - 2 ]) init = ( 0 , 0 , 0 , v , cte , e\u03c8 , * poly ) self . state0 = self . get_state0 ( v , cte , e\u03c8 , self . steer , self . throttle , poly ) result = self . minimize_cost ( self . bounds , self . state0 , init ) # self.steer = -0.6 * cte - 5.5 * (cte - self.prev_cte) # self.prev_cte = cte # self.throttle = VehicleMPCController.clip_throttle(self.throttle, # v, self.target_speed) control = VehicleControl () if 'success' in result . message : self . steer = result . x [ - self . steps_ahead ] self . throttle = result . x [ - 2 * self . steps_ahead ] else : self . logger . debug ( 'Unsuccessful optimization' ) control . steering = self . steer control . throttle = self . throttle return control transform_into_cars_coordinate_system ( pts , x , y , cos_\u03c8 , sin_\u03c8 ) staticmethod \u00a4 Source code in ROAR/control_module/mpc_controller.py @staticmethod def transform_into_cars_coordinate_system ( pts , x , y , cos_\u03c8 , sin_\u03c8 ): diff = ( pts - [ x , y ]) pts_car = np . zeros_like ( diff ) pts_car [:, 0 ] = cos_\u03c8 * diff [:, 0 ] + sin_\u03c8 * diff [:, 1 ] pts_car [:, 1 ] = sin_\u03c8 * diff [:, 0 ] - cos_\u03c8 * diff [:, 1 ] return pts_car pid_controller \u00a4 LatPIDController \u00a4 __init__ ( self , agent , config , steering_boundary , dt = 0.03 , ** kwargs ) special \u00a4 Source code in ROAR/control_module/pid_controller.py def __init__ ( self , agent , config : dict , steering_boundary : Tuple [ float , float ], dt : float = 0.03 , ** kwargs ): super () . __init__ ( agent , ** kwargs ) self . config = config self . steering_boundary = steering_boundary self . _error_buffer = deque ( maxlen = 10 ) self . _dt = dt run_in_series ( self , next_waypoint , ** kwargs ) \u00a4 Calculates a vector that represent where you are going. Parameters: Name Type Description Default next_waypoint Transform required **kwargs {} Returns: Type Description float lat_control Source code in ROAR/control_module/pid_controller.py def run_in_series ( self , next_waypoint : Transform , ** kwargs ) -> float : \"\"\" Calculates a vector that represent where you are going. Args: next_waypoint (): **kwargs (): Returns: lat_control \"\"\" # calculate a vector that represent where you are going v_begin = self . agent . vehicle . transform . location v_end = v_begin + Location ( x = math . cos ( math . radians ( self . agent . vehicle . transform . rotation . pitch )), y = v_begin . y , z = math . sin ( math . radians ( self . agent . vehicle . transform . rotation . pitch )), ) v_vec = np . array ([ v_end . x - v_begin . x , v_end . y - v_begin . y , v_end . z - v_begin . z ]) # calculate error projection w_vec = np . array ( [ next_waypoint . location . x - v_begin . x , next_waypoint . location . y - v_begin . y , next_waypoint . location . z - v_begin . z , ] ) _dot = math . acos ( np . clip ( np . dot ( w_vec , v_vec ) / ( np . linalg . norm ( w_vec ) * np . linalg . norm ( v_vec )), - 1.0 , 1.0 , ) ) _cross = np . cross ( v_vec , w_vec ) if _cross [ 1 ] > 0 : _dot *= - 1.0 self . _error_buffer . append ( _dot ) if len ( self . _error_buffer ) >= 2 : _de = ( self . _error_buffer [ - 1 ] - self . _error_buffer [ - 2 ]) / self . _dt _ie = sum ( self . _error_buffer ) * self . _dt else : _de = 0.0 _ie = 0.0 k_p , k_d , k_i = PIDController . find_k_values ( config = self . config , vehicle = self . agent . vehicle ) lat_control = float ( np . clip (( k_p * _dot ) + ( k_d * _de ) + ( k_i * _ie ), self . steering_boundary [ 0 ], self . steering_boundary [ 1 ]) ) return lat_control LongPIDController \u00a4 __init__ ( self , agent , config , throttle_boundary , max_speed , dt = 0.03 , ** kwargs ) special \u00a4 Source code in ROAR/control_module/pid_controller.py def __init__ ( self , agent , config : dict , throttle_boundary : Tuple [ float , float ], max_speed : float , dt : float = 0.03 , ** kwargs ): super () . __init__ ( agent , ** kwargs ) self . config = config self . max_speed = max_speed self . throttle_boundary = throttle_boundary self . _error_buffer = deque ( maxlen = 10 ) self . _dt = dt run_in_series ( self , next_waypoint , ** kwargs ) \u00a4 Abstract function for run step Parameters: Name Type Description Default next_waypoint Transform next waypoint required **kwargs {} Returns: Type Description float VehicleControl Source code in ROAR/control_module/pid_controller.py def run_in_series ( self , next_waypoint : Transform , ** kwargs ) -> float : target_speed = min ( self . max_speed , kwargs . get ( \"target_speed\" , self . max_speed )) current_speed = Vehicle . get_speed ( self . agent . vehicle ) k_p , k_d , k_i = PIDController . find_k_values ( vehicle = self . agent . vehicle , config = self . config ) error = target_speed - current_speed self . _error_buffer . append ( error ) if len ( self . _error_buffer ) >= 2 : # print(self._error_buffer[-1], self._error_buffer[-2]) _de = ( self . _error_buffer [ - 2 ] - self . _error_buffer [ - 1 ]) / self . _dt _ie = sum ( self . _error_buffer ) * self . _dt else : _de = 0.0 _ie = 0.0 output = float ( np . clip (( k_p * error ) + ( k_d * _de ) + ( k_i * _ie ), self . throttle_boundary [ 0 ], self . throttle_boundary [ 1 ])) # self.logger.debug(f\"curr_speed: {round(current_speed, 2)} | kp: {round(k_p, 2)} | kd: {k_d} | ki = {k_i} | \" # f\"err = {round(error, 2)} | de = {round(_de, 2)} | ie = {round(_ie, 2)}\") #f\"self._error_buffer[-1] {self._error_buffer[-1]} | self._error_buffer[-2] = {self._error_buffer[-2]}\") return output PIDController \u00a4 __init__ ( self , agent , steering_boundary , throttle_boundary , ** kwargs ) special \u00a4 Source code in ROAR/control_module/pid_controller.py def __init__ ( self , agent , steering_boundary : Tuple [ float , float ], throttle_boundary : Tuple [ float , float ], ** kwargs ): super () . __init__ ( agent , ** kwargs ) self . max_speed = self . agent . agent_settings . max_speed self . throttle_boundary = throttle_boundary self . steering_boundary = steering_boundary self . config = json . load ( Path ( agent . agent_settings . pid_config_file_path ) . open ( mode = 'r' )) self . long_pid_controller = LongPIDController ( agent = agent , throttle_boundary = throttle_boundary , max_speed = self . max_speed , config = self . config [ \"longitudinal_controller\" ]) self . lat_pid_controller = LatPIDController ( agent = agent , config = self . config [ \"latitudinal_controller\" ], steering_boundary = steering_boundary ) self . logger = logging . getLogger ( __name__ ) find_k_values ( vehicle , config ) staticmethod \u00a4 Source code in ROAR/control_module/pid_controller.py @staticmethod def find_k_values ( vehicle : Vehicle , config : dict ) -> np . array : current_speed = Vehicle . get_speed ( vehicle = vehicle ) k_p , k_d , k_i = 1 , 0 , 0 for speed_upper_bound , kvalues in config . items (): speed_upper_bound = float ( speed_upper_bound ) if current_speed < speed_upper_bound : k_p , k_d , k_i = kvalues [ \"Kp\" ], kvalues [ \"Kd\" ], kvalues [ \"Ki\" ] break return np . clip ([ k_p , k_d , k_i ], a_min = 0 , a_max = 1 ) run_in_series ( self , next_waypoint , ** kwargs ) \u00a4 Abstract function for run step Parameters: Name Type Description Default next_waypoint Transform next waypoint required **kwargs {} Returns: Type Description VehicleControl VehicleControl Source code in ROAR/control_module/pid_controller.py def run_in_series ( self , next_waypoint : Transform , ** kwargs ) -> VehicleControl : throttle = self . long_pid_controller . run_in_series ( next_waypoint = next_waypoint , target_speed = kwargs . get ( \"target_speed\" , self . max_speed )) steering = self . lat_pid_controller . run_in_series ( next_waypoint = next_waypoint ) return VehicleControl ( throttle = throttle , steering = steering ) pure_pursuit_control \u00a4 LatitunalPurePursuitController \u00a4 __init__ ( self , agent , look_ahead_gain , look_ahead_distance ) special \u00a4 Source code in ROAR/control_module/pure_pursuit_control.py def __init__ ( self , agent : Agent , look_ahead_gain : float , look_ahead_distance : float ): self . agent = agent self . look_ahead_gain = look_ahead_gain self . look_ahead_distance = look_ahead_distance run_step ( self , next_waypoint ) \u00a4 Parameters: Name Type Description Default next_waypoint Transform required Returns: Type Description float VehicleControl.clamp Source code in ROAR/control_module/pure_pursuit_control.py def run_step ( self , next_waypoint : Transform ) -> float : \"\"\" Args: next_waypoint (): Returns: VehicleControl.clamp \"\"\" target_z = next_waypoint . location . z target_x = next_waypoint . location . x angle_difference = math . atan2 ( target_z - self . agent . vehicle . transform . location . z , target_x - self . agent . vehicle . transform . location . x ) - np . radians ( self . agent . vehicle . transform . rotation . pitch ) curr_look_forward = ( self . look_ahead_gain * Vehicle . get_speed ( vehicle = self . agent . vehicle ) + self . look_ahead_distance ) lateral_difference = math . atan2 ( 2.0 * self . agent . vehicle . wheel_base * math . sin ( angle_difference ) / curr_look_forward , 1.0 , ) return VehicleControl . clamp ( lateral_difference , - 1 , 1 ) LongitunalPurePursuitController \u00a4 __init__ ( self , agent , target_speed = 60 , kp = 0.1 ) special \u00a4 Source code in ROAR/control_module/pure_pursuit_control.py def __init__ ( self , agent : Agent , target_speed = 60 , kp = 0.1 ): self . agent = agent self . target_speed = target_speed self . kp = kp run_step ( self ) \u00a4 Source code in ROAR/control_module/pure_pursuit_control.py def run_step ( self ) -> float : return float ( VehicleControl . clamp ( self . kp * ( self . target_speed - Vehicle . get_speed ( self . agent . vehicle )), 0 , 1 ) ) PurePursuitController \u00a4 __init__ ( self , agent , look_ahead_gain = 0.1 , look_ahead_distance = 2 , target_speed = 60 ) special \u00a4 Parameters: Name Type Description Default vehicle Vehicle information required look_ahead_gain float Look ahead factor 0.1 look_ahead_distance float look ahead distance 2 target_speed desired longitudinal speed to maintain 60 Source code in ROAR/control_module/pure_pursuit_control.py def __init__ ( self , agent : Agent , look_ahead_gain : float = 0.1 , look_ahead_distance : float = 2 , target_speed = 60 , ): \"\"\" Args: vehicle: Vehicle information look_ahead_gain: Look ahead factor look_ahead_distance: look ahead distance target_speed: desired longitudinal speed to maintain \"\"\" super ( PurePursuitController , self ) . __init__ ( agent = agent ) self . target_speed = self . agent . agent_settings . max_speed \\ if self . agent . agent_settings . max_speed else target_speed self . look_ahead_gain = look_ahead_gain self . look_ahead_distance = look_ahead_distance self . latitunal_controller = LatitunalPurePursuitController ( agent = self . agent , look_ahead_gain = look_ahead_gain , look_ahead_distance = look_ahead_distance , ) self . longitunal_controller = LongitunalPurePursuitController ( agent = self . agent , target_speed = target_speed ) run_in_series ( self , next_waypoint , ** kwargs ) \u00a4 run one step of Pure Pursuit Control Parameters: Name Type Description Default vehicle current vehicle state required next_waypoint Transform Next waypoint, Transform required **kwargs {} Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/control_module/pure_pursuit_control.py def run_in_series ( self , next_waypoint : Transform , ** kwargs ) -> VehicleControl : \"\"\" run one step of Pure Pursuit Control Args: vehicle: current vehicle state next_waypoint: Next waypoint, Transform **kwargs: Returns: Vehicle Control \"\"\" control = VehicleControl ( throttle = self . longitunal_controller . run_step (), steering = self . latitunal_controller . run_step ( next_waypoint = next_waypoint ), ) return control","title":"Control Module"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.controller","text":"","title":"controller"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.controller.Controller","text":"","title":"Controller"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.controller.Controller.__init__","text":"Source code in ROAR/control_module/controller.py def __init__ ( self , agent , ** kwargs ): super () . __init__ ( ** kwargs ) self . agent = agent self . logger = logging . getLogger ( \"Controller\" )","title":"__init__()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.controller.Controller.run_in_series","text":"Abstract function for run step Parameters: Name Type Description Default next_waypoint Transform next waypoint required **kwargs {} Returns: Type Description VehicleControl VehicleControl Source code in ROAR/control_module/controller.py @abstractmethod def run_in_series ( self , next_waypoint : Transform , ** kwargs ) \\ -> VehicleControl : \"\"\" Abstract function for run step Args: next_waypoint: next waypoint **kwargs: Returns: VehicleControl \"\"\" return VehicleControl ()","title":"run_in_series()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.controller.Controller.run_in_threaded","text":"This is the threaded function. Parameters: Name Type Description Default **kwargs {} Source code in ROAR/control_module/controller.py def run_in_threaded ( self , ** kwargs ): pass","title":"run_in_threaded()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller","text":"","title":"mpc_controller"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController","text":"","title":"VehicleMPCController"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController.__init__","text":"Source code in ROAR/control_module/mpc_controller.py def __init__ ( self , agent : Agent , route_file_path : Path , # read in route target_speed = float ( \"inf\" ), steps_ahead = 10 , max_throttle = 1 , max_steering = 1 , dt = 0.1 ): super () . __init__ ( agent = agent ) self . logger = logging . getLogger ( __name__ ) # Read in route file self . track_DF = pd . read_csv ( route_file_path , header = None ) # Fit the route to a curve spline_points = 10000 self . pts_2D = self . track_DF . loc [:, [ 0 , 1 ]] . values tck , u = splprep ( self . pts_2D . T , u = None , s = 2.0 , per = 1 , k = 3 ) u_new = np . linspace ( u . min (), u . max (), spline_points ) x_new , y_new = splev ( u_new , tck , der = 0 ) self . pts_2D = np . c_ [ x_new , y_new ] # Modified parm self . prev_cte = 0 self . target_speed = target_speed self . state_vars = ( 'x' , 'y' , 'v' , '\u03c8' , 'cte' , 'e\u03c8' ) self . steps_ahead = steps_ahead self . dt = dt # Cost function coefficients self . cte_coeff = 100 # 100 self . epsi_coeff = 100 # 100 self . speed_coeff = 0.4 # 0.2 self . acc_coeff = 1 # 1 self . steer_coeff = 0.1 # 0.1 self . consec_acc_coeff = 50 self . consec_steer_coeff = 50 # Front wheel L self . Lf = 2.5 # How the polynomial fitting the desired curve is fitted self . steps_poly = 30 # modify to 3 when using 3D data self . poly_degree = 3 # Bounds for the optimizer self . bounds = ( 6 * self . steps_ahead * [( None , None )] + self . steps_ahead * [( 0 , max_throttle )] # throttle bounds + self . steps_ahead * [( - max_steering , max_steering )] # steer bounds ) # State 0 placeholder num_vars = ( len ( self . state_vars ) + 2 ) # State variables and two actuators self . state0 = np . zeros ( self . steps_ahead * num_vars ) # Lambdify and minimize stuff self . evaluator = 'numpy' self . tolerance = 1 self . cost_func , self . cost_grad_func , self . constr_funcs = \\ self . get_func_constraints_and_bounds () # To keep the previous state self . steer = 0 self . throttle = 0 self . logger . debug ( \"MPC Controller initiated\" )","title":"__init__()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController.clip_throttle","text":"Source code in ROAR/control_module/mpc_controller.py @staticmethod def clip_throttle ( throttle , curr_speed , target_speed ): return np . clip ( throttle - 0.01 * ( curr_speed - target_speed ), 0.4 , 0.9 )","title":"clip_throttle()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController.create_array_of_symbols","text":"Source code in ROAR/control_module/mpc_controller.py @staticmethod def create_array_of_symbols ( str_symbol , N ): return sym . symbols ( ' {symbol} 0: {N} ' . format ( symbol = str_symbol , N = N ))","title":"create_array_of_symbols()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController.generate_fun","text":"Generates a function of the form fun(x, *args) Source code in ROAR/control_module/mpc_controller.py def generate_fun ( self , symb_fun , vars_ , init , poly ): \"\"\" Generates a function of the form `fun(x, *args)` \"\"\" args = init + poly return sym . lambdify (( vars_ , * args ), symb_fun , self . evaluator )","title":"generate_fun()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController.generate_grad","text":"TODO: add comments Source code in ROAR/control_module/mpc_controller.py def generate_grad ( self , symb_fun , vars_ , init , poly ): \"\"\" TODO: add comments \"\"\" args = init + poly return sym . lambdify ( ( vars_ , * args ), derive_by_array ( symb_fun , vars_ + args )[: len ( vars_ )], self . evaluator )","title":"generate_grad()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController.get_closest_waypoint_index_2D","text":"Get the index of the closest waypoint in self.pts_2D Note: it may give wrong index when the route is overlapped Source code in ROAR/control_module/mpc_controller.py def get_closest_waypoint_index_2D ( self , car_location , waypoint_location ): \"\"\"Get the index of the closest waypoint in self.pts_2D Note: it may give wrong index when the route is overlapped \"\"\" location_arr = np . array ([ car_location . x , car_location . y ]) dists = np . linalg . norm ( self . pts_2D - location_arr , axis = 1 ) return np . argmin ( dists )","title":"get_closest_waypoint_index_2D()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController.get_closest_waypoint_index_3D","text":"Get the index of the closest waypoint in self.track_DF car_location: current car location waypoint_location: next_waypoint Source code in ROAR/control_module/mpc_controller.py def get_closest_waypoint_index_3D ( self , car_location , waypoint_location ): \"\"\"Get the index of the closest waypoint in self.track_DF car_location: current car location waypoint_location: next_waypoint \"\"\" index = self . track_DF . loc [( self . track_DF [ 0 ] == waypoint_location . x ) & ( self . track_DF [ 1 ] == waypoint_location . y )] . index if len ( index ) > 0 : return index [ 0 ] else : location_arr = np . array ([ car_location . x , car_location . y , car_location . z , ]) dists = np . linalg . norm ( self . track_DF - location_arr , axis = 1 ) return np . argmin ( dists )","title":"get_closest_waypoint_index_3D()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController.get_func_constraints_and_bounds","text":"Defines MPC's cost function and constraints. Source code in ROAR/control_module/mpc_controller.py def get_func_constraints_and_bounds ( self ): \"\"\" Defines MPC's cost function and constraints. \"\"\" # Polynomial coefficients will also be symbolic variables poly = self . create_array_of_symbols ( 'poly' , self . poly_degree + 1 ) # Initialize the initial state x_init = sym . symbols ( 'x_init' ) y_init = sym . symbols ( 'y_init' ) \u03c8_init = sym . symbols ( '\u03c8_init' ) v_init = sym . symbols ( 'v_init' ) cte_init = sym . symbols ( 'cte_init' ) e\u03c8_init = sym . symbols ( 'e\u03c8_init' ) init = ( x_init , y_init , \u03c8_init , v_init , cte_init , e\u03c8_init ) # State variables x = self . create_array_of_symbols ( 'x' , self . steps_ahead ) y = self . create_array_of_symbols ( 'y' , self . steps_ahead ) \u03c8 = self . create_array_of_symbols ( '\u03c8' , self . steps_ahead ) v = self . create_array_of_symbols ( 'v' , self . steps_ahead ) cte = self . create_array_of_symbols ( 'cte' , self . steps_ahead ) e\u03c8 = self . create_array_of_symbols ( 'e\u03c8' , self . steps_ahead ) # Actuators a = self . create_array_of_symbols ( 'a' , self . steps_ahead ) \u03b4 = self . create_array_of_symbols ( '\u03b4' , self . steps_ahead ) vars_ = ( # Symbolic arrays (but NOT actuators) * x , * y , * \u03c8 , * v , * cte , * e\u03c8 , # Symbolic arrays (actuators) * a , * \u03b4 , ) cost = 0 for t in range ( self . steps_ahead ): cost += ( # Reference state penalties self . cte_coeff * cte [ t ] ** 2 + self . epsi_coeff * e\u03c8 [ t ] ** 2 + + self . speed_coeff * ( v [ t ] - self . target_speed ) ** 2 # Actuator penalties + self . acc_coeff * a [ t ] ** 2 + self . steer_coeff * \u03b4 [ t ] ** 2 ) # Penalty for differences in consecutive actuators for t in range ( self . steps_ahead - 1 ): cost += ( self . consec_acc_coeff * ( a [ t + 1 ] - a [ t ]) ** 2 + self . consec_steer_coeff * ( \u03b4 [ t + 1 ] - \u03b4 [ t ]) ** 2 ) # Initialize constraints eq_constr = _EqualityConstraints ( self . steps_ahead , self . state_vars ) eq_constr [ 'x' ][ 0 ] = x [ 0 ] - x_init eq_constr [ 'y' ][ 0 ] = y [ 0 ] - y_init eq_constr [ '\u03c8' ][ 0 ] = \u03c8 [ 0 ] - \u03c8_init eq_constr [ 'v' ][ 0 ] = v [ 0 ] - v_init eq_constr [ 'cte' ][ 0 ] = cte [ 0 ] - cte_init eq_constr [ 'e\u03c8' ][ 0 ] = e\u03c8 [ 0 ] - e\u03c8_init for t in range ( 1 , self . steps_ahead ): curve = sum ( poly [ - ( i + 1 )] * x [ t - 1 ] ** i for i in range ( len ( poly ))) # The desired \u03c8 is equal to the derivative of the polynomial # curve at # point x[t-1] \u03c8des = sum ( poly [ - ( i + 1 )] * i * x [ t - 1 ] ** ( i - 1 ) for i in range ( 1 , len ( poly ))) eq_constr [ 'x' ][ t ] = x [ t ] - ( x [ t - 1 ] + v [ t - 1 ] * sym . cos ( \u03c8 [ t - 1 ]) * self . dt ) eq_constr [ 'y' ][ t ] = y [ t ] - ( y [ t - 1 ] + v [ t - 1 ] * sym . sin ( \u03c8 [ t - 1 ]) * self . dt ) eq_constr [ '\u03c8' ][ t ] = \u03c8 [ t ] - ( \u03c8 [ t - 1 ] - v [ t - 1 ] * \u03b4 [ t - 1 ] / self . Lf * self . dt ) eq_constr [ 'v' ][ t ] = v [ t ] - ( v [ t - 1 ] + a [ t - 1 ] * self . dt ) eq_constr [ 'cte' ][ t ] = cte [ t ] - ( curve - y [ t - 1 ] + v [ t - 1 ] * sym . sin ( e\u03c8 [ t - 1 ]) * self . dt ) eq_constr [ 'e\u03c8' ][ t ] = e\u03c8 [ t ] - ( \u03c8 [ t - 1 ] - \u03c8des - v [ t - 1 ] * \u03b4 [ t - 1 ] / self . Lf * self . dt ) # Generate actual functions from cost_func = self . generate_fun ( cost , vars_ , init , poly ) cost_grad_func = self . generate_grad ( cost , vars_ , init , poly ) constr_funcs = [] for symbol in self . state_vars : for t in range ( self . steps_ahead ): func = self . generate_fun ( eq_constr [ symbol ][ t ], vars_ , init , poly ) grad_func = self . generate_grad ( eq_constr [ symbol ][ t ], vars_ , init , poly ) constr_funcs . append ( { 'type' : 'eq' , 'fun' : func , 'jac' : grad_func , 'args' : None }, ) return cost_func , cost_grad_func , constr_funcs","title":"get_func_constraints_and_bounds()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController.get_state0","text":"Source code in ROAR/control_module/mpc_controller.py def get_state0 ( self , v , cte , epsi , a , delta , poly ): a = a or 0 delta = delta or 0 x = np . linspace ( 0 , 1 , self . steps_ahead ) y = np . polyval ( poly , x ) psi = 0 self . state0 [: self . steps_ahead ] = x self . state0 [ self . steps_ahead : 2 * self . steps_ahead ] = y self . state0 [ 2 * self . steps_ahead : 3 * self . steps_ahead ] = psi self . state0 [ 3 * self . steps_ahead : 4 * self . steps_ahead ] = v self . state0 [ 4 * self . steps_ahead : 5 * self . steps_ahead ] = cte self . state0 [ 5 * self . steps_ahead : 6 * self . steps_ahead ] = epsi self . state0 [ 6 * self . steps_ahead : 7 * self . steps_ahead ] = a self . state0 [ 7 * self . steps_ahead : 8 * self . steps_ahead ] = delta return self . state0","title":"get_state0()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController.minimize_cost","text":"Source code in ROAR/control_module/mpc_controller.py def minimize_cost ( self , bounds , x0 , init ): for constr_func in self . constr_funcs : constr_func [ 'args' ] = init return minimize ( fun = self . cost_func , x0 = x0 , args = init , jac = self . cost_grad_func , bounds = bounds , constraints = self . constr_funcs , method = 'SLSQP' , tol = self . tolerance , )","title":"minimize_cost()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController.run_in_series","text":"Abstract function for run step Parameters: Name Type Description Default next_waypoint Transform next waypoint required **kwargs required Returns: Type Description VehicleControl VehicleControl Source code in ROAR/control_module/mpc_controller.py def run_in_series ( self , next_waypoint : Transform ) -> VehicleControl : super ( VehicleMPCController , self ) . run_in_series ( next_waypoint ) # get vehicle location (x, y) # location = self.vehicle.transform.location location = self . agent . vehicle . transform . location x , y = location . x , location . y # get vehicle rotation # rotation = self.vehicle.transform.rotation rotation = self . agent . vehicle . transform . rotation \u03c8 = rotation . yaw / 180 * np . pi # transform into radient cos_\u03c8 = np . cos ( \u03c8 ) sin_\u03c8 = np . sin ( \u03c8 ) # get vehicle speed # v = Vehicle.get_speed(self.vehicle) v = Vehicle . get_speed ( self . agent . vehicle ) # get next waypoint location wx , wy = next_waypoint . location . x , next_waypoint . location . y # debug logging # self.logger.debug(f\"car location: ({x}, {y})\") # self.logger.debug(f\"car \u03c8: {\u03c8}\") # self.logger.debug(f\"car speed: {v}\") # self.logger.debug(f\"next waypoint: ({wx}, {wy})\") ### 3D ### # get the index of next waypoint # waypoint_index = self.get_closest_waypoint_index_3D(location, # next_waypoint.location) # # find more waypoints index to fit a polynomial # waypoint_index_shifted = waypoint_index - 2 # indeces = waypoint_index_shifted + self.steps_poly * np.arange( # self.poly_degree + 1) # indeces = indeces % self.track_DF.shape[0] # # get waypoints for polynomial fitting # pts = np.array([[self.track_DF.iloc[i][0], self.track_DF.iloc[i][ # 1]] for i in indeces]) ### 2D ### index_2D = self . get_closest_waypoint_index_2D ( location , next_waypoint . location ) index_2D_shifted = index_2D - 5 indeces_2D = index_2D_shifted + self . steps_poly * np . arange ( self . poly_degree + 1 ) indeces_2D = indeces_2D % self . pts_2D . shape [ 0 ] pts = self . pts_2D [ indeces_2D ] # self.logger.debug(f'\\nwaypoint index:\\n {index_2D}') # self.logger.debug(f'\\nindeces:\\n {indeces_2D}') # transform waypoints from world to car coorinate pts_car = VehicleMPCController . transform_into_cars_coordinate_system ( pts , x , y , cos_\u03c8 , sin_\u03c8 ) # fit the polynomial poly = np . polyfit ( pts_car [:, 0 ], pts_car [:, 1 ], self . poly_degree ) # Debug # self.logger.debug(f'\\nwaypoint index:\\n {waypoint_index}') # self.logger.debug(f'\\nindeces:\\n {indeces}') # self.logger.debug(f'\\npts for poly_fit:\\n {pts}') # self.logger.debug(f'\\npts_car:\\n {pts_car}') ########### cte = poly [ - 1 ] e\u03c8 = - np . arctan ( poly [ - 2 ]) init = ( 0 , 0 , 0 , v , cte , e\u03c8 , * poly ) self . state0 = self . get_state0 ( v , cte , e\u03c8 , self . steer , self . throttle , poly ) result = self . minimize_cost ( self . bounds , self . state0 , init ) # self.steer = -0.6 * cte - 5.5 * (cte - self.prev_cte) # self.prev_cte = cte # self.throttle = VehicleMPCController.clip_throttle(self.throttle, # v, self.target_speed) control = VehicleControl () if 'success' in result . message : self . steer = result . x [ - self . steps_ahead ] self . throttle = result . x [ - 2 * self . steps_ahead ] else : self . logger . debug ( 'Unsuccessful optimization' ) control . steering = self . steer control . throttle = self . throttle return control","title":"run_in_series()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.mpc_controller.VehicleMPCController.transform_into_cars_coordinate_system","text":"Source code in ROAR/control_module/mpc_controller.py @staticmethod def transform_into_cars_coordinate_system ( pts , x , y , cos_\u03c8 , sin_\u03c8 ): diff = ( pts - [ x , y ]) pts_car = np . zeros_like ( diff ) pts_car [:, 0 ] = cos_\u03c8 * diff [:, 0 ] + sin_\u03c8 * diff [:, 1 ] pts_car [:, 1 ] = sin_\u03c8 * diff [:, 0 ] - cos_\u03c8 * diff [:, 1 ] return pts_car","title":"transform_into_cars_coordinate_system()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pid_controller","text":"","title":"pid_controller"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pid_controller.LatPIDController","text":"","title":"LatPIDController"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pid_controller.LatPIDController.__init__","text":"Source code in ROAR/control_module/pid_controller.py def __init__ ( self , agent , config : dict , steering_boundary : Tuple [ float , float ], dt : float = 0.03 , ** kwargs ): super () . __init__ ( agent , ** kwargs ) self . config = config self . steering_boundary = steering_boundary self . _error_buffer = deque ( maxlen = 10 ) self . _dt = dt","title":"__init__()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pid_controller.LatPIDController.run_in_series","text":"Calculates a vector that represent where you are going. Parameters: Name Type Description Default next_waypoint Transform required **kwargs {} Returns: Type Description float lat_control Source code in ROAR/control_module/pid_controller.py def run_in_series ( self , next_waypoint : Transform , ** kwargs ) -> float : \"\"\" Calculates a vector that represent where you are going. Args: next_waypoint (): **kwargs (): Returns: lat_control \"\"\" # calculate a vector that represent where you are going v_begin = self . agent . vehicle . transform . location v_end = v_begin + Location ( x = math . cos ( math . radians ( self . agent . vehicle . transform . rotation . pitch )), y = v_begin . y , z = math . sin ( math . radians ( self . agent . vehicle . transform . rotation . pitch )), ) v_vec = np . array ([ v_end . x - v_begin . x , v_end . y - v_begin . y , v_end . z - v_begin . z ]) # calculate error projection w_vec = np . array ( [ next_waypoint . location . x - v_begin . x , next_waypoint . location . y - v_begin . y , next_waypoint . location . z - v_begin . z , ] ) _dot = math . acos ( np . clip ( np . dot ( w_vec , v_vec ) / ( np . linalg . norm ( w_vec ) * np . linalg . norm ( v_vec )), - 1.0 , 1.0 , ) ) _cross = np . cross ( v_vec , w_vec ) if _cross [ 1 ] > 0 : _dot *= - 1.0 self . _error_buffer . append ( _dot ) if len ( self . _error_buffer ) >= 2 : _de = ( self . _error_buffer [ - 1 ] - self . _error_buffer [ - 2 ]) / self . _dt _ie = sum ( self . _error_buffer ) * self . _dt else : _de = 0.0 _ie = 0.0 k_p , k_d , k_i = PIDController . find_k_values ( config = self . config , vehicle = self . agent . vehicle ) lat_control = float ( np . clip (( k_p * _dot ) + ( k_d * _de ) + ( k_i * _ie ), self . steering_boundary [ 0 ], self . steering_boundary [ 1 ]) ) return lat_control","title":"run_in_series()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pid_controller.LongPIDController","text":"","title":"LongPIDController"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pid_controller.LongPIDController.__init__","text":"Source code in ROAR/control_module/pid_controller.py def __init__ ( self , agent , config : dict , throttle_boundary : Tuple [ float , float ], max_speed : float , dt : float = 0.03 , ** kwargs ): super () . __init__ ( agent , ** kwargs ) self . config = config self . max_speed = max_speed self . throttle_boundary = throttle_boundary self . _error_buffer = deque ( maxlen = 10 ) self . _dt = dt","title":"__init__()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pid_controller.LongPIDController.run_in_series","text":"Abstract function for run step Parameters: Name Type Description Default next_waypoint Transform next waypoint required **kwargs {} Returns: Type Description float VehicleControl Source code in ROAR/control_module/pid_controller.py def run_in_series ( self , next_waypoint : Transform , ** kwargs ) -> float : target_speed = min ( self . max_speed , kwargs . get ( \"target_speed\" , self . max_speed )) current_speed = Vehicle . get_speed ( self . agent . vehicle ) k_p , k_d , k_i = PIDController . find_k_values ( vehicle = self . agent . vehicle , config = self . config ) error = target_speed - current_speed self . _error_buffer . append ( error ) if len ( self . _error_buffer ) >= 2 : # print(self._error_buffer[-1], self._error_buffer[-2]) _de = ( self . _error_buffer [ - 2 ] - self . _error_buffer [ - 1 ]) / self . _dt _ie = sum ( self . _error_buffer ) * self . _dt else : _de = 0.0 _ie = 0.0 output = float ( np . clip (( k_p * error ) + ( k_d * _de ) + ( k_i * _ie ), self . throttle_boundary [ 0 ], self . throttle_boundary [ 1 ])) # self.logger.debug(f\"curr_speed: {round(current_speed, 2)} | kp: {round(k_p, 2)} | kd: {k_d} | ki = {k_i} | \" # f\"err = {round(error, 2)} | de = {round(_de, 2)} | ie = {round(_ie, 2)}\") #f\"self._error_buffer[-1] {self._error_buffer[-1]} | self._error_buffer[-2] = {self._error_buffer[-2]}\") return output","title":"run_in_series()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pid_controller.PIDController","text":"","title":"PIDController"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pid_controller.PIDController.__init__","text":"Source code in ROAR/control_module/pid_controller.py def __init__ ( self , agent , steering_boundary : Tuple [ float , float ], throttle_boundary : Tuple [ float , float ], ** kwargs ): super () . __init__ ( agent , ** kwargs ) self . max_speed = self . agent . agent_settings . max_speed self . throttle_boundary = throttle_boundary self . steering_boundary = steering_boundary self . config = json . load ( Path ( agent . agent_settings . pid_config_file_path ) . open ( mode = 'r' )) self . long_pid_controller = LongPIDController ( agent = agent , throttle_boundary = throttle_boundary , max_speed = self . max_speed , config = self . config [ \"longitudinal_controller\" ]) self . lat_pid_controller = LatPIDController ( agent = agent , config = self . config [ \"latitudinal_controller\" ], steering_boundary = steering_boundary ) self . logger = logging . getLogger ( __name__ )","title":"__init__()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pid_controller.PIDController.find_k_values","text":"Source code in ROAR/control_module/pid_controller.py @staticmethod def find_k_values ( vehicle : Vehicle , config : dict ) -> np . array : current_speed = Vehicle . get_speed ( vehicle = vehicle ) k_p , k_d , k_i = 1 , 0 , 0 for speed_upper_bound , kvalues in config . items (): speed_upper_bound = float ( speed_upper_bound ) if current_speed < speed_upper_bound : k_p , k_d , k_i = kvalues [ \"Kp\" ], kvalues [ \"Kd\" ], kvalues [ \"Ki\" ] break return np . clip ([ k_p , k_d , k_i ], a_min = 0 , a_max = 1 )","title":"find_k_values()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pid_controller.PIDController.run_in_series","text":"Abstract function for run step Parameters: Name Type Description Default next_waypoint Transform next waypoint required **kwargs {} Returns: Type Description VehicleControl VehicleControl Source code in ROAR/control_module/pid_controller.py def run_in_series ( self , next_waypoint : Transform , ** kwargs ) -> VehicleControl : throttle = self . long_pid_controller . run_in_series ( next_waypoint = next_waypoint , target_speed = kwargs . get ( \"target_speed\" , self . max_speed )) steering = self . lat_pid_controller . run_in_series ( next_waypoint = next_waypoint ) return VehicleControl ( throttle = throttle , steering = steering )","title":"run_in_series()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pure_pursuit_control","text":"","title":"pure_pursuit_control"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pure_pursuit_control.LatitunalPurePursuitController","text":"","title":"LatitunalPurePursuitController"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pure_pursuit_control.LatitunalPurePursuitController.__init__","text":"Source code in ROAR/control_module/pure_pursuit_control.py def __init__ ( self , agent : Agent , look_ahead_gain : float , look_ahead_distance : float ): self . agent = agent self . look_ahead_gain = look_ahead_gain self . look_ahead_distance = look_ahead_distance","title":"__init__()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pure_pursuit_control.LatitunalPurePursuitController.run_step","text":"Parameters: Name Type Description Default next_waypoint Transform required Returns: Type Description float VehicleControl.clamp Source code in ROAR/control_module/pure_pursuit_control.py def run_step ( self , next_waypoint : Transform ) -> float : \"\"\" Args: next_waypoint (): Returns: VehicleControl.clamp \"\"\" target_z = next_waypoint . location . z target_x = next_waypoint . location . x angle_difference = math . atan2 ( target_z - self . agent . vehicle . transform . location . z , target_x - self . agent . vehicle . transform . location . x ) - np . radians ( self . agent . vehicle . transform . rotation . pitch ) curr_look_forward = ( self . look_ahead_gain * Vehicle . get_speed ( vehicle = self . agent . vehicle ) + self . look_ahead_distance ) lateral_difference = math . atan2 ( 2.0 * self . agent . vehicle . wheel_base * math . sin ( angle_difference ) / curr_look_forward , 1.0 , ) return VehicleControl . clamp ( lateral_difference , - 1 , 1 )","title":"run_step()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pure_pursuit_control.LongitunalPurePursuitController","text":"","title":"LongitunalPurePursuitController"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pure_pursuit_control.LongitunalPurePursuitController.__init__","text":"Source code in ROAR/control_module/pure_pursuit_control.py def __init__ ( self , agent : Agent , target_speed = 60 , kp = 0.1 ): self . agent = agent self . target_speed = target_speed self . kp = kp","title":"__init__()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pure_pursuit_control.LongitunalPurePursuitController.run_step","text":"Source code in ROAR/control_module/pure_pursuit_control.py def run_step ( self ) -> float : return float ( VehicleControl . clamp ( self . kp * ( self . target_speed - Vehicle . get_speed ( self . agent . vehicle )), 0 , 1 ) )","title":"run_step()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pure_pursuit_control.PurePursuitController","text":"","title":"PurePursuitController"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pure_pursuit_control.PurePursuitController.__init__","text":"Parameters: Name Type Description Default vehicle Vehicle information required look_ahead_gain float Look ahead factor 0.1 look_ahead_distance float look ahead distance 2 target_speed desired longitudinal speed to maintain 60 Source code in ROAR/control_module/pure_pursuit_control.py def __init__ ( self , agent : Agent , look_ahead_gain : float = 0.1 , look_ahead_distance : float = 2 , target_speed = 60 , ): \"\"\" Args: vehicle: Vehicle information look_ahead_gain: Look ahead factor look_ahead_distance: look ahead distance target_speed: desired longitudinal speed to maintain \"\"\" super ( PurePursuitController , self ) . __init__ ( agent = agent ) self . target_speed = self . agent . agent_settings . max_speed \\ if self . agent . agent_settings . max_speed else target_speed self . look_ahead_gain = look_ahead_gain self . look_ahead_distance = look_ahead_distance self . latitunal_controller = LatitunalPurePursuitController ( agent = self . agent , look_ahead_gain = look_ahead_gain , look_ahead_distance = look_ahead_distance , ) self . longitunal_controller = LongitunalPurePursuitController ( agent = self . agent , target_speed = target_speed )","title":"__init__()"},{"location":"code_documentations/ROAR/controller_module/#ROAR.control_module.pure_pursuit_control.PurePursuitController.run_in_series","text":"run one step of Pure Pursuit Control Parameters: Name Type Description Default vehicle current vehicle state required next_waypoint Transform Next waypoint, Transform required **kwargs {} Returns: Type Description VehicleControl Vehicle Control Source code in ROAR/control_module/pure_pursuit_control.py def run_in_series ( self , next_waypoint : Transform , ** kwargs ) -> VehicleControl : \"\"\" run one step of Pure Pursuit Control Args: vehicle: current vehicle state next_waypoint: Next waypoint, Transform **kwargs: Returns: Vehicle Control \"\"\" control = VehicleControl ( throttle = self . longitunal_controller . run_step (), steering = self . latitunal_controller . run_step ( next_waypoint = next_waypoint ), ) return control","title":"run_in_series()"},{"location":"code_documentations/ROAR/perception_module/","text":"DepthToPointCloudDetector \u00a4 __init__ ( self , agent , should_compute_global_pointcloud = False , should_sample_points = False , should_filter_by_distance = False , max_detectable_distance = 1 , max_points_to_convert = 10000 ) special \u00a4 Source code in ROAR/perception_module/depth_to_pointcloud_detector.py def __init__ ( self , agent : Agent , should_compute_global_pointcloud : bool = False , should_sample_points : bool = False , should_filter_by_distance : float = False , max_detectable_distance : float = 1 , max_points_to_convert = 10000 ): super () . __init__ ( agent ) self . should_compute_global_pointcloud = should_compute_global_pointcloud self . should_sample_points = should_sample_points self . should_filter_by_distance = should_filter_by_distance self . max_detectable_distance = max_detectable_distance self . max_points_to_convert = max_points_to_convert find_fps ( t1 , t2 ) staticmethod \u00a4 Source code in ROAR/perception_module/depth_to_pointcloud_detector.py @staticmethod def find_fps ( t1 , t2 ): return 1 / ( t2 - t1 ) run_in_series ( self ) \u00a4 :return: 3 x N array of point cloud Source code in ROAR/perception_module/depth_to_pointcloud_detector.py def run_in_series ( self ) -> Optional [ np . ndarray ]: \"\"\" :return: 3 x N array of point cloud \"\"\" if self . agent . front_depth_camera . data is not None : depth_img = self . agent . front_depth_camera . data . copy () if self . should_filter_by_distance : coords = np . where ( depth_img < self . max_detectable_distance ) else : coords = np . where ( depth_img < 2 ) if self . should_sample_points and np . shape ( coords )[ 1 ] > self . max_points_to_convert : coords = np . random . choice ( a = coords , size = self . max_points_to_convert , replace = False ) depths = depth_img [ coords ][:, np . newaxis ] * 1000 result = np . multiply ( np . array ( coords ) . T , depths ) raw_p2d = np . hstack (( result , depths )) cords_xyz = np . linalg . inv ( self . agent . front_depth_camera . intrinsics_matrix ) @ raw_p2d . T if self . should_compute_global_pointcloud : cords_xyz_1 = np . vstack ([ cords_xyz , np . ones (( 1 , np . shape ( cords_xyz )[ 1 ]))]) return ( self . agent . vehicle . transform . get_matrix () @ self . agent . front_depth_camera . transform . get_matrix () @ cords_xyz_1 )[: 3 , :] . T else : return cords_xyz . T return None Detector \u00a4 __init__ ( self , agent , ** kwargs ) special \u00a4 Source code in ROAR/perception_module/detector.py def __init__ ( self , agent : Agent , ** kwargs ): super () . __init__ ( ** kwargs ) self . agent = agent self . logger = logging . getLogger ( \"Base Detector\" ) run_in_series ( self , ** kwargs ) \u00a4 This is the none-threaded function. It run in series! Parameters: Name Type Description Default **kwargs {} Returns: Type Description Any Source code in ROAR/perception_module/detector.py @abstractmethod def run_in_series ( self , ** kwargs ) -> Any : return None run_in_threaded ( self , ** kwargs ) \u00a4 This is the threaded function. Parameters: Name Type Description Default **kwargs {} Source code in ROAR/perception_module/detector.py def run_in_threaded ( self , ** kwargs ): pass GroundPlaneDetector \u00a4 __init__ ( self , agent , knn = 200 , ** kwargs ) special \u00a4 Source code in ROAR/perception_module/ground_plane_detector.py def __init__ ( self , agent : Agent , knn : int = 200 , ** kwargs ): super () . __init__ ( agent , ** kwargs ) self . reference_norm : Optional [ np . ndarray ] = np . array ([ - 0.00000283 , - 0.00012446 , 0.99999999 ]) self . knn = knn self . f1 , self . f2 , self . f3 , self . f4 = self . compute_vectors_near_me () compute_reference_norm ( self , pcd ) \u00a4 Source code in ROAR/perception_module/ground_plane_detector.py def compute_reference_norm ( self , pcd : o3d . geometry . PointCloud ): pcd_tree = o3d . geometry . KDTreeFlann ( pcd ) # build KD tree for fast computation [ k , idx , _ ] = pcd_tree . search_knn_vector_3d ( self . agent . vehicle . transform . location . to_array (), knn = self . knn ) # find points around me points_near_me = np . asarray ( pcd . points )[ idx , :] # 200 x 3 u , s , vh = np . linalg . svd ( points_near_me , full_matrices = False ) # use svd to find normals of points self . reference_norm = vh [ 2 , :] compute_vectors_near_me ( self ) \u00a4 Computes vectors near Agent from Front Depth Camera. Source code in ROAR/perception_module/ground_plane_detector.py def compute_vectors_near_me ( self ): \"\"\"Computes vectors near Agent from Front Depth Camera.\"\"\" d1 , d2 = self . agent . front_depth_camera . image_size_y , self . agent . front_depth_camera . image_size_x idx , jdx = np . indices (( d1 , d2 )) idx_back = np . clip ( idx - 1 , 0 , idx . max ()) . flatten () idx_front = np . clip ( idx + 1 , 0 , idx . max ()) . flatten () jdx_back = np . clip ( jdx - 1 , 0 , jdx . max ()) . flatten () jdx_front = np . clip ( jdx + 1 , 0 , jdx . max ()) . flatten () idx = idx . flatten () jdx = jdx . flatten () # rand_idx = np.random.choice(np.arange(idx.shape[0]), size=d1*d2, replace=False) f1 = ( idx_front * d2 + jdx )[:: 16 ] # [rand_idx] f2 = ( idx_back * d2 + jdx )[:: 16 ] # [rand_idx] f3 = ( idx * d2 + jdx_front )[:: 16 ] # [rand_idx] f4 = ( idx * d2 + jdx_back )[:: 16 ] # [rand_idx] return f1 , f2 , f3 , f4 construct_pointcloud ( points ) staticmethod \u00a4 Source code in ROAR/perception_module/ground_plane_detector.py @staticmethod def construct_pointcloud ( points ) -> o3d . geometry . PointCloud : pcd = o3d . geometry . PointCloud () pcd . points = o3d . utility . Vector3dVector ( points ) pcd . estimate_normals () return pcd normalize_v3 ( arr ) staticmethod \u00a4 Source code in ROAR/perception_module/ground_plane_detector.py @staticmethod def normalize_v3 ( arr ): lens = np . sqrt ( arr [:, 0 ] ** 2 + arr [:, 1 ] ** 2 + arr [:, 2 ] ** 2 ) lens [ lens <= 0 ] = 1 arr [:, 0 ] /= lens arr [:, 1 ] /= lens arr [:, 2 ] /= lens return arr run_in_series ( self ) \u00a4 :return: 3 x N array of point cloud Source code in ROAR/perception_module/ground_plane_detector.py def run_in_series ( self ) -> Any : points = super ( GroundPlaneDetector , self ) . run_in_series () # Nx3 x = points [ self . f3 , :] - points [ self . f4 , :] y = points [ self . f1 , :] - points [ self . f2 , :] normals = self . normalize_v3 ( np . cross ( x , y )) # OpenCV FloodFill d1 = self . agent . front_depth_camera . image_size_y d2 = self . agent . front_depth_camera . image_size_x curr_img = normals . reshape (( int ( d1 / 4 ), int ( d2 / 4 ), 3 )) . astype ( np . float32 ) seed_point = ( int ( d1 / 4 ) - 1 , int ( int ( d2 / 4 ) / 2 )) _ , retval , _ , _ = cv2 . floodFill ( image = curr_img , seedPoint = seed_point , newVal = ( 0 , 0 , 0 ), loDiff = ( 0.01 , 0.01 , 0.01 ), upDiff = ( 0.01 , 0.01 , 0.01 ), mask = None ) bool_matrix = np . mean ( retval , axis = 2 ) == 0 bool_zeros = np . zeros ( d1 * d2 ) . flatten () bool_indices = np . indices ( bool_zeros . shape )[ 0 ][:: 16 ] bool_zeros [ bool_indices ] = bool_matrix . flatten () bool_matrix = bool_zeros . reshape (( d1 , d2 )) color_image = self . agent . front_rgb_camera . data . copy () color_image [ bool_matrix > 0 ] = 255 cv2 . imshow ( 'Color' , color_image ) cv2 . waitKey ( 1 )","title":"Perception Module"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.depth_to_pointcloud_detector.DepthToPointCloudDetector","text":"","title":"DepthToPointCloudDetector"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.depth_to_pointcloud_detector.DepthToPointCloudDetector.__init__","text":"Source code in ROAR/perception_module/depth_to_pointcloud_detector.py def __init__ ( self , agent : Agent , should_compute_global_pointcloud : bool = False , should_sample_points : bool = False , should_filter_by_distance : float = False , max_detectable_distance : float = 1 , max_points_to_convert = 10000 ): super () . __init__ ( agent ) self . should_compute_global_pointcloud = should_compute_global_pointcloud self . should_sample_points = should_sample_points self . should_filter_by_distance = should_filter_by_distance self . max_detectable_distance = max_detectable_distance self . max_points_to_convert = max_points_to_convert","title":"__init__()"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.depth_to_pointcloud_detector.DepthToPointCloudDetector.find_fps","text":"Source code in ROAR/perception_module/depth_to_pointcloud_detector.py @staticmethod def find_fps ( t1 , t2 ): return 1 / ( t2 - t1 )","title":"find_fps()"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.depth_to_pointcloud_detector.DepthToPointCloudDetector.run_in_series","text":":return: 3 x N array of point cloud Source code in ROAR/perception_module/depth_to_pointcloud_detector.py def run_in_series ( self ) -> Optional [ np . ndarray ]: \"\"\" :return: 3 x N array of point cloud \"\"\" if self . agent . front_depth_camera . data is not None : depth_img = self . agent . front_depth_camera . data . copy () if self . should_filter_by_distance : coords = np . where ( depth_img < self . max_detectable_distance ) else : coords = np . where ( depth_img < 2 ) if self . should_sample_points and np . shape ( coords )[ 1 ] > self . max_points_to_convert : coords = np . random . choice ( a = coords , size = self . max_points_to_convert , replace = False ) depths = depth_img [ coords ][:, np . newaxis ] * 1000 result = np . multiply ( np . array ( coords ) . T , depths ) raw_p2d = np . hstack (( result , depths )) cords_xyz = np . linalg . inv ( self . agent . front_depth_camera . intrinsics_matrix ) @ raw_p2d . T if self . should_compute_global_pointcloud : cords_xyz_1 = np . vstack ([ cords_xyz , np . ones (( 1 , np . shape ( cords_xyz )[ 1 ]))]) return ( self . agent . vehicle . transform . get_matrix () @ self . agent . front_depth_camera . transform . get_matrix () @ cords_xyz_1 )[: 3 , :] . T else : return cords_xyz . T return None","title":"run_in_series()"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.detector.Detector","text":"","title":"Detector"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.detector.Detector.__init__","text":"Source code in ROAR/perception_module/detector.py def __init__ ( self , agent : Agent , ** kwargs ): super () . __init__ ( ** kwargs ) self . agent = agent self . logger = logging . getLogger ( \"Base Detector\" )","title":"__init__()"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.detector.Detector.run_in_series","text":"This is the none-threaded function. It run in series! Parameters: Name Type Description Default **kwargs {} Returns: Type Description Any Source code in ROAR/perception_module/detector.py @abstractmethod def run_in_series ( self , ** kwargs ) -> Any : return None","title":"run_in_series()"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.detector.Detector.run_in_threaded","text":"This is the threaded function. Parameters: Name Type Description Default **kwargs {} Source code in ROAR/perception_module/detector.py def run_in_threaded ( self , ** kwargs ): pass","title":"run_in_threaded()"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.ground_plane_detector.GroundPlaneDetector","text":"","title":"GroundPlaneDetector"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.ground_plane_detector.GroundPlaneDetector.__init__","text":"Source code in ROAR/perception_module/ground_plane_detector.py def __init__ ( self , agent : Agent , knn : int = 200 , ** kwargs ): super () . __init__ ( agent , ** kwargs ) self . reference_norm : Optional [ np . ndarray ] = np . array ([ - 0.00000283 , - 0.00012446 , 0.99999999 ]) self . knn = knn self . f1 , self . f2 , self . f3 , self . f4 = self . compute_vectors_near_me ()","title":"__init__()"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.ground_plane_detector.GroundPlaneDetector.compute_reference_norm","text":"Source code in ROAR/perception_module/ground_plane_detector.py def compute_reference_norm ( self , pcd : o3d . geometry . PointCloud ): pcd_tree = o3d . geometry . KDTreeFlann ( pcd ) # build KD tree for fast computation [ k , idx , _ ] = pcd_tree . search_knn_vector_3d ( self . agent . vehicle . transform . location . to_array (), knn = self . knn ) # find points around me points_near_me = np . asarray ( pcd . points )[ idx , :] # 200 x 3 u , s , vh = np . linalg . svd ( points_near_me , full_matrices = False ) # use svd to find normals of points self . reference_norm = vh [ 2 , :]","title":"compute_reference_norm()"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.ground_plane_detector.GroundPlaneDetector.compute_vectors_near_me","text":"Computes vectors near Agent from Front Depth Camera. Source code in ROAR/perception_module/ground_plane_detector.py def compute_vectors_near_me ( self ): \"\"\"Computes vectors near Agent from Front Depth Camera.\"\"\" d1 , d2 = self . agent . front_depth_camera . image_size_y , self . agent . front_depth_camera . image_size_x idx , jdx = np . indices (( d1 , d2 )) idx_back = np . clip ( idx - 1 , 0 , idx . max ()) . flatten () idx_front = np . clip ( idx + 1 , 0 , idx . max ()) . flatten () jdx_back = np . clip ( jdx - 1 , 0 , jdx . max ()) . flatten () jdx_front = np . clip ( jdx + 1 , 0 , jdx . max ()) . flatten () idx = idx . flatten () jdx = jdx . flatten () # rand_idx = np.random.choice(np.arange(idx.shape[0]), size=d1*d2, replace=False) f1 = ( idx_front * d2 + jdx )[:: 16 ] # [rand_idx] f2 = ( idx_back * d2 + jdx )[:: 16 ] # [rand_idx] f3 = ( idx * d2 + jdx_front )[:: 16 ] # [rand_idx] f4 = ( idx * d2 + jdx_back )[:: 16 ] # [rand_idx] return f1 , f2 , f3 , f4","title":"compute_vectors_near_me()"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.ground_plane_detector.GroundPlaneDetector.construct_pointcloud","text":"Source code in ROAR/perception_module/ground_plane_detector.py @staticmethod def construct_pointcloud ( points ) -> o3d . geometry . PointCloud : pcd = o3d . geometry . PointCloud () pcd . points = o3d . utility . Vector3dVector ( points ) pcd . estimate_normals () return pcd","title":"construct_pointcloud()"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.ground_plane_detector.GroundPlaneDetector.normalize_v3","text":"Source code in ROAR/perception_module/ground_plane_detector.py @staticmethod def normalize_v3 ( arr ): lens = np . sqrt ( arr [:, 0 ] ** 2 + arr [:, 1 ] ** 2 + arr [:, 2 ] ** 2 ) lens [ lens <= 0 ] = 1 arr [:, 0 ] /= lens arr [:, 1 ] /= lens arr [:, 2 ] /= lens return arr","title":"normalize_v3()"},{"location":"code_documentations/ROAR/perception_module/#ROAR.perception_module.ground_plane_detector.GroundPlaneDetector.run_in_series","text":":return: 3 x N array of point cloud Source code in ROAR/perception_module/ground_plane_detector.py def run_in_series ( self ) -> Any : points = super ( GroundPlaneDetector , self ) . run_in_series () # Nx3 x = points [ self . f3 , :] - points [ self . f4 , :] y = points [ self . f1 , :] - points [ self . f2 , :] normals = self . normalize_v3 ( np . cross ( x , y )) # OpenCV FloodFill d1 = self . agent . front_depth_camera . image_size_y d2 = self . agent . front_depth_camera . image_size_x curr_img = normals . reshape (( int ( d1 / 4 ), int ( d2 / 4 ), 3 )) . astype ( np . float32 ) seed_point = ( int ( d1 / 4 ) - 1 , int ( int ( d2 / 4 ) / 2 )) _ , retval , _ , _ = cv2 . floodFill ( image = curr_img , seedPoint = seed_point , newVal = ( 0 , 0 , 0 ), loDiff = ( 0.01 , 0.01 , 0.01 ), upDiff = ( 0.01 , 0.01 , 0.01 ), mask = None ) bool_matrix = np . mean ( retval , axis = 2 ) == 0 bool_zeros = np . zeros ( d1 * d2 ) . flatten () bool_indices = np . indices ( bool_zeros . shape )[ 0 ][:: 16 ] bool_zeros [ bool_indices ] = bool_matrix . flatten () bool_matrix = bool_zeros . reshape (( d1 , d2 )) color_image = self . agent . front_rgb_camera . data . copy () color_image [ bool_matrix > 0 ] = 255 cv2 . imshow ( 'Color' , color_image ) cv2 . waitKey ( 1 )","title":"run_in_series()"},{"location":"code_documentations/ROAR/planning_module/","text":"abstract_planner \u00a4 AbstractPlanner \u00a4 __init__ ( self , agent , ** kwargs ) special \u00a4 Source code in ROAR/planning_module/abstract_planner.py def __init__ ( self , agent , ** kwargs ): super () . __init__ ( ** kwargs ) self . logger = logging self . logger = logging . getLogger ( __name__ ) self . agent = agent run_in_series ( self , ** kwargs ) \u00a4 On every step, produce an actionable plan Returns: Type Description Any Source code in ROAR/planning_module/abstract_planner.py @abstractmethod def run_in_series ( self , ** kwargs ) -> Any : \"\"\" On every step, produce an actionable plan Returns: \"\"\" return None run_in_threaded ( self , ** kwargs ) \u00a4 This is the threaded function. Parameters: Name Type Description Default **kwargs {} Source code in ROAR/planning_module/abstract_planner.py def run_in_threaded ( self , ** kwargs ): pass behavior_planner special \u00a4 behavior_planner \u00a4 BehaviorPlanner \u00a4 __init__ ( self , agent , ** kwargs ) special \u00a4 Source code in ROAR/planning_module/behavior_planner/behavior_planner.py def __init__ ( self , agent , ** kwargs ): super () . __init__ ( agent , ** kwargs ) run_in_series ( self ) \u00a4 On every step, produce an actionable plan Returns: Type Description Any Source code in ROAR/planning_module/behavior_planner/behavior_planner.py def run_in_series ( self ) -> Any : pass local_planner special \u00a4 floodfill_based_planner \u00a4 FloodfillBasedPlanner \u00a4 run_in_series ( self ) \u00a4 On every step, produce an actionable plan Returns: Type Description VehicleControl Source code in ROAR/planning_module/local_planner/floodfill_based_planner.py def run_in_series ( self ) -> VehicleControl : pass local_planner \u00a4 LocalPlanner \u00a4 __init__ ( self , agent , controller = None , behavior_planner = None , mission_planner = None , ** kwargs ) special \u00a4 Source code in ROAR/planning_module/local_planner/local_planner.py def __init__ ( self , agent , controller : Optional [ Controller ] = None , behavior_planner : Optional [ BehaviorPlanner ] = None , mission_planner : Optional [ MissionPlanner ] = None , ** kwargs ): super () . __init__ ( agent = agent , ** kwargs ) self . controller = ( Controller ( agent = agent ) if controller is None else controller ) self . behavior_planner = ( BehaviorPlanner ( agent = agent ) if behavior_planner is None else behavior_planner ) self . mission_planner = ( MissionPlanner ( agent = agent ) if mission_planner is None else mission_planner ) self . way_points_queue = deque () run_in_series ( self ) \u00a4 On every step, produce an actionable plan Returns: Type Description VehicleControl Source code in ROAR/planning_module/local_planner/local_planner.py @abstractmethod def run_in_series ( self ) -> VehicleControl : return VehicleControl () simple_waypoint_following_local_planner \u00a4 SimpleWaypointFollowingLocalPlanner \u00a4 __init__ ( self , agent , controller , mission_planner , behavior_planner , closeness_threshold = 0.5 ) special \u00a4 Initialize Simple Waypoint Following Planner Parameters: Name Type Description Default agent Agent newest agent state required controller Controller Control module used required mission_planner MissionPlanner mission planner used required behavior_planner BehaviorPlanner behavior planner used required closeness_threshold how close can a waypoint be with the vehicle 0.5 Source code in ROAR/planning_module/local_planner/simple_waypoint_following_local_planner.py def __init__ ( self , agent : Agent , controller : Controller , mission_planner : MissionPlanner , behavior_planner : BehaviorPlanner , closeness_threshold = 0.5 , ): \"\"\" Initialize Simple Waypoint Following Planner Args: agent: newest agent state controller: Control module used mission_planner: mission planner used behavior_planner: behavior planner used closeness_threshold: how close can a waypoint be with the vehicle \"\"\" super () . __init__ ( agent = agent , controller = controller , mission_planner = mission_planner , behavior_planner = behavior_planner , ) self . logger = logging . getLogger ( \"SimplePathFollowingLocalPlanner\" ) self . set_mission_plan () self . logger . debug ( \"Simple Path Following Local Planner Initiated\" ) self . closeness_threshold = closeness_threshold self . closeness_threshold_config = json . load ( Path ( agent . agent_settings . simple_waypoint_local_planner_config_file_path ) . open ( mode = 'r' )) is_done ( self ) \u00a4 If there are nothing in self.way_points_queue, that means you have finished a lap, you are done Returns: Type Description bool True if Done, False otherwise Source code in ROAR/planning_module/local_planner/simple_waypoint_following_local_planner.py def is_done ( self ) -> bool : \"\"\" If there are nothing in self.way_points_queue, that means you have finished a lap, you are done Returns: True if Done, False otherwise \"\"\" return len ( self . way_points_queue ) == 0 run_in_series ( self ) \u00a4 Procedure Sync data get the correct look ahead for current speed get the correct next waypoint feed waypoint into controller return result from controller Returns: Type Description VehicleControl next control that the local think the agent should execute. Source code in ROAR/planning_module/local_planner/simple_waypoint_following_local_planner.py def run_in_series ( self ) -> VehicleControl : \"\"\" Run step for the local planner Procedure: 1. Sync data 2. get the correct look ahead for current speed 3. get the correct next waypoint 4. feed waypoint into controller 5. return result from controller Returns: next control that the local think the agent should execute. \"\"\" if ( len ( self . mission_planner . mission_plan ) == 0 and len ( self . way_points_queue ) == 0 ): return VehicleControl () # get vehicle's location vehicle_transform : Union [ Transform , None ] = self . agent . vehicle . transform if vehicle_transform is None : raise AgentException ( \"I do not know where I am, I cannot proceed forward\" ) # redefine closeness level based on speed self . set_closeness_threhold ( self . closeness_threshold_config ) # get current waypoint curr_closest_dist = float ( \"inf\" ) while True : if len ( self . way_points_queue ) == 0 : self . logger . info ( \"Destination reached\" ) return VehicleControl () waypoint : Transform = self . way_points_queue [ 0 ] curr_dist = vehicle_transform . location . distance ( waypoint . location ) if curr_dist < curr_closest_dist : # if i find a waypoint that is closer to me than before # note that i will always enter here to start the calculation for curr_closest_dist curr_closest_dist = curr_dist elif curr_dist < self . closeness_threshold : # i have moved onto a waypoint, remove that waypoint from the queue self . way_points_queue . popleft () else : break target_waypoint = self . way_points_queue [ 0 ] control : VehicleControl = self . controller . run_in_series ( next_waypoint = target_waypoint ) self . logger . debug ( f \" \\n \" f \"Curr Transform: { self . agent . vehicle . transform } \\n \" f \"Target Location: { target_waypoint . location } \\n \" f \"Control: { control } | Speed: { Vehicle . get_speed ( self . agent . vehicle ) } \\n \" ) return control set_closeness_threhold ( self , config ) \u00a4 Source code in ROAR/planning_module/local_planner/simple_waypoint_following_local_planner.py def set_closeness_threhold ( self , config : dict ): curr_speed = Vehicle . get_speed ( self . agent . vehicle ) for speed_upper_bound , closeness_threshold in config . items (): speed_upper_bound = float ( speed_upper_bound ) if curr_speed < speed_upper_bound : self . closeness_threshold = closeness_threshold break set_mission_plan ( self ) \u00a4 Clears current waypoints, and reset mission plan from start I am simply transferring the mission plan into my waypoint queue. Assuming that this current run will run all the way to the end Returns: Type Description None None Source code in ROAR/planning_module/local_planner/simple_waypoint_following_local_planner.py def set_mission_plan ( self ) -> None : \"\"\" Clears current waypoints, and reset mission plan from start I am simply transferring the mission plan into my waypoint queue. Assuming that this current run will run all the way to the end Returns: None \"\"\" self . way_points_queue . clear () while ( self . mission_planner . mission_plan ): # this actually clears the mission plan!! self . way_points_queue . append ( self . mission_planner . mission_plan . popleft ()) mission_planner special \u00a4 json_waypoint_planner \u00a4 JSONWaypointPlanner \u00a4 __init__ ( self , agent ) special \u00a4 Source code in ROAR/planning_module/mission_planner/json_waypoint_planner.py def __init__ ( self , agent : Agent ): super () . __init__ ( agent = agent ) self . file_path : Path = Path ( self . agent . agent_settings . json_waypoint_file_path ) self . mission_plan : deque = self . run_in_series () run_in_series ( self ) \u00a4 Abstract run step function for Mission Planner Parameters: Name Type Description Default vehicle new vehicle state required Returns: Type Description deque Plan for next steps Source code in ROAR/planning_module/mission_planner/json_waypoint_planner.py def run_in_series ( self ) -> deque : result = deque () map_entries = self . _read_data_file () for m in map_entries : result . append ( self . _map_entry_to_transform ( map_entry = m )) return result mission_planner \u00a4 MissionPlanner \u00a4 __init__ ( self , agent , ** kwargs ) special \u00a4 Source code in ROAR/planning_module/mission_planner/mission_planner.py def __init__ ( self , agent , ** kwargs ): super () . __init__ ( agent = agent , ** kwargs ) self . logger = logging . getLogger ( __name__ ) self . mission_plan : deque = deque () run_in_series ( self ) \u00a4 Abstract run step function for Mission Planner Parameters: Name Type Description Default vehicle new vehicle state required Returns: Type Description List[ROAR.utilities_module.data_structures_models.Transform] Plan for next steps Source code in ROAR/planning_module/mission_planner/mission_planner.py def run_in_series ( self ) -> List [ Transform ]: \"\"\" Abstract run step function for Mission Planner Args: vehicle: new vehicle state Returns: Plan for next steps \"\"\" return [] waypoint_following_mission_planner \u00a4 WaypointFollowingMissionPlanner \u00a4 A mission planner that takes in a file that contains x,y,z coordinates, formulate into carla.Transform __init__ ( self , agent ) special \u00a4 Source code in ROAR/planning_module/mission_planner/waypoint_following_mission_planner.py def __init__ ( self , agent : Agent ): super () . __init__ ( agent = agent ) self . logger = logging . getLogger ( __name__ ) self . file_path : Path = Path ( self . agent . agent_settings . waypoint_file_path ) self . mission_plan = self . produce_mission_plan () self . logger . debug ( \"Path Following Mission Planner Initiated.\" ) produce_mission_plan ( self ) \u00a4 Generates a list of waypoints based on the input file path :return a list of waypoint Source code in ROAR/planning_module/mission_planner/waypoint_following_mission_planner.py def produce_mission_plan ( self ) -> deque : \"\"\" Generates a list of waypoints based on the input file path :return a list of waypoint \"\"\" mission_plan = deque () raw_path : List [ List [ float ]] = self . _read_data_file () for coord in raw_path : if len ( coord ) == 3 or len ( coord ) == 6 : mission_plan . append ( self . _raw_coord_to_transform ( coord )) self . logger . debug ( f \"Computed Mission path of length [ { len ( mission_plan ) } ]\" ) return mission_plan run_in_series ( self ) \u00a4 Regenerate waypoints from file Find the waypoint that is closest to the current vehicle location. return a mission plan starting from that waypoint Parameters: Name Type Description Default vehicle current state of the vehicle required Returns: Type Description deque mission plan that start from the current vehicle location Source code in ROAR/planning_module/mission_planner/waypoint_following_mission_planner.py def run_in_series ( self ) -> deque : \"\"\" Regenerate waypoints from file Find the waypoint that is closest to the current vehicle location. return a mission plan starting from that waypoint Args: vehicle: current state of the vehicle Returns: mission plan that start from the current vehicle location \"\"\" super ( WaypointFollowingMissionPlanner , self ) . run_in_series () self . logger . debug ( \"TO BE IMPLEMENTED\" ) return self . produce_mission_plan ()","title":"Planning Module"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.abstract_planner","text":"","title":"abstract_planner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.abstract_planner.AbstractPlanner","text":"","title":"AbstractPlanner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.abstract_planner.AbstractPlanner.__init__","text":"Source code in ROAR/planning_module/abstract_planner.py def __init__ ( self , agent , ** kwargs ): super () . __init__ ( ** kwargs ) self . logger = logging self . logger = logging . getLogger ( __name__ ) self . agent = agent","title":"__init__()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.abstract_planner.AbstractPlanner.run_in_series","text":"On every step, produce an actionable plan Returns: Type Description Any Source code in ROAR/planning_module/abstract_planner.py @abstractmethod def run_in_series ( self , ** kwargs ) -> Any : \"\"\" On every step, produce an actionable plan Returns: \"\"\" return None","title":"run_in_series()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.abstract_planner.AbstractPlanner.run_in_threaded","text":"This is the threaded function. Parameters: Name Type Description Default **kwargs {} Source code in ROAR/planning_module/abstract_planner.py def run_in_threaded ( self , ** kwargs ): pass","title":"run_in_threaded()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.behavior_planner","text":"","title":"behavior_planner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.behavior_planner.behavior_planner","text":"","title":"behavior_planner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.behavior_planner.behavior_planner.BehaviorPlanner","text":"","title":"BehaviorPlanner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.behavior_planner.behavior_planner.BehaviorPlanner.__init__","text":"Source code in ROAR/planning_module/behavior_planner/behavior_planner.py def __init__ ( self , agent , ** kwargs ): super () . __init__ ( agent , ** kwargs )","title":"__init__()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.behavior_planner.behavior_planner.BehaviorPlanner.run_in_series","text":"On every step, produce an actionable plan Returns: Type Description Any Source code in ROAR/planning_module/behavior_planner/behavior_planner.py def run_in_series ( self ) -> Any : pass","title":"run_in_series()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner","text":"","title":"local_planner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.floodfill_based_planner","text":"","title":"floodfill_based_planner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.floodfill_based_planner.FloodfillBasedPlanner","text":"","title":"FloodfillBasedPlanner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.floodfill_based_planner.FloodfillBasedPlanner.run_in_series","text":"On every step, produce an actionable plan Returns: Type Description VehicleControl Source code in ROAR/planning_module/local_planner/floodfill_based_planner.py def run_in_series ( self ) -> VehicleControl : pass","title":"run_in_series()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.local_planner","text":"","title":"local_planner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.local_planner.LocalPlanner","text":"","title":"LocalPlanner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.local_planner.LocalPlanner.__init__","text":"Source code in ROAR/planning_module/local_planner/local_planner.py def __init__ ( self , agent , controller : Optional [ Controller ] = None , behavior_planner : Optional [ BehaviorPlanner ] = None , mission_planner : Optional [ MissionPlanner ] = None , ** kwargs ): super () . __init__ ( agent = agent , ** kwargs ) self . controller = ( Controller ( agent = agent ) if controller is None else controller ) self . behavior_planner = ( BehaviorPlanner ( agent = agent ) if behavior_planner is None else behavior_planner ) self . mission_planner = ( MissionPlanner ( agent = agent ) if mission_planner is None else mission_planner ) self . way_points_queue = deque ()","title":"__init__()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.local_planner.LocalPlanner.run_in_series","text":"On every step, produce an actionable plan Returns: Type Description VehicleControl Source code in ROAR/planning_module/local_planner/local_planner.py @abstractmethod def run_in_series ( self ) -> VehicleControl : return VehicleControl ()","title":"run_in_series()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.simple_waypoint_following_local_planner","text":"","title":"simple_waypoint_following_local_planner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.simple_waypoint_following_local_planner.SimpleWaypointFollowingLocalPlanner","text":"","title":"SimpleWaypointFollowingLocalPlanner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.simple_waypoint_following_local_planner.SimpleWaypointFollowingLocalPlanner.__init__","text":"Initialize Simple Waypoint Following Planner Parameters: Name Type Description Default agent Agent newest agent state required controller Controller Control module used required mission_planner MissionPlanner mission planner used required behavior_planner BehaviorPlanner behavior planner used required closeness_threshold how close can a waypoint be with the vehicle 0.5 Source code in ROAR/planning_module/local_planner/simple_waypoint_following_local_planner.py def __init__ ( self , agent : Agent , controller : Controller , mission_planner : MissionPlanner , behavior_planner : BehaviorPlanner , closeness_threshold = 0.5 , ): \"\"\" Initialize Simple Waypoint Following Planner Args: agent: newest agent state controller: Control module used mission_planner: mission planner used behavior_planner: behavior planner used closeness_threshold: how close can a waypoint be with the vehicle \"\"\" super () . __init__ ( agent = agent , controller = controller , mission_planner = mission_planner , behavior_planner = behavior_planner , ) self . logger = logging . getLogger ( \"SimplePathFollowingLocalPlanner\" ) self . set_mission_plan () self . logger . debug ( \"Simple Path Following Local Planner Initiated\" ) self . closeness_threshold = closeness_threshold self . closeness_threshold_config = json . load ( Path ( agent . agent_settings . simple_waypoint_local_planner_config_file_path ) . open ( mode = 'r' ))","title":"__init__()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.simple_waypoint_following_local_planner.SimpleWaypointFollowingLocalPlanner.is_done","text":"If there are nothing in self.way_points_queue, that means you have finished a lap, you are done Returns: Type Description bool True if Done, False otherwise Source code in ROAR/planning_module/local_planner/simple_waypoint_following_local_planner.py def is_done ( self ) -> bool : \"\"\" If there are nothing in self.way_points_queue, that means you have finished a lap, you are done Returns: True if Done, False otherwise \"\"\" return len ( self . way_points_queue ) == 0","title":"is_done()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.simple_waypoint_following_local_planner.SimpleWaypointFollowingLocalPlanner.run_in_series","text":"Procedure Sync data get the correct look ahead for current speed get the correct next waypoint feed waypoint into controller return result from controller Returns: Type Description VehicleControl next control that the local think the agent should execute. Source code in ROAR/planning_module/local_planner/simple_waypoint_following_local_planner.py def run_in_series ( self ) -> VehicleControl : \"\"\" Run step for the local planner Procedure: 1. Sync data 2. get the correct look ahead for current speed 3. get the correct next waypoint 4. feed waypoint into controller 5. return result from controller Returns: next control that the local think the agent should execute. \"\"\" if ( len ( self . mission_planner . mission_plan ) == 0 and len ( self . way_points_queue ) == 0 ): return VehicleControl () # get vehicle's location vehicle_transform : Union [ Transform , None ] = self . agent . vehicle . transform if vehicle_transform is None : raise AgentException ( \"I do not know where I am, I cannot proceed forward\" ) # redefine closeness level based on speed self . set_closeness_threhold ( self . closeness_threshold_config ) # get current waypoint curr_closest_dist = float ( \"inf\" ) while True : if len ( self . way_points_queue ) == 0 : self . logger . info ( \"Destination reached\" ) return VehicleControl () waypoint : Transform = self . way_points_queue [ 0 ] curr_dist = vehicle_transform . location . distance ( waypoint . location ) if curr_dist < curr_closest_dist : # if i find a waypoint that is closer to me than before # note that i will always enter here to start the calculation for curr_closest_dist curr_closest_dist = curr_dist elif curr_dist < self . closeness_threshold : # i have moved onto a waypoint, remove that waypoint from the queue self . way_points_queue . popleft () else : break target_waypoint = self . way_points_queue [ 0 ] control : VehicleControl = self . controller . run_in_series ( next_waypoint = target_waypoint ) self . logger . debug ( f \" \\n \" f \"Curr Transform: { self . agent . vehicle . transform } \\n \" f \"Target Location: { target_waypoint . location } \\n \" f \"Control: { control } | Speed: { Vehicle . get_speed ( self . agent . vehicle ) } \\n \" ) return control","title":"run_in_series()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.simple_waypoint_following_local_planner.SimpleWaypointFollowingLocalPlanner.set_closeness_threhold","text":"Source code in ROAR/planning_module/local_planner/simple_waypoint_following_local_planner.py def set_closeness_threhold ( self , config : dict ): curr_speed = Vehicle . get_speed ( self . agent . vehicle ) for speed_upper_bound , closeness_threshold in config . items (): speed_upper_bound = float ( speed_upper_bound ) if curr_speed < speed_upper_bound : self . closeness_threshold = closeness_threshold break","title":"set_closeness_threhold()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.local_planner.simple_waypoint_following_local_planner.SimpleWaypointFollowingLocalPlanner.set_mission_plan","text":"Clears current waypoints, and reset mission plan from start I am simply transferring the mission plan into my waypoint queue. Assuming that this current run will run all the way to the end Returns: Type Description None None Source code in ROAR/planning_module/local_planner/simple_waypoint_following_local_planner.py def set_mission_plan ( self ) -> None : \"\"\" Clears current waypoints, and reset mission plan from start I am simply transferring the mission plan into my waypoint queue. Assuming that this current run will run all the way to the end Returns: None \"\"\" self . way_points_queue . clear () while ( self . mission_planner . mission_plan ): # this actually clears the mission plan!! self . way_points_queue . append ( self . mission_planner . mission_plan . popleft ())","title":"set_mission_plan()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner","text":"","title":"mission_planner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.json_waypoint_planner","text":"","title":"json_waypoint_planner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.json_waypoint_planner.JSONWaypointPlanner","text":"","title":"JSONWaypointPlanner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.json_waypoint_planner.JSONWaypointPlanner.__init__","text":"Source code in ROAR/planning_module/mission_planner/json_waypoint_planner.py def __init__ ( self , agent : Agent ): super () . __init__ ( agent = agent ) self . file_path : Path = Path ( self . agent . agent_settings . json_waypoint_file_path ) self . mission_plan : deque = self . run_in_series ()","title":"__init__()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.json_waypoint_planner.JSONWaypointPlanner.run_in_series","text":"Abstract run step function for Mission Planner Parameters: Name Type Description Default vehicle new vehicle state required Returns: Type Description deque Plan for next steps Source code in ROAR/planning_module/mission_planner/json_waypoint_planner.py def run_in_series ( self ) -> deque : result = deque () map_entries = self . _read_data_file () for m in map_entries : result . append ( self . _map_entry_to_transform ( map_entry = m )) return result","title":"run_in_series()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.mission_planner","text":"","title":"mission_planner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.mission_planner.MissionPlanner","text":"","title":"MissionPlanner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.mission_planner.MissionPlanner.__init__","text":"Source code in ROAR/planning_module/mission_planner/mission_planner.py def __init__ ( self , agent , ** kwargs ): super () . __init__ ( agent = agent , ** kwargs ) self . logger = logging . getLogger ( __name__ ) self . mission_plan : deque = deque ()","title":"__init__()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.mission_planner.MissionPlanner.run_in_series","text":"Abstract run step function for Mission Planner Parameters: Name Type Description Default vehicle new vehicle state required Returns: Type Description List[ROAR.utilities_module.data_structures_models.Transform] Plan for next steps Source code in ROAR/planning_module/mission_planner/mission_planner.py def run_in_series ( self ) -> List [ Transform ]: \"\"\" Abstract run step function for Mission Planner Args: vehicle: new vehicle state Returns: Plan for next steps \"\"\" return []","title":"run_in_series()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.waypoint_following_mission_planner","text":"","title":"waypoint_following_mission_planner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.waypoint_following_mission_planner.WaypointFollowingMissionPlanner","text":"A mission planner that takes in a file that contains x,y,z coordinates, formulate into carla.Transform","title":"WaypointFollowingMissionPlanner"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.waypoint_following_mission_planner.WaypointFollowingMissionPlanner.__init__","text":"Source code in ROAR/planning_module/mission_planner/waypoint_following_mission_planner.py def __init__ ( self , agent : Agent ): super () . __init__ ( agent = agent ) self . logger = logging . getLogger ( __name__ ) self . file_path : Path = Path ( self . agent . agent_settings . waypoint_file_path ) self . mission_plan = self . produce_mission_plan () self . logger . debug ( \"Path Following Mission Planner Initiated.\" )","title":"__init__()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.waypoint_following_mission_planner.WaypointFollowingMissionPlanner.produce_mission_plan","text":"Generates a list of waypoints based on the input file path :return a list of waypoint Source code in ROAR/planning_module/mission_planner/waypoint_following_mission_planner.py def produce_mission_plan ( self ) -> deque : \"\"\" Generates a list of waypoints based on the input file path :return a list of waypoint \"\"\" mission_plan = deque () raw_path : List [ List [ float ]] = self . _read_data_file () for coord in raw_path : if len ( coord ) == 3 or len ( coord ) == 6 : mission_plan . append ( self . _raw_coord_to_transform ( coord )) self . logger . debug ( f \"Computed Mission path of length [ { len ( mission_plan ) } ]\" ) return mission_plan","title":"produce_mission_plan()"},{"location":"code_documentations/ROAR/planning_module/#ROAR.planning_module.mission_planner.waypoint_following_mission_planner.WaypointFollowingMissionPlanner.run_in_series","text":"Regenerate waypoints from file Find the waypoint that is closest to the current vehicle location. return a mission plan starting from that waypoint Parameters: Name Type Description Default vehicle current state of the vehicle required Returns: Type Description deque mission plan that start from the current vehicle location Source code in ROAR/planning_module/mission_planner/waypoint_following_mission_planner.py def run_in_series ( self ) -> deque : \"\"\" Regenerate waypoints from file Find the waypoint that is closest to the current vehicle location. return a mission plan starting from that waypoint Args: vehicle: current state of the vehicle Returns: mission plan that start from the current vehicle location \"\"\" super ( WaypointFollowingMissionPlanner , self ) . run_in_series () self . logger . debug ( \"TO BE IMPLEMENTED\" ) return self . produce_mission_plan ()","title":"run_in_series()"},{"location":"code_documentations/ROAR/utilities_module/","text":"camera_models \u00a4 Camera pydantic-model \u00a4 data : ndarray pydantic-field \u00a4 distortion_coefficient : ndarray pydantic-field \u00a4 fov : int pydantic-field \u00a4 image_size_x : int pydantic-field \u00a4 image_size_y : int pydantic-field \u00a4 intrinsics_matrix : ndarray pydantic-field \u00a4 transform : Transform pydantic-field \u00a4 __config__ \u00a4 Config \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 calculate_default_intrinsics_matrix ( self ) \u00a4 Calculate intrinsics matrix Will set the attribute intrinsic matrix so that re-calculation is not necessary. https://github.com/carla-simulator/carla/issues/56 [ ax, 0, cx, 0, ay, cy, 0 , 0, 1 ] Returns: Type Description ndarray Intrinsics_matrix Source code in ROAR/utilities_module/camera_models.py def calculate_default_intrinsics_matrix ( self ) -> np . ndarray : \"\"\" Calculate intrinsics matrix Will set the attribute intrinsic matrix so that re-calculation is not necessary. https://github.com/carla-simulator/carla/issues/56 [ ax, 0, cx, 0, ay, cy, 0 , 0, 1 ] Returns: Intrinsics_matrix \"\"\" intrinsics_matrix = np . identity ( 3 ) intrinsics_matrix [ 0 , 2 ] = self . image_size_x / 2.0 intrinsics_matrix [ 1 , 2 ] = self . image_size_y / 2.0 intrinsics_matrix [ 0 , 0 ] = self . image_size_x / ( 2.0 * np . tan ( self . fov * np . pi / 360.0 ) ) intrinsics_matrix [ 1 , 1 ] = self . image_size_y / ( 2.0 * np . tan ( self . fov * np . pi / 360.0 ) ) self . intrinsics_matrix = intrinsics_matrix return intrinsics_matrix visualize ( self , title = 'CameraData' , duration = 1 ) \u00a4 Visualize camera data. Parameters: Name Type Description Default title title of cv2 image 'CameraData' duration in milisecond 1 Returns: Type Description None None Source code in ROAR/utilities_module/camera_models.py def visualize ( self , title = \"CameraData\" , duration = 1 ) -> None : \"\"\" Visualize camera data. Args: title: title of cv2 image duration: in milisecond Returns: None \"\"\" if self . data is not None : cv2 . imshow ( title , self . data . data ) cv2 . waitKey ( duration ) data_structures_models \u00a4 DepthData pydantic-model \u00a4 data : ndarray pydantic-field required \u00a4 Array of size (WIDTH, HEIGHT, 3) __config__ \u00a4 Config \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 IMUData pydantic-model \u00a4 accelerometer : Vector3D pydantic-field \u00a4 Linear acceleration in m/s^2 gyroscope : Vector3D pydantic-field \u00a4 Angular velocity in rad/sec __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 Location pydantic-model \u00a4 x : float pydantic-field required \u00a4 Distance in meters from origin to spot on X axis y : float pydantic-field required \u00a4 Distance in meters from origin to spot on Y axis z : float pydantic-field required \u00a4 Distance in meters from origin to spot on Z axis __config__ \u00a4 __add__ ( self , other ) special \u00a4 Source code in ROAR/utilities_module/data_structures_models.py def __add__ ( self , other ): \"\"\"\"\"\" return Location ( x = self . x + other . x , y = self . y + other . y , z = self . z + other . z ) __json_encoder__ ( obj ) special staticmethod \u00a4 __str__ ( self ) special \u00a4 Return str(self). Source code in ROAR/utilities_module/data_structures_models.py def __str__ ( self ): return f \"x: { self . x : .3 } , y: { self . y : .3 } , z: { self . z : .3 } \" distance ( self , other_location ) \u00a4 Euclidean distance between current location and other location Source code in ROAR/utilities_module/data_structures_models.py def distance ( self , other_location ): \"\"\"Euclidean distance between current location and other location\"\"\" return distance . euclidean ( ( self . x , self . y , self . z ), ( other_location . x , other_location . y , other_location . z ), ) to_array ( self ) \u00a4 Source code in ROAR/utilities_module/data_structures_models.py def to_array ( self ) -> np . array : return np . array ([ self . x , self . y , self . z ]) MapEntry pydantic-model \u00a4 point_a : float pydantic-field required \u00a4 point_b : float pydantic-field required \u00a4 __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 RGBData pydantic-model \u00a4 data : ndarray pydantic-field required \u00a4 Array of size (WIDTH, HEIGHT, 3) __config__ \u00a4 Config \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 Rotation pydantic-model \u00a4 pitch : float pydantic-field required \u00a4 Degree around the Y-axis roll : float pydantic-field required \u00a4 Degree around the X-axis yaw : float pydantic-field required \u00a4 Degree around the Z-axis __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 __str__ ( self ) special \u00a4 Return str(self). Source code in ROAR/utilities_module/data_structures_models.py def __str__ ( self ): return f \"Roll: { round ( self . roll , 2 ) } , Pitch: { round ( self . pitch , 2 ) } , Yaw: { round ( self . yaw , 2 ) } \" to_array ( self ) \u00a4 Source code in ROAR/utilities_module/data_structures_models.py def to_array ( self ) -> np . array : return np . array ([ self . pitch , self . yaw , self . roll ]) SensorsData pydantic-model \u00a4 front_depth : DepthData pydantic-field \u00a4 front_rgb : RGBData pydantic-field \u00a4 imu_data : IMUData pydantic-field \u00a4 rear_rgb : RGBData pydantic-field \u00a4 vive_tracker_data : ViveTrackerData pydantic-field \u00a4 __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 Transform pydantic-model \u00a4 location : Location pydantic-field \u00a4 rotation : Rotation pydantic-field \u00a4 __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 __str__ ( self ) special \u00a4 Return str(self). Source code in ROAR/utilities_module/data_structures_models.py def __str__ ( self ): return f \"Location: { self . location . __str__ () } | Rotation: { self . rotation . __str__ () } \" get_matrix ( self ) \u00a4 Calculate extrinsics matrix with respect to parent object http://planning.cs.uiuc.edu/node104.html Returns: Type Description ndarray Extrinsics matrix Source code in ROAR/utilities_module/data_structures_models.py def get_matrix ( self ) -> np . ndarray : \"\"\" Calculate extrinsics matrix with respect to parent object http://planning.cs.uiuc.edu/node104.html Returns: Extrinsics matrix \"\"\" location = self . location rotation = self . rotation yaw , pitch , roll = rotation . yaw , rotation . pitch , rotation . roll c_y = np . cos ( np . radians ( yaw )) s_y = np . sin ( np . radians ( yaw )) c_r = np . cos ( np . radians ( roll )) s_r = np . sin ( np . radians ( roll )) c_p = np . cos ( np . radians ( pitch )) s_p = np . sin ( np . radians ( pitch )) matrix = np . identity ( 4 ) matrix [ 0 , 3 ] = location . x matrix [ 1 , 3 ] = location . y matrix [ 2 , 3 ] = location . z matrix [ 0 , 0 ] = c_p * c_y matrix [ 0 , 1 ] = c_y * s_p * s_r - s_y * c_r matrix [ 0 , 2 ] = - c_y * s_p * c_r - s_y * s_r matrix [ 1 , 0 ] = s_y * c_p matrix [ 1 , 1 ] = s_y * s_p * s_r + c_y * c_r matrix [ 1 , 2 ] = - s_y * s_p * c_r + c_y * s_r matrix [ 2 , 0 ] = s_p matrix [ 2 , 1 ] = - c_p * s_r matrix [ 2 , 2 ] = c_p * c_r return matrix record ( self ) \u00a4 Source code in ROAR/utilities_module/data_structures_models.py def record ( self ): return f \" { self . location . x } , { self . location . y } , { self . location . z } , { self . rotation . roll } , { self . rotation . pitch } , { self . rotation . yaw } \" Vector3D pydantic-model \u00a4 x : float pydantic-field \u00a4 y : float pydantic-field \u00a4 z : float pydantic-field \u00a4 __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 to_array ( self ) \u00a4 Source code in ROAR/utilities_module/data_structures_models.py def to_array ( self ): return np . array ([ self . x , self . y , self . z ]) ViveTrackerData pydantic-model \u00a4 location : Location pydantic-field \u00a4 rotation : Rotation pydantic-field \u00a4 tracker_name : str pydantic-field \u00a4 velocity : Vector3D pydantic-field required \u00a4 __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 errors \u00a4 AgentException \u00a4 localization_map \u00a4 module \u00a4 Module \u00a4 __init__ ( self , threaded = False ) special \u00a4 Source code in ROAR/utilities_module/module.py def __init__ ( self , threaded = False ): self . threaded = threaded run_in_series ( self , ** kwargs ) \u00a4 This is the none-threaded function. It run in series! Parameters: Name Type Description Default **kwargs {} Source code in ROAR/utilities_module/module.py @abstractmethod def run_in_series ( self , ** kwargs ): \"\"\" This is the none-threaded function. It run in series! Args: **kwargs: Returns: \"\"\" pass run_in_threaded ( self , ** kwargs ) \u00a4 This is the threaded function. Parameters: Name Type Description Default **kwargs {} Source code in ROAR/utilities_module/module.py @abstractmethod def run_in_threaded ( self , ** kwargs ): \"\"\" This is the threaded function. Args: **kwargs: Returns: \"\"\" pass shutdown ( self ) \u00a4 Source code in ROAR/utilities_module/module.py def shutdown ( self ): pass occupancy_map \u00a4 OccupancyGridMap \u00a4 A 2D Occupancy Grid Map representing the world Should be able to handle 1. Transformation of coordinate from world to grid cord 2. Transformation of cord from grid cord to world cord 3. Represent the vehicle size and position, vehicle is represented as 0 Note that this class does NOT remember the vehicle position, in order to visualize vehicle, vehicle position has to be passed in 4. Represent the obstacles' position once its world coordinate is given 5. Represent free space's position, once its world coordinate is given 6. visualize itself, including zoom to a certain area so that not the entire map is visualized 7. The range of values should be bewteen 0 - 1 - 0 = obstacles, 1 = free space 8 Failure tolerant, if I pass in a wrong world coordinate, it will prompt it, but do not fail. Similar with other functions in this class 9. Fixed map size for enhanced performance __init__ ( self , absolute_maximum_map_size , map_padding = 40 , vehicle_width = 5 , vehicle_height = 5 ) special \u00a4 Parameters: Name Type Description Default absolute_maximum_map_size Absolute maximum size of the map, will be used to compute a square occupancy map required map_padding int additional padding intended to add. 40 Note: This method pad to both sides, for example, it create padding to the left of min_x, and to the right of max_x Note: map_padding is for when when visualizing, we have to take a whole block and just in case the route is to the edge of the map, it will not error out Source code in ROAR/utilities_module/occupancy_map.py def __init__ ( self , absolute_maximum_map_size , map_padding : int = 40 , vehicle_width = 5 , vehicle_height = 5 ): \"\"\" Args: absolute_maximum_map_size: Absolute maximum size of the map, will be used to compute a square occupancy map map_padding: additional padding intended to add. Note: This method pad to both sides, for example, it create padding to the left of min_x, and to the right of max_x Note: map_padding is for when when visualizing, we have to take a whole block and just in case the route is to the edge of the map, it will not error out \"\"\" self . logger = logging . getLogger ( __name__ ) self . map : Optional [ np . ndarray ] = None self . _absolute_maximum_map_size = absolute_maximum_map_size self . _min_x = - math . floor ( self . _absolute_maximum_map_size ) self . _min_y = - math . floor ( self . _absolute_maximum_map_size ) self . _max_x = math . ceil ( self . _absolute_maximum_map_size ) self . _max_y = math . ceil ( self . _absolute_maximum_map_size ) self . _map_additiona_padding = map_padding self . vehicle_width = vehicle_width self . vehicle_height = vehicle_height self . _initialize_map () cord_translation_from_world ( self , world_cords_xy ) \u00a4 Translate from world coordinate to occupancy coordinate If the given world coord is less than min or greater than maximum, then do not execute the translation, log error message Parameters: Name Type Description Default world_cords_xy ndarray Numpy array of shape (N, 2) representing [[x, y], [x, y], ...] required Returns: Type Description ndarray occupancy grid map coordinate for this world coordinate of shape (N, 2) [ [x, y], [x, y] ] Source code in ROAR/utilities_module/occupancy_map.py def cord_translation_from_world ( self , world_cords_xy : np . ndarray ) -> np . ndarray : \"\"\" Translate from world coordinate to occupancy coordinate If the given world coord is less than min or greater than maximum, then do not execute the translation, log error message Args: world_cords_xy: Numpy array of shape (N, 2) representing [[x, y], [x, y], ...] Returns: occupancy grid map coordinate for this world coordinate of shape (N, 2) [ [x, y], [x, y] ] \"\"\" # reshape input into a ndarray that looks like [[X, Y], [X, Y]...] # self.logger.debug(f\"translating world cords xy: {np.shape(world_cords_xy)}\") transformed = np . round ( world_cords_xy - [ self . _min_x , self . _min_y ]) . astype ( np . int64 ) return transformed location_to_occu_cord ( self , location ) \u00a4 Converts World coordinate to coordinate in Occupancy Grid Map Source code in ROAR/utilities_module/occupancy_map.py def location_to_occu_cord ( self , location : Location ): \"\"\"Converts World coordinate to coordinate in Occupancy Grid Map\"\"\" return self . cord_translation_from_world ( world_cords_xy = np . array ([[ location . x , location . y ]])) update_grid_map ( self , depth_img , camera , vehicle ) \u00a4 This is an easier to use update_grid_map method that can be directly called by an agent It will update grid map using the update_grid_map_from_world_cord method Parameters: Name Type Description Default depth_img current depth map required camera Camera camera state required vehicle Vehicle vehicle state required Returns: Type Description None Source code in ROAR/utilities_module/occupancy_map.py def update_grid_map ( self , depth_img , camera : Camera , vehicle : Vehicle ): \"\"\" This is an easier to use update_grid_map method that can be directly called by an agent It will update grid map using the update_grid_map_from_world_cord method Args: depth_img: current depth map camera: camera state vehicle: vehicle state Returns: None \"\"\" world_cords = img_to_world ( depth_img = depth_img , intrinsics_matrix = camera . intrinsics_matrix , extrinsics_matrix = camera . transform . get_matrix () @ vehicle . transform . get_matrix () ) self . update_grid_map_from_world_cord ( world_cords_xy = world_cords [: 2 , :] . T ) update_grid_map_from_world_cord ( self , world_cords_xy ) \u00a4 Updates the grid map based on the world coordinates passed in Parameters: Name Type Description Default world_cords_xy Numpy array of shape (N, 2) representing [[x, y], [x, y], ...] required Returns: Type Description None Source code in ROAR/utilities_module/occupancy_map.py def update_grid_map_from_world_cord ( self , world_cords_xy ): \"\"\" Updates the grid map based on the world coordinates passed in Args: world_cords_xy: Numpy array of shape (N, 2) representing [[x, y], [x, y], ...] Returns: None \"\"\" # find occupancy map cords # self.logger.debug(f\"Updating Grid Map: {np.shape(world_cords_xy)}\") occu_cords = self . cord_translation_from_world ( world_cords_xy = world_cords_xy ) # self.logger.debug(f\"Occupancy Grid Map Cord shape = {np.shape(occu_cords)}\") self . map [ occu_cords [:, 1 ], occu_cords [:, 0 ]] = 1 visualize ( self , vehicle_location = None , view_size = 200 ) \u00a4 Source code in ROAR/utilities_module/occupancy_map.py def visualize ( self , vehicle_location : Optional [ Location ] = None , view_size = 200 ): if vehicle_location is None : cv2 . imshow ( \"Occupancy Grid Map\" , self . map ) else : occu_cord = self . location_to_occu_cord ( location = vehicle_location ) map_copy = self . map . copy () x , y = occu_cord [ 0 ] map_copy [ y - self . vehicle_height // 2 : y + self . vehicle_height // 2 , x - self . vehicle_width // 2 : x + self . vehicle_width // 2 ] = 0 cv2 . imshow ( \"Occupancy Grid Map\" , map_copy [ y - view_size // 2 : y + view_size // 2 :, x - view_size // 2 : x + view_size // 2 ]) cv2 . waitKey ( 1 ) track_visualizer \u00a4 The purpose of this file is to take in a txt file in containing data x,y,z,roll,pitch,yaw or x,y,z ... and visualize the track read_txt ( file_path ) \u00a4 Source code in ROAR/utilities_module/track_visualizer.py def read_txt ( file_path : Path ) -> List [ List [ float ]]: if file_path . exists () is False : raise FileNotFoundError ( f \" { file_path } is not found. Please double check\" ) file = file_path . open ( 'r' ) result : List [ List [ float ]] = [] for line in file . readlines (): try : x , y , z = line . split ( sep = ',' ) except Exception as e : x , y , z , roll , pitch , yaw = line . split ( sep = ',' ) result . append ([ float ( x ), float ( y ), float ( z )]) return result visualize_track_data ( track_data ) \u00a4 Source code in ROAR/utilities_module/track_visualizer.py def visualize_track_data ( track_data : List [ List [ float ]]): print ( f \"Visualizing [ { len ( track_data ) } ] data points\" ) track_data = np . asarray ( track_data ) fig = go . Figure ( data = [ go . Scatter3d ( x = track_data [:, 0 ], y = [ 0 ] * len ( track_data ), z = track_data [:, 2 ], mode = 'markers' )]) fig . show () utilities \u00a4 img_to_world ( depth_img , intrinsics_matrix , extrinsics_matrix , sky_level = 0.9 , depth_scaling_factor = 1000 ) \u00a4 Source code in ROAR/utilities_module/utilities.py def img_to_world ( depth_img , intrinsics_matrix , extrinsics_matrix , sky_level = 0.9 , depth_scaling_factor = 1000 ) -> np . ndarray : # get a 2 x N array for their indices ground_loc = np . where ( depth_img < sky_level ) depth_val = depth_img [ depth_img < sky_level ] * depth_scaling_factor ground_loc = ground_loc * depth_val # compute raw_points raw_points = np . vstack ([ ground_loc , depth_val ]) # convert to cords_y_minus_z_x cords_y_minus_z_x = np . linalg . inv ( intrinsics_matrix ) @ raw_points # convert to cords_xyz_1 ones = np . ones (( 1 , np . shape ( cords_y_minus_z_x )[ 1 ])) cords_xyz_1 = np . vstack ([ cords_y_minus_z_x [ 2 , :], cords_y_minus_z_x [ 0 , :], - cords_y_minus_z_x [ 1 , :], ones ]) # multiply by cam_world_matrix points = extrinsics_matrix @ cords_xyz_1 # i have all points now return points img_to_world2 ( depth_img , intrinsics_matrix , extrinsics_matrix , segmentation , criteria , depth_scaling_factor = 1000 ) \u00a4 Source code in ROAR/utilities_module/utilities.py def img_to_world2 ( depth_img , intrinsics_matrix , extrinsics_matrix , segmentation : np . ndarray , criteria , depth_scaling_factor = 1000 ) -> np . ndarray : # get a 2 x N array for their indices ground_loc = np . where ( segmentation == criteria )[: 2 ] # print(ground) # ground_loc = np.where(depth_img == criteria) depth_val = depth_img [ ground_loc ] * depth_scaling_factor ground_loc = ground_loc * depth_val # compute raw_points raw_points = np . vstack ([ ground_loc , depth_val ]) # convert to cords_y_minus_z_x cords_y_minus_z_x = np . linalg . inv ( intrinsics_matrix ) @ raw_points # convert to cords_xyz_1 ones = np . ones (( 1 , np . shape ( cords_y_minus_z_x )[ 1 ])) cords_xyz_1 = np . vstack ([ cords_y_minus_z_x [ 2 , :], cords_y_minus_z_x [ 0 , :], - cords_y_minus_z_x [ 1 , :], ones ]) # multiply by cam_world_matrix points = extrinsics_matrix @ cords_xyz_1 # i have all points now return points png_to_depth ( im ) \u00a4 Takes in an image read from cv2.imread(), whose output is simply a numpy array, turn it into a depth image according to carla's method of (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1). Parameters: Name Type Description Default im <built-in function array> input image, read from cv2.imread() required Returns: Type Description <built-in function array> depth image Source code in ROAR/utilities_module/utilities.py def png_to_depth ( im : np . array ) -> np . array : \"\"\" Takes in an image read from cv2.imread(), whose output is simply a numpy array, turn it into a depth image according to carla's method of (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1). Args: im: input image, read from cv2.imread() Returns: depth image \"\"\" im = im . astype ( np . float64 ) normalized_depth = np . dot ( im [:, :, : 3 ], [ 1 , 256 , 65536.0 ]) normalized_depth /= 16777215.0 return normalized_depth vehicle_models \u00a4 Vehicle pydantic-model \u00a4 Encodes the Vehicle's state at the last tick control : VehicleControl pydantic-field \u00a4 transform : Transform pydantic-field \u00a4 velocity : Vector3D pydantic-field \u00a4 wheel_base : float pydantic-field \u00a4 Default to tesla model 3's wheel base __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 get_speed ( vehicle ) staticmethod \u00a4 Compute speed of a vehicle in Km/h. :param vehicle: the vehicle for which speed is calculated :return: speed as a float in Km/h Source code in ROAR/utilities_module/vehicle_models.py @staticmethod def get_speed ( vehicle ): # TODO consider the jetson case \"\"\" Compute speed of a vehicle in Km/h. :param vehicle: the vehicle for which speed is calculated :return: speed as a float in Km/h \"\"\" vel = vehicle . velocity return 3.6 * math . sqrt ( vel . x ** 2 + vel . y ** 2 + vel . z ** 2 ) VehicleControl pydantic-model \u00a4 steering : float pydantic-field \u00a4 throttle : float pydantic-field \u00a4 __config__ \u00a4 __json_encoder__ ( obj ) special staticmethod \u00a4 clamp ( n , minn , maxn ) staticmethod \u00a4 Source code in ROAR/utilities_module/vehicle_models.py @staticmethod def clamp ( n , minn , maxn ): return max ( min ( maxn , n ), minn ) get_steering ( self ) \u00a4 Cap it between -1 and 1 :return: Source code in ROAR/utilities_module/vehicle_models.py def get_steering ( self ) -> float : \"\"\" Cap it between -1 and 1 :return: \"\"\" return self . clamp ( self . steering , - 1 , 1 ) get_throttle ( self ) \u00a4 Cap it between -1 and 1 :return: Source code in ROAR/utilities_module/vehicle_models.py def get_throttle ( self ) -> float : \"\"\" Cap it between -1 and 1 :return: \"\"\" return self . clamp ( self . throttle , - 1 , 1 )","title":"Utilities Module"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models","text":"","title":"camera_models"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera","text":"","title":"Camera"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera.data","text":"","title":"data"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera.distortion_coefficient","text":"","title":"distortion_coefficient"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera.fov","text":"","title":"fov"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera.image_size_x","text":"","title":"image_size_x"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera.image_size_y","text":"","title":"image_size_y"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera.intrinsics_matrix","text":"","title":"intrinsics_matrix"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera.transform","text":"","title":"transform"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera.Config","text":"","title":"Config"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera.calculate_default_intrinsics_matrix","text":"Calculate intrinsics matrix Will set the attribute intrinsic matrix so that re-calculation is not necessary. https://github.com/carla-simulator/carla/issues/56 [ ax, 0, cx, 0, ay, cy, 0 , 0, 1 ] Returns: Type Description ndarray Intrinsics_matrix Source code in ROAR/utilities_module/camera_models.py def calculate_default_intrinsics_matrix ( self ) -> np . ndarray : \"\"\" Calculate intrinsics matrix Will set the attribute intrinsic matrix so that re-calculation is not necessary. https://github.com/carla-simulator/carla/issues/56 [ ax, 0, cx, 0, ay, cy, 0 , 0, 1 ] Returns: Intrinsics_matrix \"\"\" intrinsics_matrix = np . identity ( 3 ) intrinsics_matrix [ 0 , 2 ] = self . image_size_x / 2.0 intrinsics_matrix [ 1 , 2 ] = self . image_size_y / 2.0 intrinsics_matrix [ 0 , 0 ] = self . image_size_x / ( 2.0 * np . tan ( self . fov * np . pi / 360.0 ) ) intrinsics_matrix [ 1 , 1 ] = self . image_size_y / ( 2.0 * np . tan ( self . fov * np . pi / 360.0 ) ) self . intrinsics_matrix = intrinsics_matrix return intrinsics_matrix","title":"calculate_default_intrinsics_matrix()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.camera_models.Camera.visualize","text":"Visualize camera data. Parameters: Name Type Description Default title title of cv2 image 'CameraData' duration in milisecond 1 Returns: Type Description None None Source code in ROAR/utilities_module/camera_models.py def visualize ( self , title = \"CameraData\" , duration = 1 ) -> None : \"\"\" Visualize camera data. Args: title: title of cv2 image duration: in milisecond Returns: None \"\"\" if self . data is not None : cv2 . imshow ( title , self . data . data ) cv2 . waitKey ( duration )","title":"visualize()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models","text":"","title":"data_structures_models"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.DepthData","text":"","title":"DepthData"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.DepthData.data","text":"Array of size (WIDTH, HEIGHT, 3)","title":"data"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.DepthData.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.DepthData.Config","text":"","title":"Config"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.DepthData.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.IMUData","text":"","title":"IMUData"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.IMUData.accelerometer","text":"Linear acceleration in m/s^2","title":"accelerometer"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.IMUData.gyroscope","text":"Angular velocity in rad/sec","title":"gyroscope"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.IMUData.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.IMUData.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Location","text":"","title":"Location"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Location.x","text":"Distance in meters from origin to spot on X axis","title":"x"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Location.y","text":"Distance in meters from origin to spot on Y axis","title":"y"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Location.z","text":"Distance in meters from origin to spot on Z axis","title":"z"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Location.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Location.__add__","text":"Source code in ROAR/utilities_module/data_structures_models.py def __add__ ( self , other ): \"\"\"\"\"\" return Location ( x = self . x + other . x , y = self . y + other . y , z = self . z + other . z )","title":"__add__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Location.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Location.__str__","text":"Return str(self). Source code in ROAR/utilities_module/data_structures_models.py def __str__ ( self ): return f \"x: { self . x : .3 } , y: { self . y : .3 } , z: { self . z : .3 } \"","title":"__str__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Location.distance","text":"Euclidean distance between current location and other location Source code in ROAR/utilities_module/data_structures_models.py def distance ( self , other_location ): \"\"\"Euclidean distance between current location and other location\"\"\" return distance . euclidean ( ( self . x , self . y , self . z ), ( other_location . x , other_location . y , other_location . z ), )","title":"distance()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Location.to_array","text":"Source code in ROAR/utilities_module/data_structures_models.py def to_array ( self ) -> np . array : return np . array ([ self . x , self . y , self . z ])","title":"to_array()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.MapEntry","text":"","title":"MapEntry"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.MapEntry.point_a","text":"","title":"point_a"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.MapEntry.point_b","text":"","title":"point_b"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.MapEntry.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.MapEntry.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.RGBData","text":"","title":"RGBData"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.RGBData.data","text":"Array of size (WIDTH, HEIGHT, 3)","title":"data"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.RGBData.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.RGBData.Config","text":"","title":"Config"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.RGBData.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Rotation","text":"","title":"Rotation"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Rotation.pitch","text":"Degree around the Y-axis","title":"pitch"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Rotation.roll","text":"Degree around the X-axis","title":"roll"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Rotation.yaw","text":"Degree around the Z-axis","title":"yaw"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Rotation.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Rotation.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Rotation.__str__","text":"Return str(self). Source code in ROAR/utilities_module/data_structures_models.py def __str__ ( self ): return f \"Roll: { round ( self . roll , 2 ) } , Pitch: { round ( self . pitch , 2 ) } , Yaw: { round ( self . yaw , 2 ) } \"","title":"__str__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Rotation.to_array","text":"Source code in ROAR/utilities_module/data_structures_models.py def to_array ( self ) -> np . array : return np . array ([ self . pitch , self . yaw , self . roll ])","title":"to_array()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.SensorsData","text":"","title":"SensorsData"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.SensorsData.front_depth","text":"","title":"front_depth"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.SensorsData.front_rgb","text":"","title":"front_rgb"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.SensorsData.imu_data","text":"","title":"imu_data"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.SensorsData.rear_rgb","text":"","title":"rear_rgb"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.SensorsData.vive_tracker_data","text":"","title":"vive_tracker_data"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.SensorsData.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.SensorsData.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Transform","text":"","title":"Transform"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Transform.location","text":"","title":"location"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Transform.rotation","text":"","title":"rotation"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Transform.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Transform.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Transform.__str__","text":"Return str(self). Source code in ROAR/utilities_module/data_structures_models.py def __str__ ( self ): return f \"Location: { self . location . __str__ () } | Rotation: { self . rotation . __str__ () } \"","title":"__str__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Transform.get_matrix","text":"Calculate extrinsics matrix with respect to parent object http://planning.cs.uiuc.edu/node104.html Returns: Type Description ndarray Extrinsics matrix Source code in ROAR/utilities_module/data_structures_models.py def get_matrix ( self ) -> np . ndarray : \"\"\" Calculate extrinsics matrix with respect to parent object http://planning.cs.uiuc.edu/node104.html Returns: Extrinsics matrix \"\"\" location = self . location rotation = self . rotation yaw , pitch , roll = rotation . yaw , rotation . pitch , rotation . roll c_y = np . cos ( np . radians ( yaw )) s_y = np . sin ( np . radians ( yaw )) c_r = np . cos ( np . radians ( roll )) s_r = np . sin ( np . radians ( roll )) c_p = np . cos ( np . radians ( pitch )) s_p = np . sin ( np . radians ( pitch )) matrix = np . identity ( 4 ) matrix [ 0 , 3 ] = location . x matrix [ 1 , 3 ] = location . y matrix [ 2 , 3 ] = location . z matrix [ 0 , 0 ] = c_p * c_y matrix [ 0 , 1 ] = c_y * s_p * s_r - s_y * c_r matrix [ 0 , 2 ] = - c_y * s_p * c_r - s_y * s_r matrix [ 1 , 0 ] = s_y * c_p matrix [ 1 , 1 ] = s_y * s_p * s_r + c_y * c_r matrix [ 1 , 2 ] = - s_y * s_p * c_r + c_y * s_r matrix [ 2 , 0 ] = s_p matrix [ 2 , 1 ] = - c_p * s_r matrix [ 2 , 2 ] = c_p * c_r return matrix","title":"get_matrix()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Transform.record","text":"Source code in ROAR/utilities_module/data_structures_models.py def record ( self ): return f \" { self . location . x } , { self . location . y } , { self . location . z } , { self . rotation . roll } , { self . rotation . pitch } , { self . rotation . yaw } \"","title":"record()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Vector3D","text":"","title":"Vector3D"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Vector3D.x","text":"","title":"x"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Vector3D.y","text":"","title":"y"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Vector3D.z","text":"","title":"z"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Vector3D.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Vector3D.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.Vector3D.to_array","text":"Source code in ROAR/utilities_module/data_structures_models.py def to_array ( self ): return np . array ([ self . x , self . y , self . z ])","title":"to_array()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.ViveTrackerData","text":"","title":"ViveTrackerData"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.ViveTrackerData.location","text":"","title":"location"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.ViveTrackerData.rotation","text":"","title":"rotation"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.ViveTrackerData.tracker_name","text":"","title":"tracker_name"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.ViveTrackerData.velocity","text":"","title":"velocity"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.ViveTrackerData.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.data_structures_models.ViveTrackerData.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.errors","text":"","title":"errors"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.errors.AgentException","text":"","title":"AgentException"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.localization_map","text":"","title":"localization_map"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.module","text":"","title":"module"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.module.Module","text":"","title":"Module"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.module.Module.__init__","text":"Source code in ROAR/utilities_module/module.py def __init__ ( self , threaded = False ): self . threaded = threaded","title":"__init__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.module.Module.run_in_series","text":"This is the none-threaded function. It run in series! Parameters: Name Type Description Default **kwargs {} Source code in ROAR/utilities_module/module.py @abstractmethod def run_in_series ( self , ** kwargs ): \"\"\" This is the none-threaded function. It run in series! Args: **kwargs: Returns: \"\"\" pass","title":"run_in_series()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.module.Module.run_in_threaded","text":"This is the threaded function. Parameters: Name Type Description Default **kwargs {} Source code in ROAR/utilities_module/module.py @abstractmethod def run_in_threaded ( self , ** kwargs ): \"\"\" This is the threaded function. Args: **kwargs: Returns: \"\"\" pass","title":"run_in_threaded()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.module.Module.shutdown","text":"Source code in ROAR/utilities_module/module.py def shutdown ( self ): pass","title":"shutdown()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.occupancy_map","text":"","title":"occupancy_map"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.occupancy_map.OccupancyGridMap","text":"A 2D Occupancy Grid Map representing the world Should be able to handle 1. Transformation of coordinate from world to grid cord 2. Transformation of cord from grid cord to world cord 3. Represent the vehicle size and position, vehicle is represented as 0 Note that this class does NOT remember the vehicle position, in order to visualize vehicle, vehicle position has to be passed in 4. Represent the obstacles' position once its world coordinate is given 5. Represent free space's position, once its world coordinate is given 6. visualize itself, including zoom to a certain area so that not the entire map is visualized 7. The range of values should be bewteen 0 - 1 - 0 = obstacles, 1 = free space 8 Failure tolerant, if I pass in a wrong world coordinate, it will prompt it, but do not fail. Similar with other functions in this class 9. Fixed map size for enhanced performance","title":"OccupancyGridMap"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.occupancy_map.OccupancyGridMap.__init__","text":"Parameters: Name Type Description Default absolute_maximum_map_size Absolute maximum size of the map, will be used to compute a square occupancy map required map_padding int additional padding intended to add. 40 Note: This method pad to both sides, for example, it create padding to the left of min_x, and to the right of max_x Note: map_padding is for when when visualizing, we have to take a whole block and just in case the route is to the edge of the map, it will not error out Source code in ROAR/utilities_module/occupancy_map.py def __init__ ( self , absolute_maximum_map_size , map_padding : int = 40 , vehicle_width = 5 , vehicle_height = 5 ): \"\"\" Args: absolute_maximum_map_size: Absolute maximum size of the map, will be used to compute a square occupancy map map_padding: additional padding intended to add. Note: This method pad to both sides, for example, it create padding to the left of min_x, and to the right of max_x Note: map_padding is for when when visualizing, we have to take a whole block and just in case the route is to the edge of the map, it will not error out \"\"\" self . logger = logging . getLogger ( __name__ ) self . map : Optional [ np . ndarray ] = None self . _absolute_maximum_map_size = absolute_maximum_map_size self . _min_x = - math . floor ( self . _absolute_maximum_map_size ) self . _min_y = - math . floor ( self . _absolute_maximum_map_size ) self . _max_x = math . ceil ( self . _absolute_maximum_map_size ) self . _max_y = math . ceil ( self . _absolute_maximum_map_size ) self . _map_additiona_padding = map_padding self . vehicle_width = vehicle_width self . vehicle_height = vehicle_height self . _initialize_map ()","title":"__init__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.occupancy_map.OccupancyGridMap.cord_translation_from_world","text":"Translate from world coordinate to occupancy coordinate If the given world coord is less than min or greater than maximum, then do not execute the translation, log error message Parameters: Name Type Description Default world_cords_xy ndarray Numpy array of shape (N, 2) representing [[x, y], [x, y], ...] required Returns: Type Description ndarray occupancy grid map coordinate for this world coordinate of shape (N, 2) [ [x, y], [x, y] ] Source code in ROAR/utilities_module/occupancy_map.py def cord_translation_from_world ( self , world_cords_xy : np . ndarray ) -> np . ndarray : \"\"\" Translate from world coordinate to occupancy coordinate If the given world coord is less than min or greater than maximum, then do not execute the translation, log error message Args: world_cords_xy: Numpy array of shape (N, 2) representing [[x, y], [x, y], ...] Returns: occupancy grid map coordinate for this world coordinate of shape (N, 2) [ [x, y], [x, y] ] \"\"\" # reshape input into a ndarray that looks like [[X, Y], [X, Y]...] # self.logger.debug(f\"translating world cords xy: {np.shape(world_cords_xy)}\") transformed = np . round ( world_cords_xy - [ self . _min_x , self . _min_y ]) . astype ( np . int64 ) return transformed","title":"cord_translation_from_world()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.occupancy_map.OccupancyGridMap.location_to_occu_cord","text":"Converts World coordinate to coordinate in Occupancy Grid Map Source code in ROAR/utilities_module/occupancy_map.py def location_to_occu_cord ( self , location : Location ): \"\"\"Converts World coordinate to coordinate in Occupancy Grid Map\"\"\" return self . cord_translation_from_world ( world_cords_xy = np . array ([[ location . x , location . y ]]))","title":"location_to_occu_cord()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.occupancy_map.OccupancyGridMap.update_grid_map","text":"This is an easier to use update_grid_map method that can be directly called by an agent It will update grid map using the update_grid_map_from_world_cord method Parameters: Name Type Description Default depth_img current depth map required camera Camera camera state required vehicle Vehicle vehicle state required Returns: Type Description None Source code in ROAR/utilities_module/occupancy_map.py def update_grid_map ( self , depth_img , camera : Camera , vehicle : Vehicle ): \"\"\" This is an easier to use update_grid_map method that can be directly called by an agent It will update grid map using the update_grid_map_from_world_cord method Args: depth_img: current depth map camera: camera state vehicle: vehicle state Returns: None \"\"\" world_cords = img_to_world ( depth_img = depth_img , intrinsics_matrix = camera . intrinsics_matrix , extrinsics_matrix = camera . transform . get_matrix () @ vehicle . transform . get_matrix () ) self . update_grid_map_from_world_cord ( world_cords_xy = world_cords [: 2 , :] . T )","title":"update_grid_map()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.occupancy_map.OccupancyGridMap.update_grid_map_from_world_cord","text":"Updates the grid map based on the world coordinates passed in Parameters: Name Type Description Default world_cords_xy Numpy array of shape (N, 2) representing [[x, y], [x, y], ...] required Returns: Type Description None Source code in ROAR/utilities_module/occupancy_map.py def update_grid_map_from_world_cord ( self , world_cords_xy ): \"\"\" Updates the grid map based on the world coordinates passed in Args: world_cords_xy: Numpy array of shape (N, 2) representing [[x, y], [x, y], ...] Returns: None \"\"\" # find occupancy map cords # self.logger.debug(f\"Updating Grid Map: {np.shape(world_cords_xy)}\") occu_cords = self . cord_translation_from_world ( world_cords_xy = world_cords_xy ) # self.logger.debug(f\"Occupancy Grid Map Cord shape = {np.shape(occu_cords)}\") self . map [ occu_cords [:, 1 ], occu_cords [:, 0 ]] = 1","title":"update_grid_map_from_world_cord()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.occupancy_map.OccupancyGridMap.visualize","text":"Source code in ROAR/utilities_module/occupancy_map.py def visualize ( self , vehicle_location : Optional [ Location ] = None , view_size = 200 ): if vehicle_location is None : cv2 . imshow ( \"Occupancy Grid Map\" , self . map ) else : occu_cord = self . location_to_occu_cord ( location = vehicle_location ) map_copy = self . map . copy () x , y = occu_cord [ 0 ] map_copy [ y - self . vehicle_height // 2 : y + self . vehicle_height // 2 , x - self . vehicle_width // 2 : x + self . vehicle_width // 2 ] = 0 cv2 . imshow ( \"Occupancy Grid Map\" , map_copy [ y - view_size // 2 : y + view_size // 2 :, x - view_size // 2 : x + view_size // 2 ]) cv2 . waitKey ( 1 )","title":"visualize()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.track_visualizer","text":"The purpose of this file is to take in a txt file in containing data x,y,z,roll,pitch,yaw or x,y,z ... and visualize the track","title":"track_visualizer"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.track_visualizer.read_txt","text":"Source code in ROAR/utilities_module/track_visualizer.py def read_txt ( file_path : Path ) -> List [ List [ float ]]: if file_path . exists () is False : raise FileNotFoundError ( f \" { file_path } is not found. Please double check\" ) file = file_path . open ( 'r' ) result : List [ List [ float ]] = [] for line in file . readlines (): try : x , y , z = line . split ( sep = ',' ) except Exception as e : x , y , z , roll , pitch , yaw = line . split ( sep = ',' ) result . append ([ float ( x ), float ( y ), float ( z )]) return result","title":"read_txt()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.track_visualizer.visualize_track_data","text":"Source code in ROAR/utilities_module/track_visualizer.py def visualize_track_data ( track_data : List [ List [ float ]]): print ( f \"Visualizing [ { len ( track_data ) } ] data points\" ) track_data = np . asarray ( track_data ) fig = go . Figure ( data = [ go . Scatter3d ( x = track_data [:, 0 ], y = [ 0 ] * len ( track_data ), z = track_data [:, 2 ], mode = 'markers' )]) fig . show ()","title":"visualize_track_data()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.utilities","text":"","title":"utilities"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.utilities.img_to_world","text":"Source code in ROAR/utilities_module/utilities.py def img_to_world ( depth_img , intrinsics_matrix , extrinsics_matrix , sky_level = 0.9 , depth_scaling_factor = 1000 ) -> np . ndarray : # get a 2 x N array for their indices ground_loc = np . where ( depth_img < sky_level ) depth_val = depth_img [ depth_img < sky_level ] * depth_scaling_factor ground_loc = ground_loc * depth_val # compute raw_points raw_points = np . vstack ([ ground_loc , depth_val ]) # convert to cords_y_minus_z_x cords_y_minus_z_x = np . linalg . inv ( intrinsics_matrix ) @ raw_points # convert to cords_xyz_1 ones = np . ones (( 1 , np . shape ( cords_y_minus_z_x )[ 1 ])) cords_xyz_1 = np . vstack ([ cords_y_minus_z_x [ 2 , :], cords_y_minus_z_x [ 0 , :], - cords_y_minus_z_x [ 1 , :], ones ]) # multiply by cam_world_matrix points = extrinsics_matrix @ cords_xyz_1 # i have all points now return points","title":"img_to_world()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.utilities.img_to_world2","text":"Source code in ROAR/utilities_module/utilities.py def img_to_world2 ( depth_img , intrinsics_matrix , extrinsics_matrix , segmentation : np . ndarray , criteria , depth_scaling_factor = 1000 ) -> np . ndarray : # get a 2 x N array for their indices ground_loc = np . where ( segmentation == criteria )[: 2 ] # print(ground) # ground_loc = np.where(depth_img == criteria) depth_val = depth_img [ ground_loc ] * depth_scaling_factor ground_loc = ground_loc * depth_val # compute raw_points raw_points = np . vstack ([ ground_loc , depth_val ]) # convert to cords_y_minus_z_x cords_y_minus_z_x = np . linalg . inv ( intrinsics_matrix ) @ raw_points # convert to cords_xyz_1 ones = np . ones (( 1 , np . shape ( cords_y_minus_z_x )[ 1 ])) cords_xyz_1 = np . vstack ([ cords_y_minus_z_x [ 2 , :], cords_y_minus_z_x [ 0 , :], - cords_y_minus_z_x [ 1 , :], ones ]) # multiply by cam_world_matrix points = extrinsics_matrix @ cords_xyz_1 # i have all points now return points","title":"img_to_world2()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.utilities.png_to_depth","text":"Takes in an image read from cv2.imread(), whose output is simply a numpy array, turn it into a depth image according to carla's method of (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1). Parameters: Name Type Description Default im <built-in function array> input image, read from cv2.imread() required Returns: Type Description <built-in function array> depth image Source code in ROAR/utilities_module/utilities.py def png_to_depth ( im : np . array ) -> np . array : \"\"\" Takes in an image read from cv2.imread(), whose output is simply a numpy array, turn it into a depth image according to carla's method of (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1). Args: im: input image, read from cv2.imread() Returns: depth image \"\"\" im = im . astype ( np . float64 ) normalized_depth = np . dot ( im [:, :, : 3 ], [ 1 , 256 , 65536.0 ]) normalized_depth /= 16777215.0 return normalized_depth","title":"png_to_depth()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models","text":"","title":"vehicle_models"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.Vehicle","text":"Encodes the Vehicle's state at the last tick","title":"Vehicle"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.Vehicle.control","text":"","title":"control"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.Vehicle.transform","text":"","title":"transform"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.Vehicle.velocity","text":"","title":"velocity"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.Vehicle.wheel_base","text":"Default to tesla model 3's wheel base","title":"wheel_base"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.Vehicle.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.Vehicle.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.Vehicle.get_speed","text":"Compute speed of a vehicle in Km/h. :param vehicle: the vehicle for which speed is calculated :return: speed as a float in Km/h Source code in ROAR/utilities_module/vehicle_models.py @staticmethod def get_speed ( vehicle ): # TODO consider the jetson case \"\"\" Compute speed of a vehicle in Km/h. :param vehicle: the vehicle for which speed is calculated :return: speed as a float in Km/h \"\"\" vel = vehicle . velocity return 3.6 * math . sqrt ( vel . x ** 2 + vel . y ** 2 + vel . z ** 2 )","title":"get_speed()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.VehicleControl","text":"","title":"VehicleControl"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.VehicleControl.steering","text":"","title":"steering"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.VehicleControl.throttle","text":"","title":"throttle"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.VehicleControl.__config__","text":"","title":"__config__"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.VehicleControl.__json_encoder__","text":"","title":"__json_encoder__()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.VehicleControl.clamp","text":"Source code in ROAR/utilities_module/vehicle_models.py @staticmethod def clamp ( n , minn , maxn ): return max ( min ( maxn , n ), minn )","title":"clamp()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.VehicleControl.get_steering","text":"Cap it between -1 and 1 :return: Source code in ROAR/utilities_module/vehicle_models.py def get_steering ( self ) -> float : \"\"\" Cap it between -1 and 1 :return: \"\"\" return self . clamp ( self . steering , - 1 , 1 )","title":"get_steering()"},{"location":"code_documentations/ROAR/utilities_module/#ROAR.utilities_module.vehicle_models.VehicleControl.get_throttle","text":"Cap it between -1 and 1 :return: Source code in ROAR/utilities_module/vehicle_models.py def get_throttle ( self ) -> float : \"\"\" Cap it between -1 and 1 :return: \"\"\" return self . clamp ( self . throttle , - 1 , 1 )","title":"get_throttle()"},{"location":"code_documentations/ROAR/visualization/","text":"visualizer \u00a4 Visualizer \u00a4 GREEN \u00a4 GROUND \u00a4 __init__ ( self , agent , occupancy_grid_map = None , semantic_segmentation_detector = None , point_cloud_detector = None ) special \u00a4 Source code in ROAR/visualization_module/visualizer.py def __init__ ( self , agent : Agent , occupancy_grid_map : Optional [ OccupancyGridMap ] = None , semantic_segmentation_detector : Optional [ SemanticSegmentationDetector ] = None , point_cloud_detector : Optional [ PointCloudDetector ] = None ): self . logger = logging . getLogger ( __name__ ) self . agent = agent self . occupancy_grid_map = occupancy_grid_map self . semantic_segmentation_detector = semantic_segmentation_detector self . point_cloud_detector = point_cloud_detector calculate_img_pos ( self , waypoint_transform , camera ) \u00a4 Calculate the 2D image coordinate from 3D world space Parameters: Name Type Description Default camera Camera required waypoint_transform Transform Desired point in 3D world space required Returns: Type Description ndarray Array if integers [X, Y, depth] Source code in ROAR/visualization_module/visualizer.py @deprecated ( reason = \"Will no longer support single image to world calculation.\" ) def calculate_img_pos ( self , waypoint_transform : Transform , camera : Camera ) -> np . ndarray : \"\"\" Calculate the 2D image coordinate from 3D world space Args: camera: waypoint_transform: Desired point in 3D world space Returns: Array if integers [X, Y, depth] \"\"\" waypoint_location = waypoint_transform . location . to_array () # [x, y, z] waypoint_location = np . concatenate ( [ waypoint_location , [ 1 ]] ) # 4 x 1 array [X, Y, Z, 1] veh_cam_matrix = camera . transform . get_matrix () # 4 x 4 world_veh_matrix = self . agent . vehicle . transform . get_matrix () # 4 x 4 world_cam_matrix = np . linalg . inv ( np . dot ( world_veh_matrix , veh_cam_matrix )) cords_xyz = world_cam_matrix @ waypoint_location cords_y_minus_z_x = np . array ([ cords_xyz [ 1 ], - cords_xyz [ 2 ], cords_xyz [ 0 ]]) raw_p2d = camera . intrinsics_matrix @ cords_y_minus_z_x cam_cords = np . array ( [ raw_p2d [ 0 ] / raw_p2d [ 2 ], raw_p2d [ 1 ] / raw_p2d [ 2 ], raw_p2d [ 2 ]] ) return np . round ( cam_cords , 0 ) . astype ( np . int64 ) show_birds_eye_visualization ( self , focus_on_vehicle = True , view_size = 200 ) \u00a4 Visualizes top down image of Agent. Parameters: Name Type Description Default focus_on_vehicle bool True view_size int 200 Returns: Type Description None Source code in ROAR/visualization_module/visualizer.py def show_birds_eye_visualization ( self , focus_on_vehicle : bool = True , view_size : int = 200 ): \"\"\" Visualizes top down image of Agent. Args: focus_on_vehicle (): view_size (): Returns: None \"\"\" if self . occupancy_grid_map is None : self . logger . error ( \"No Occupancy Grid Map is connected\" ) else : if focus_on_vehicle : occu_cord = self . occupancy_grid_map . location_to_occu_cord ( location = self . agent . vehicle . transform . location ) map_copy = self . occupancy_grid_map . map . copy () x , y = occu_cord [ 0 ] map_copy [ y - self . occupancy_grid_map . vehicle_height // 2 : y + self . occupancy_grid_map . vehicle_height // 2 , x - self . occupancy_grid_map . vehicle_width // 2 : x + self . occupancy_grid_map . vehicle_width // 2 ] = 0 cv2 . imshow ( \"Occupancy Grid Map\" , map_copy [ y - view_size // 2 : y + view_size // 2 :, x - view_size // 2 : x + view_size // 2 ]) else : cv2 . imshow ( \"Occupancy Grid Map\" , self . occupancy_grid_map . map ) cv2 . waitKey ( 1 ) show_first_person_visualization ( self , show_num_waypoints = 0 , show_semantic_segmentation_obstacle = False , show_semantic_segmentation_sky = False , show_semantic_segmentation_ground = False , show_point_cloud_ground = False , ground_points = None ) \u00a4 Visualizes image from Front RGB Camera. Parameters: Name Type Description Default show_num_waypoints int 0 show_semantic_segmentation_obstacle bool False show_semantic_segmentation_sky bool False show_semantic_segmentation_ground bool False show_point_cloud_ground bool False ground_points Optional[numpy.ndarray] None Returns: Type Description None Source code in ROAR/visualization_module/visualizer.py def show_first_person_visualization ( self , show_num_waypoints : int = 0 , show_semantic_segmentation_obstacle : bool = False , show_semantic_segmentation_sky : bool = False , show_semantic_segmentation_ground : bool = False , show_point_cloud_ground : bool = False , ground_points : Optional [ np . ndarray ] = None ): \"\"\" Visualizes image from Front RGB Camera. Args: show_num_waypoints (): show_semantic_segmentation_obstacle (): show_semantic_segmentation_sky (): show_semantic_segmentation_ground (): show_point_cloud_ground (): ground_points (): Returns: None \"\"\" rgb_img = self . agent . front_rgb_camera . data . copy () if show_semantic_segmentation_sky or show_semantic_segmentation_obstacle or show_semantic_segmentation_ground : if self . semantic_segmentation_detector is not None and \\ self . semantic_segmentation_detector . curr_segmentation is not None : if show_semantic_segmentation_sky : mask = np . all ( self . semantic_segmentation_detector . curr_segmentation == self . semantic_segmentation_detector . SKY , axis =- 1 ) rgb_img [ mask ] = self . semantic_segmentation_detector . SKY if show_semantic_segmentation_obstacle : mask = np . all ( self . semantic_segmentation_detector . curr_segmentation == self . semantic_segmentation_detector . OBSTACLE , axis =- 1 ) rgb_img [ mask ] = self . semantic_segmentation_detector . OBSTACLE if show_semantic_segmentation_ground : mask = np . all ( self . semantic_segmentation_detector . curr_segmentation == self . semantic_segmentation_detector . GROUND , axis =- 1 ) rgb_img [ mask ] = self . semantic_segmentation_detector . GROUND else : self . logger . error ( \"Semantic Segmentation Detector is not configured\" ) if show_point_cloud_ground and ground_points is not None : img_cords : np . ndarray = self . world_to_img_transform ( ground_points )[:, : 2 ] # ys = [342, 278, 271, 413 ,327 ,169 ,415, 747 ,507 ,311,311,311,311,311,311] # xs = [577, 513 ,531, 522 ,372 ,581, 470 ,484, 587, 523,524,525,526,527,528] # rgb_img[xs, ys] = [0, 0, 0] rgb_img [ img_cords [:, 1 ], img_cords [:, 0 ]] = [ 0 , 0 , 0 ] # TODO this aint working lol if self . agent . local_planner is not None and \\ 0 < show_num_waypoints < len ( self . agent . local_planner . way_points_queue ): img_positions = self . world_to_img_transform ( np . array ( [ self . agent . local_planner . way_points_queue [ i ] . location . to_array () for i in range ( show_num_waypoints )])) for y , x , _ in img_positions : rgb_img [ x - 2 : x + 2 , y - 2 : y + 2 ] = self . GREEN cv2 . imshow ( \"First Person View\" , rgb_img ) cv2 . waitKey ( 1 ) visualize ( self , next_waypoint_transform ) \u00a4 This function will allow multiple objects to be drawn on here. Parameters: Name Type Description Default next_waypoint_transform Transform Next Waypoint's Transform information required Returns: Type Description None None Source code in ROAR/visualization_module/visualizer.py @deprecated ( reason = \"Will no longer support next waypoint visualization on a single display\" ) def visualize ( self , next_waypoint_transform : Transform ) -> None : \"\"\" This function will allow multiple objects to be drawn on here. Args: next_waypoint_transform: Next Waypoint's Transform information Returns: None \"\"\" next_waypoint_cam_pos = self . calculate_img_pos ( waypoint_transform = next_waypoint_transform , camera = self . agent . front_depth_camera , ) img = self . agent . front_rgb_camera . data . copy () start_point = ( 400 , 600 ) img = cv2 . arrowedLine ( img = img , pt1 = start_point , pt2 = ( next_waypoint_cam_pos [ 0 ], next_waypoint_cam_pos [ 1 ]), color = ( 0 , 255 , 0 ), thickness = 2 , ) cv2 . imshow ( \"Visualization\" , img ) cv2 . waitKey ( 1 ) visualize_semantic_segmentation ( cls , semantic_segmetation ) classmethod \u00a4 Parameters: Name Type Description Default semantic_segmetation Width x Height x 3 array with white = obstacles, black = ground, blue = sky required Returns: Type Description None None Source code in ROAR/visualization_module/visualizer.py @classmethod @deprecated ( reason = \"will no longer support single semantic segmentation visualization\" ) def visualize_semantic_segmentation ( cls , semantic_segmetation ) -> None : \"\"\" Args: semantic_segmetation: Width x Height x 3 array with white = obstacles, black = ground, blue = sky Returns: None \"\"\" if semantic_segmetation is not None : cv2 . imshow ( \"Semantic Segmentation\" , semantic_segmetation ) cv2 . waitKey ( 1 ) visualize_waypoint ( self , waypoint_transform ) \u00a4 Calculates position of waypoint Parameters: Name Type Description Default waypoint_transform Transform required Returns: Type Description None Source code in ROAR/visualization_module/visualizer.py @deprecated ( reason = \"Will no longer support seperate graph visualization\" ) def visualize_waypoint ( self , waypoint_transform : Transform ): \"\"\" Calculates position of waypoint Args: waypoint_transform (): Returns: None \"\"\" coord = self . calculate_img_pos ( waypoint_transform = waypoint_transform , camera = self . agent . front_depth_camera ) img = self . agent . front_rgb_camera . data . copy () img = cv2 . arrowedLine ( img , ( 400 , 600 ), ( coord [ 0 ], coord [ 1 ]), ( 0 , 255 , 0 ), 2 ) cv2 . imshow ( \"Next Waypoint\" , img ) cv2 . waitKey ( 1 ) world_to_img_transform ( self , xyz ) \u00a4 Calculate the 2D image coordinate from 3D world space Parameters: Name Type Description Default xyz ndarray (Nx3) array representing X, Y, Z in world coord required Returns: Type Description ndarray Array if integers [u, v, f] Source code in ROAR/visualization_module/visualizer.py def world_to_img_transform ( self , xyz : np . ndarray ) -> np . ndarray : \"\"\" Calculate the 2D image coordinate from 3D world space Args: xyz: (Nx3) array representing X, Y, Z in world coord Returns: Array if integers [u, v, f] \"\"\" xyz1 = np . append ( xyz , np . ones ( shape = ( len ( xyz ), 1 )), axis = 1 ) veh_cam_matrix = self . agent . front_depth_camera . transform . get_matrix () # 4 x 4 world_veh_matrix = self . agent . vehicle . transform . get_matrix () # 4 x 4 world_cam_matrix = np . linalg . inv ( np . dot ( world_veh_matrix , veh_cam_matrix )) cords_xyz1 = world_cam_matrix @ xyz1 . T cords_y_minus_z_x = np . array ([ cords_xyz1 [ 1 , :], - cords_xyz1 [ 2 , :], cords_xyz1 [ 0 , :]]) raw_p2d = self . agent . front_depth_camera . intrinsics_matrix @ cords_y_minus_z_x cam_cords = np . array ( [ raw_p2d [ 0 , :] / raw_p2d [ 2 , :], raw_p2d [ 1 , :] / raw_p2d [ 2 , :], raw_p2d [ 2 , :]] ) . T return np . round ( cam_cords , 0 ) . astype ( np . int64 )","title":"Visualization Module"},{"location":"code_documentations/ROAR/visualization/#ROAR.visualization_module.visualizer","text":"","title":"visualizer"},{"location":"code_documentations/ROAR/visualization/#ROAR.visualization_module.visualizer.Visualizer","text":"","title":"Visualizer"},{"location":"code_documentations/ROAR/visualization/#ROAR.visualization_module.visualizer.Visualizer.GREEN","text":"","title":"GREEN"},{"location":"code_documentations/ROAR/visualization/#ROAR.visualization_module.visualizer.Visualizer.GROUND","text":"","title":"GROUND"},{"location":"code_documentations/ROAR/visualization/#ROAR.visualization_module.visualizer.Visualizer.__init__","text":"Source code in ROAR/visualization_module/visualizer.py def __init__ ( self , agent : Agent , occupancy_grid_map : Optional [ OccupancyGridMap ] = None , semantic_segmentation_detector : Optional [ SemanticSegmentationDetector ] = None , point_cloud_detector : Optional [ PointCloudDetector ] = None ): self . logger = logging . getLogger ( __name__ ) self . agent = agent self . occupancy_grid_map = occupancy_grid_map self . semantic_segmentation_detector = semantic_segmentation_detector self . point_cloud_detector = point_cloud_detector","title":"__init__()"},{"location":"code_documentations/ROAR/visualization/#ROAR.visualization_module.visualizer.Visualizer.calculate_img_pos","text":"Calculate the 2D image coordinate from 3D world space Parameters: Name Type Description Default camera Camera required waypoint_transform Transform Desired point in 3D world space required Returns: Type Description ndarray Array if integers [X, Y, depth] Source code in ROAR/visualization_module/visualizer.py @deprecated ( reason = \"Will no longer support single image to world calculation.\" ) def calculate_img_pos ( self , waypoint_transform : Transform , camera : Camera ) -> np . ndarray : \"\"\" Calculate the 2D image coordinate from 3D world space Args: camera: waypoint_transform: Desired point in 3D world space Returns: Array if integers [X, Y, depth] \"\"\" waypoint_location = waypoint_transform . location . to_array () # [x, y, z] waypoint_location = np . concatenate ( [ waypoint_location , [ 1 ]] ) # 4 x 1 array [X, Y, Z, 1] veh_cam_matrix = camera . transform . get_matrix () # 4 x 4 world_veh_matrix = self . agent . vehicle . transform . get_matrix () # 4 x 4 world_cam_matrix = np . linalg . inv ( np . dot ( world_veh_matrix , veh_cam_matrix )) cords_xyz = world_cam_matrix @ waypoint_location cords_y_minus_z_x = np . array ([ cords_xyz [ 1 ], - cords_xyz [ 2 ], cords_xyz [ 0 ]]) raw_p2d = camera . intrinsics_matrix @ cords_y_minus_z_x cam_cords = np . array ( [ raw_p2d [ 0 ] / raw_p2d [ 2 ], raw_p2d [ 1 ] / raw_p2d [ 2 ], raw_p2d [ 2 ]] ) return np . round ( cam_cords , 0 ) . astype ( np . int64 )","title":"calculate_img_pos()"},{"location":"code_documentations/ROAR/visualization/#ROAR.visualization_module.visualizer.Visualizer.show_birds_eye_visualization","text":"Visualizes top down image of Agent. Parameters: Name Type Description Default focus_on_vehicle bool True view_size int 200 Returns: Type Description None Source code in ROAR/visualization_module/visualizer.py def show_birds_eye_visualization ( self , focus_on_vehicle : bool = True , view_size : int = 200 ): \"\"\" Visualizes top down image of Agent. Args: focus_on_vehicle (): view_size (): Returns: None \"\"\" if self . occupancy_grid_map is None : self . logger . error ( \"No Occupancy Grid Map is connected\" ) else : if focus_on_vehicle : occu_cord = self . occupancy_grid_map . location_to_occu_cord ( location = self . agent . vehicle . transform . location ) map_copy = self . occupancy_grid_map . map . copy () x , y = occu_cord [ 0 ] map_copy [ y - self . occupancy_grid_map . vehicle_height // 2 : y + self . occupancy_grid_map . vehicle_height // 2 , x - self . occupancy_grid_map . vehicle_width // 2 : x + self . occupancy_grid_map . vehicle_width // 2 ] = 0 cv2 . imshow ( \"Occupancy Grid Map\" , map_copy [ y - view_size // 2 : y + view_size // 2 :, x - view_size // 2 : x + view_size // 2 ]) else : cv2 . imshow ( \"Occupancy Grid Map\" , self . occupancy_grid_map . map ) cv2 . waitKey ( 1 )","title":"show_birds_eye_visualization()"},{"location":"code_documentations/ROAR/visualization/#ROAR.visualization_module.visualizer.Visualizer.show_first_person_visualization","text":"Visualizes image from Front RGB Camera. Parameters: Name Type Description Default show_num_waypoints int 0 show_semantic_segmentation_obstacle bool False show_semantic_segmentation_sky bool False show_semantic_segmentation_ground bool False show_point_cloud_ground bool False ground_points Optional[numpy.ndarray] None Returns: Type Description None Source code in ROAR/visualization_module/visualizer.py def show_first_person_visualization ( self , show_num_waypoints : int = 0 , show_semantic_segmentation_obstacle : bool = False , show_semantic_segmentation_sky : bool = False , show_semantic_segmentation_ground : bool = False , show_point_cloud_ground : bool = False , ground_points : Optional [ np . ndarray ] = None ): \"\"\" Visualizes image from Front RGB Camera. Args: show_num_waypoints (): show_semantic_segmentation_obstacle (): show_semantic_segmentation_sky (): show_semantic_segmentation_ground (): show_point_cloud_ground (): ground_points (): Returns: None \"\"\" rgb_img = self . agent . front_rgb_camera . data . copy () if show_semantic_segmentation_sky or show_semantic_segmentation_obstacle or show_semantic_segmentation_ground : if self . semantic_segmentation_detector is not None and \\ self . semantic_segmentation_detector . curr_segmentation is not None : if show_semantic_segmentation_sky : mask = np . all ( self . semantic_segmentation_detector . curr_segmentation == self . semantic_segmentation_detector . SKY , axis =- 1 ) rgb_img [ mask ] = self . semantic_segmentation_detector . SKY if show_semantic_segmentation_obstacle : mask = np . all ( self . semantic_segmentation_detector . curr_segmentation == self . semantic_segmentation_detector . OBSTACLE , axis =- 1 ) rgb_img [ mask ] = self . semantic_segmentation_detector . OBSTACLE if show_semantic_segmentation_ground : mask = np . all ( self . semantic_segmentation_detector . curr_segmentation == self . semantic_segmentation_detector . GROUND , axis =- 1 ) rgb_img [ mask ] = self . semantic_segmentation_detector . GROUND else : self . logger . error ( \"Semantic Segmentation Detector is not configured\" ) if show_point_cloud_ground and ground_points is not None : img_cords : np . ndarray = self . world_to_img_transform ( ground_points )[:, : 2 ] # ys = [342, 278, 271, 413 ,327 ,169 ,415, 747 ,507 ,311,311,311,311,311,311] # xs = [577, 513 ,531, 522 ,372 ,581, 470 ,484, 587, 523,524,525,526,527,528] # rgb_img[xs, ys] = [0, 0, 0] rgb_img [ img_cords [:, 1 ], img_cords [:, 0 ]] = [ 0 , 0 , 0 ] # TODO this aint working lol if self . agent . local_planner is not None and \\ 0 < show_num_waypoints < len ( self . agent . local_planner . way_points_queue ): img_positions = self . world_to_img_transform ( np . array ( [ self . agent . local_planner . way_points_queue [ i ] . location . to_array () for i in range ( show_num_waypoints )])) for y , x , _ in img_positions : rgb_img [ x - 2 : x + 2 , y - 2 : y + 2 ] = self . GREEN cv2 . imshow ( \"First Person View\" , rgb_img ) cv2 . waitKey ( 1 )","title":"show_first_person_visualization()"},{"location":"code_documentations/ROAR/visualization/#ROAR.visualization_module.visualizer.Visualizer.visualize","text":"This function will allow multiple objects to be drawn on here. Parameters: Name Type Description Default next_waypoint_transform Transform Next Waypoint's Transform information required Returns: Type Description None None Source code in ROAR/visualization_module/visualizer.py @deprecated ( reason = \"Will no longer support next waypoint visualization on a single display\" ) def visualize ( self , next_waypoint_transform : Transform ) -> None : \"\"\" This function will allow multiple objects to be drawn on here. Args: next_waypoint_transform: Next Waypoint's Transform information Returns: None \"\"\" next_waypoint_cam_pos = self . calculate_img_pos ( waypoint_transform = next_waypoint_transform , camera = self . agent . front_depth_camera , ) img = self . agent . front_rgb_camera . data . copy () start_point = ( 400 , 600 ) img = cv2 . arrowedLine ( img = img , pt1 = start_point , pt2 = ( next_waypoint_cam_pos [ 0 ], next_waypoint_cam_pos [ 1 ]), color = ( 0 , 255 , 0 ), thickness = 2 , ) cv2 . imshow ( \"Visualization\" , img ) cv2 . waitKey ( 1 )","title":"visualize()"},{"location":"code_documentations/ROAR/visualization/#ROAR.visualization_module.visualizer.Visualizer.visualize_semantic_segmentation","text":"Parameters: Name Type Description Default semantic_segmetation Width x Height x 3 array with white = obstacles, black = ground, blue = sky required Returns: Type Description None None Source code in ROAR/visualization_module/visualizer.py @classmethod @deprecated ( reason = \"will no longer support single semantic segmentation visualization\" ) def visualize_semantic_segmentation ( cls , semantic_segmetation ) -> None : \"\"\" Args: semantic_segmetation: Width x Height x 3 array with white = obstacles, black = ground, blue = sky Returns: None \"\"\" if semantic_segmetation is not None : cv2 . imshow ( \"Semantic Segmentation\" , semantic_segmetation ) cv2 . waitKey ( 1 )","title":"visualize_semantic_segmentation()"},{"location":"code_documentations/ROAR/visualization/#ROAR.visualization_module.visualizer.Visualizer.visualize_waypoint","text":"Calculates position of waypoint Parameters: Name Type Description Default waypoint_transform Transform required Returns: Type Description None Source code in ROAR/visualization_module/visualizer.py @deprecated ( reason = \"Will no longer support seperate graph visualization\" ) def visualize_waypoint ( self , waypoint_transform : Transform ): \"\"\" Calculates position of waypoint Args: waypoint_transform (): Returns: None \"\"\" coord = self . calculate_img_pos ( waypoint_transform = waypoint_transform , camera = self . agent . front_depth_camera ) img = self . agent . front_rgb_camera . data . copy () img = cv2 . arrowedLine ( img , ( 400 , 600 ), ( coord [ 0 ], coord [ 1 ]), ( 0 , 255 , 0 ), 2 ) cv2 . imshow ( \"Next Waypoint\" , img ) cv2 . waitKey ( 1 )","title":"visualize_waypoint()"},{"location":"code_documentations/ROAR/visualization/#ROAR.visualization_module.visualizer.Visualizer.world_to_img_transform","text":"Calculate the 2D image coordinate from 3D world space Parameters: Name Type Description Default xyz ndarray (Nx3) array representing X, Y, Z in world coord required Returns: Type Description ndarray Array if integers [u, v, f] Source code in ROAR/visualization_module/visualizer.py def world_to_img_transform ( self , xyz : np . ndarray ) -> np . ndarray : \"\"\" Calculate the 2D image coordinate from 3D world space Args: xyz: (Nx3) array representing X, Y, Z in world coord Returns: Array if integers [u, v, f] \"\"\" xyz1 = np . append ( xyz , np . ones ( shape = ( len ( xyz ), 1 )), axis = 1 ) veh_cam_matrix = self . agent . front_depth_camera . transform . get_matrix () # 4 x 4 world_veh_matrix = self . agent . vehicle . transform . get_matrix () # 4 x 4 world_cam_matrix = np . linalg . inv ( np . dot ( world_veh_matrix , veh_cam_matrix )) cords_xyz1 = world_cam_matrix @ xyz1 . T cords_y_minus_z_x = np . array ([ cords_xyz1 [ 1 , :], - cords_xyz1 [ 2 , :], cords_xyz1 [ 0 , :]]) raw_p2d = self . agent . front_depth_camera . intrinsics_matrix @ cords_y_minus_z_x cam_cords = np . array ( [ raw_p2d [ 0 , :] / raw_p2d [ 2 , :], raw_p2d [ 1 , :] / raw_p2d [ 2 , :], raw_p2d [ 2 , :]] ) . T return np . round ( cam_cords , 0 ) . astype ( np . int64 )","title":"world_to_img_transform()"},{"location":"code_documentations/ROAR_Sim/carla_client/","text":"::: ROAR_Sim.carla_client","title":"Carla client"},{"location":"code_documentations/ROAR_Sim/ccu/","text":"::: ROAR_Sim.carla_client.util","title":"Carla Client"},{"location":"code_documentations/ROAR_Sim/conf/","text":"::: ROAR_Sim.configurations","title":"Configurations"}]}